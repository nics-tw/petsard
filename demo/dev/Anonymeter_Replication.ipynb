{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c571ddc3-3147-4c39-b217-117095c58517",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/PETsARD/demo/dev\n"
     ]
    }
   ],
   "source": [
    "%cd demo/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bed3c11-869b-41fa-b01d-b40fcbfa74cc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (24.0)\n",
      "Requirement already satisfied: ipykernel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (6.29.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipykernel) (1.8.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipykernel) (8.21.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipykernel) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipykernel) (5.7.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipykernel) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipykernel) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipykernel) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipykernel) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipykernel) (5.14.1)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.18.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->ipykernel) (3.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Requirement already satisfied: pyyaml==6.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (6.0.1)\n",
      "Requirement already satisfied: boto3==1.34.58 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.58)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.58 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3==1.34.58) (1.34.68)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3==1.34.58) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3==1.34.58) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.58->boto3==1.34.58) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.58->boto3==1.34.58) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.58->boto3==1.34.58) (1.16.0)\n",
      "Requirement already satisfied: sdv==1.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.10.0)\n",
      "Requirement already satisfied: boto3<2,>=1.15.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdv==1.10.0) (1.34.58)\n",
      "Requirement already satisfied: botocore<2,>=1.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdv==1.10.0) (1.34.68)\n",
      "Requirement already satisfied: cloudpickle<3.0,>=2.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdv==1.10.0) (2.2.1)\n",
      "Requirement already satisfied: graphviz<1,>=0.13.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdv==1.10.0) (0.17)\n",
      "Requirement already satisfied: tqdm<5,>=4.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdv==1.10.0) (4.66.1)\n",
      "Requirement already satisfied: copulas<0.10,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdv==1.10.0) (0.9.2)\n",
      "Requirement already satisfied: ctgan<0.10,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdv==1.10.0) (0.9.1)\n",
      "Requirement already satisfied: deepecho<0.6,>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdv==1.10.0) (0.5.0)\n",
      "Requirement already satisfied: rdt<2,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdv==1.10.0) (1.10.1)\n",
      "Requirement already satisfied: sdmetrics<0.14,>=0.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdv==1.10.0) (0.13.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdv==1.10.0) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdv==1.10.0) (2.2.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2,>=1.15.0->sdv==1.10.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2,>=1.15.0->sdv==1.10.0) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2,>=1.18->sdv==1.10.0) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2,>=1.18->sdv==1.10.0) (1.26.18)\n",
      "Requirement already satisfied: matplotlib<4,>=3.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from copulas<0.10,>=0.9.0->sdv==1.10.0) (3.8.2)\n",
      "Requirement already satisfied: scipy<2,>=1.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from copulas<0.10,>=0.9.0->sdv==1.10.0) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ctgan<0.10,>=0.9.0->sdv==1.10.0) (1.4.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ctgan<0.10,>=0.9.0->sdv==1.10.0) (2.2.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.3.4->sdv==1.10.0) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.3.4->sdv==1.10.0) (2023.4)\n",
      "Collecting Faker<20,>=17 (from rdt<2,>=1.9.0->sdv==1.10.0)\n",
      "  Using cached Faker-19.13.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: plotly<6,>=5.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sdmetrics<0.14,>=0.13.0->sdv==1.10.0) (5.18.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.10.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.10.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.10.0) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.10.0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.10.0) (21.3)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.10.0) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<4,>=3.6.0->copulas<0.10,>=0.9.0->sdv==1.10.0) (3.1.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from plotly<6,>=5.10.0->sdmetrics<0.14,>=0.13.0->sdv==1.10.0) (8.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2,>=1.18->sdv==1.10.0) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn>=1.1.3->ctgan<0.10,>=0.9.0->sdv==1.10.0) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn>=1.1.3->ctgan<0.10,>=0.9.0->sdv==1.10.0) (3.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch>=1.11.0->ctgan<0.10,>=0.9.0->sdv==1.10.0) (1.3.0)\n",
      "Using cached Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: Faker\n",
      "  Attempting uninstall: Faker\n",
      "    Found existing installation: Faker 15.3.4\n",
      "    Uninstalling Faker-15.3.4:\n",
      "      Successfully uninstalled Faker-15.3.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "smartnoise-synth 1.0.3 requires Faker<16.0.0,>=15.0.0, but you have faker 19.13.0 which is incompatible.\n",
      "smartnoise-synth 1.0.3 requires torch<2.0.0, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Faker-19.13.0\n",
      "Requirement already satisfied: smartnoise-synth==1.0.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.0.3)\n",
      "Collecting Faker<16.0.0,>=15.0.0 (from smartnoise-synth==1.0.3)\n",
      "  Using cached Faker-15.3.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: opacus<0.15.0,>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from smartnoise-synth==1.0.3) (0.14.0)\n",
      "Requirement already satisfied: pac-synth<0.0.9,>=0.0.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from smartnoise-synth==1.0.3) (0.0.8)\n",
      "Requirement already satisfied: smartnoise-sql<2.0.0,>=1.0.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from smartnoise-synth==1.0.3) (1.0.3)\n",
      "Collecting torch<2.0.0 (from smartnoise-synth==1.0.3)\n",
      "  Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Faker<16.0.0,>=15.0.0->smartnoise-synth==1.0.3) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opacus<0.15.0,>=0.14.0->smartnoise-synth==1.0.3) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opacus<0.15.0,>=0.14.0->smartnoise-synth==1.0.3) (1.12.0)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=6.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from smartnoise-sql<2.0.0,>=1.0.3->smartnoise-synth==1.0.3) (6.0.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from smartnoise-sql<2.0.0,>=1.0.3->smartnoise-synth==1.0.3) (4.9.3)\n",
      "Requirement already satisfied: graphviz<0.18,>=0.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from smartnoise-sql<2.0.0,>=1.0.3->smartnoise-synth==1.0.3) (0.17)\n",
      "Requirement already satisfied: opendp<0.9.0,>=0.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from smartnoise-sql<2.0.0,>=1.0.3->smartnoise-synth==1.0.3) (0.8.0)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from smartnoise-sql<2.0.0,>=1.0.3->smartnoise-synth==1.0.3) (2.2.0)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from smartnoise-sql<2.0.0,>=1.0.3->smartnoise-synth==1.0.3) (2.0.25)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch<2.0.0->smartnoise-synth==1.0.3) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch<2.0.0->smartnoise-synth==1.0.3) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch<2.0.0->smartnoise-synth==1.0.3) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch<2.0.0->smartnoise-synth==1.0.3) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch<2.0.0->smartnoise-synth==1.0.3) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0->smartnoise-synth==1.0.3) (69.0.3)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0->smartnoise-synth==1.0.3) (0.42.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas<3.0.0,>=2.0.1->smartnoise-sql<2.0.0,>=1.0.3->smartnoise-synth==1.0.3) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas<3.0.0,>=2.0.1->smartnoise-sql<2.0.0,>=1.0.3->smartnoise-synth==1.0.3) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.4->Faker<16.0.0,>=15.0.0->smartnoise-synth==1.0.3) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sqlalchemy<3.0.0,>=2.0.0->smartnoise-sql<2.0.0,>=1.0.3->smartnoise-synth==1.0.3) (3.0.3)\n",
      "Using cached Faker-15.3.4-py3-none-any.whl (1.6 MB)\n",
      "Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "Installing collected packages: Faker, torch\n",
      "  Attempting uninstall: Faker\n",
      "    Found existing installation: Faker 19.13.0\n",
      "    Uninstalling Faker-19.13.0:\n",
      "      Successfully uninstalled Faker-19.13.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.1\n",
      "    Uninstalling torch-2.2.1:\n",
      "      Successfully uninstalled torch-2.2.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "rdt 1.10.1 requires Faker<20,>=17, but you have faker 15.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Faker-15.3.4 torch-1.13.1\n",
      "Requirement already satisfied: anonymeter==1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: scikit-learn~=1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anonymeter==1.0.0) (1.4.0)\n",
      "Requirement already satisfied: numpy<1.27,>=1.22 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anonymeter==1.0.0) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anonymeter==1.0.0) (2.2.0)\n",
      "Requirement already satisfied: joblib~=1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anonymeter==1.0.0) (1.3.2)\n",
      "Requirement already satisfied: numba~=0.58 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anonymeter==1.0.0) (0.58.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from numba~=0.58->anonymeter==1.0.0) (0.41.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.4->anonymeter==1.0.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.4->anonymeter==1.0.0) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.4->anonymeter==1.0.0) (2023.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn~=1.2->anonymeter==1.0.0) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn~=1.2->anonymeter==1.0.0) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.4->anonymeter==1.0.0) (1.16.0)\n",
      "Collecting git+https://github.com/ryan112358/private-pgm.git\n",
      "  Cloning https://github.com/ryan112358/private-pgm.git to /tmp/pip-req-build-l5v5fdyh\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ryan112358/private-pgm.git /tmp/pip-req-build-l5v5fdyh\n",
      "  Resolved https://github.com/ryan112358/private-pgm.git to commit 5b9126295c110b741e5426ddbff419ea1e60e788\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from private-pgm==0.0.1) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from private-pgm==0.0.1) (1.12.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from private-pgm==0.0.1) (2.2.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from private-pgm==0.0.1) (3.2.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from private-pgm==0.0.1) (3.8.2)\n",
      "Requirement already satisfied: nose in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from private-pgm==0.0.1) (1.3.7)\n",
      "Requirement already satisfied: disjoint-set in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from private-pgm==0.0.1) (0.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->private-pgm==0.0.1) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->private-pgm==0.0.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->private-pgm==0.0.1) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->private-pgm==0.0.1) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->private-pgm==0.0.1) (21.3)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->private-pgm==0.0.1) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->private-pgm==0.0.1) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->private-pgm==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->private-pgm==0.0.1) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->private-pgm==0.0.1) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->private-pgm==0.0.1) (1.16.0)\n",
      "Collecting torch==2.2.1\n",
      "  Using cached torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.2.1) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch==2.2.1) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch==2.2.1) (1.3.0)\n",
      "Using cached torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "smartnoise-synth 1.0.3 requires torch<2.0.0, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.2.1\n",
      "Requirement already satisfied: requests==2.31.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests==2.31.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests==2.31.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests==2.31.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests==2.31.0) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!pip install ipykernel\n",
    "!pip install pyyaml==6.0.1\n",
    "!pip install boto3==1.34.58\n",
    "!pip install sdv==1.10.0\n",
    "!pip install smartnoise-synth==1.0.3 # Error can be ignored\n",
    "!pip install anonymeter==1.0.0\n",
    "!pip install git+https://github.com/ryan112358/private-pgm.git\n",
    "!pip install --upgrade torch==2.2.1 # Error can be ignored\n",
    "!pip install requests==2.31.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f861d5d-c358-4fa2-aaa2-990438161687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PETsARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ef71ed-aedd-4efe-9729-ed92a46f7282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755ebb01-7ecd-4ec1-aca7-6bb150c4ac25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from PETsARD import Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e95d83-1e3b-4b25-948c-c5d88b7e0e59",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Loader with adult-income...\n",
      "Now is Splitter with p80_[2-1]...\n",
      "Now is Preprocessor with default-smartnoise...\n",
      "Now is Synthesizer with smartnoise-dpctgan10...\n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1352: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.6666, Loss D: 1.4093\n",
      "epsilon is 0.1621052371810809, alpha is 63.0\n",
      "Epoch 2, Loss G: 0.6873, Loss D: 1.3955\n",
      "epsilon is 0.2154777899194668, alpha is 63.0\n",
      "Epoch 3, Loss G: 0.6898, Loss D: 1.3916\n",
      "epsilon is 0.2688503426578527, alpha is 63.0\n",
      "Epoch 4, Loss G: 0.6688, Loss D: 1.3864\n",
      "epsilon is 0.32222289539623855, alpha is 63.0\n",
      "Epoch 5, Loss G: 0.6564, Loss D: 1.3952\n",
      "epsilon is 0.37341275087699954, alpha is 57.0\n",
      "Epoch 6, Loss G: 0.6550, Loss D: 1.3973\n",
      "epsilon is 0.41901084464897975, alpha is 52.0\n",
      "Epoch 7, Loss G: 0.6566, Loss D: 1.3939\n",
      "epsilon is 0.46047921301009653, alpha is 48.0\n",
      "Epoch 8, Loss G: 0.6550, Loss D: 1.3895\n",
      "epsilon is 0.49879327014201535, alpha is 44.0\n",
      "Epoch 9, Loss G: 0.6420, Loss D: 1.3935\n",
      "epsilon is 0.5346025437355053, alpha is 42.0\n",
      "Epoch 10, Loss G: 0.6430, Loss D: 1.3926\n",
      "epsilon is 0.5684014701443807, alpha is 40.0\n",
      "Epoch 11, Loss G: 0.6494, Loss D: 1.3883\n",
      "epsilon is 0.6004394015460149, alpha is 38.0\n",
      "Epoch 12, Loss G: 0.6484, Loss D: 1.3976\n",
      "epsilon is 0.6310196395077151, alpha is 36.0\n",
      "Epoch 13, Loss G: 0.6473, Loss D: 1.3979\n",
      "epsilon is 0.6603460122722166, alpha is 35.0\n",
      "Epoch 14, Loss G: 0.6462, Loss D: 1.3925\n",
      "epsilon is 0.6886041442379658, alpha is 34.0\n",
      "Epoch 15, Loss G: 0.6463, Loss D: 1.3939\n",
      "epsilon is 0.7157875852128055, alpha is 32.0\n",
      "Epoch 16, Loss G: 0.6427, Loss D: 1.3970\n",
      "epsilon is 0.7421024871575375, alpha is 31.0\n",
      "Epoch 17, Loss G: 0.6321, Loss D: 1.4060\n",
      "epsilon is 0.767647100288211, alpha is 31.0\n",
      "Epoch 18, Loss G: 0.6294, Loss D: 1.3982\n",
      "epsilon is 0.7923548741192558, alpha is 30.0\n",
      "Epoch 19, Loss G: 0.6258, Loss D: 1.3986\n",
      "epsilon is 0.816405988490787, alpha is 29.0\n",
      "Epoch 20, Loss G: 0.6249, Loss D: 1.3940\n",
      "epsilon is 0.8399196285202444, alpha is 28.0\n",
      "Epoch 21, Loss G: 0.6204, Loss D: 1.3970\n",
      "epsilon is 0.8629338200947815, alpha is 28.0\n",
      "Epoch 22, Loss G: 0.6220, Loss D: 1.3955\n",
      "epsilon is 0.8852065804317902, alpha is 27.0\n",
      "Epoch 23, Loss G: 0.6174, Loss D: 1.3956\n",
      "epsilon is 0.90723938148027, alpha is 26.0\n",
      "Epoch 24, Loss G: 0.6129, Loss D: 1.4000\n",
      "epsilon is 0.9285737784052924, alpha is 26.0\n",
      "Epoch 25, Loss G: 0.6075, Loss D: 1.3977\n",
      "epsilon is 0.9497140109656055, alpha is 25.0\n",
      "Epoch 26, Loss G: 0.6030, Loss D: 1.4041\n",
      "epsilon is 0.970210641801423, alpha is 25.0\n",
      "Epoch 27, Loss G: 0.5999, Loss D: 1.4045\n",
      "epsilon is 0.9906783712641867, alpha is 24.0\n",
      "Epoch 28, Loss G: 0.5991, Loss D: 1.4007\n",
      "epsilon is 1.0103386503711411, alpha is 24.0\n",
      "Epoch 29, Loss G: 0.5936, Loss D: 1.4084\n",
      "epsilon is 1.0299989294780953, alpha is 24.0\n",
      "Epoch 30, Loss G: 0.5878, Loss D: 1.4130\n",
      "epsilon is 1.0492187527163617, alpha is 23.0\n",
      "Epoch 31, Loss G: 0.5938, Loss D: 1.4021\n",
      "epsilon is 1.0680440896397936, alpha is 23.0\n",
      "Epoch 32, Loss G: 0.5842, Loss D: 1.4072\n",
      "epsilon is 1.0868694265632255, alpha is 23.0\n",
      "Epoch 33, Loss G: 0.5830, Loss D: 1.4026\n",
      "epsilon is 1.1051527178449858, alpha is 22.0\n",
      "Epoch 34, Loss G: 0.5831, Loss D: 1.4107\n",
      "epsilon is 1.1231445173410244, alpha is 22.0\n",
      "Epoch 35, Loss G: 0.5750, Loss D: 1.4090\n",
      "epsilon is 1.141136316837063, alpha is 22.0\n",
      "Epoch 36, Loss G: 0.5776, Loss D: 1.4078\n",
      "epsilon is 1.158855915839736, alpha is 21.0\n",
      "Epoch 37, Loss G: 0.5693, Loss D: 1.4146\n",
      "epsilon is 1.1760155779008916, alpha is 21.0\n",
      "Epoch 38, Loss G: 0.5682, Loss D: 1.4120\n",
      "epsilon is 1.1931752399620472, alpha is 21.0\n",
      "Epoch 39, Loss G: 0.5580, Loss D: 1.4172\n",
      "epsilon is 1.2103349020232026, alpha is 21.0\n",
      "Epoch 40, Loss G: 0.5583, Loss D: 1.4119\n",
      "epsilon is 1.2271108084042925, alpha is 20.0\n",
      "Epoch 41, Loss G: 0.5586, Loss D: 1.4078\n",
      "epsilon is 1.2434397282848608, alpha is 20.0\n",
      "Epoch 42, Loss G: 0.5392, Loss D: 1.4251\n",
      "epsilon is 1.259768648165429, alpha is 20.0\n",
      "Epoch 43, Loss G: 0.5438, Loss D: 1.4271\n",
      "epsilon is 1.2760975680459974, alpha is 20.0\n",
      "Epoch 44, Loss G: 0.5376, Loss D: 1.4293\n",
      "epsilon is 1.2924264879265657, alpha is 20.0\n",
      "Epoch 45, Loss G: 0.5417, Loss D: 1.4241\n",
      "epsilon is 1.3079827600088128, alpha is 19.0\n",
      "Epoch 46, Loss G: 0.5365, Loss D: 1.4241\n",
      "epsilon is 1.323482328250091, alpha is 19.0\n",
      "Epoch 47, Loss G: 0.5334, Loss D: 1.4172\n",
      "epsilon is 1.3389818964913687, alpha is 19.0\n",
      "Epoch 48, Loss G: 0.5279, Loss D: 1.4253\n",
      "epsilon is 1.3544814647326469, alpha is 19.0\n",
      "Epoch 49, Loss G: 0.5307, Loss D: 1.4236\n",
      "epsilon is 1.3699810329739246, alpha is 19.0\n",
      "Epoch 50, Loss G: 0.5318, Loss D: 1.4301\n",
      "epsilon is 1.3850035674822065, alpha is 18.0\n",
      "Epoch 51, Loss G: 0.5299, Loss D: 1.4209\n",
      "epsilon is 1.3996751699375183, alpha is 18.0\n",
      "Epoch 52, Loss G: 0.5279, Loss D: 1.4295\n",
      "epsilon is 1.4143467723928305, alpha is 18.0\n",
      "Epoch 53, Loss G: 0.5327, Loss D: 1.4231\n",
      "epsilon is 1.4290183748481424, alpha is 18.0\n",
      "Epoch 54, Loss G: 0.5320, Loss D: 1.4317\n",
      "epsilon is 1.4436899773034544, alpha is 18.0\n",
      "Epoch 55, Loss G: 0.5260, Loss D: 1.4191\n",
      "epsilon is 1.4583615797587666, alpha is 18.0\n",
      "Epoch 56, Loss G: 0.5303, Loss D: 1.4270\n",
      "epsilon is 1.4728805636486564, alpha is 17.0\n",
      "Epoch 57, Loss G: 0.5171, Loss D: 1.4349\n",
      "epsilon is 1.4867255815082014, alpha is 17.0\n",
      "Epoch 58, Loss G: 0.5120, Loss D: 1.4282\n",
      "epsilon is 1.5005705993677465, alpha is 17.0\n",
      "Epoch 59, Loss G: 0.5013, Loss D: 1.4453\n",
      "epsilon is 1.5144156172272918, alpha is 17.0\n",
      "Epoch 60, Loss G: 0.4968, Loss D: 1.4384\n",
      "epsilon is 1.528260635086837, alpha is 17.0\n",
      "Epoch 61, Loss G: 0.4938, Loss D: 1.4361\n",
      "epsilon is 1.5421056529463821, alpha is 17.0\n",
      "Epoch 62, Loss G: 0.4994, Loss D: 1.4341\n",
      "epsilon is 1.5559506708059274, alpha is 17.0\n",
      "Epoch 63, Loss G: 0.4939, Loss D: 1.4511\n",
      "epsilon is 1.5697956886654725, alpha is 17.0\n",
      "Epoch 64, Loss G: 0.4974, Loss D: 1.4435\n",
      "epsilon is 1.5832489554301077, alpha is 16.0\n",
      "Epoch 65, Loss G: 0.4835, Loss D: 1.4569\n",
      "epsilon is 1.5962687652456178, alpha is 16.0\n",
      "Epoch 66, Loss G: 0.4936, Loss D: 1.4364\n",
      "epsilon is 1.6092885750611279, alpha is 16.0\n",
      "Epoch 67, Loss G: 0.4868, Loss D: 1.4571\n",
      "epsilon is 1.622308384876638, alpha is 16.0\n",
      "Epoch 68, Loss G: 0.4773, Loss D: 1.4451\n",
      "epsilon is 1.635328194692148, alpha is 16.0\n",
      "Epoch 69, Loss G: 0.4789, Loss D: 1.4545\n",
      "epsilon is 1.6483480045076582, alpha is 16.0\n",
      "Epoch 70, Loss G: 0.4825, Loss D: 1.4522\n",
      "epsilon is 1.6613678143231683, alpha is 16.0\n",
      "Epoch 71, Loss G: 0.4719, Loss D: 1.4596\n",
      "epsilon is 1.6743876241386784, alpha is 16.0\n",
      "Epoch 72, Loss G: 0.4704, Loss D: 1.4582\n",
      "epsilon is 1.6874074339541885, alpha is 16.0\n",
      "Epoch 73, Loss G: 0.4770, Loss D: 1.4540\n",
      "epsilon is 1.7003765494338765, alpha is 15.0\n",
      "Epoch 74, Loss G: 0.4679, Loss D: 1.4591\n",
      "epsilon is 1.7125725231430986, alpha is 15.0\n",
      "Epoch 75, Loss G: 0.4674, Loss D: 1.4638\n",
      "epsilon is 1.7247684968523207, alpha is 15.0\n",
      "Epoch 76, Loss G: 0.4661, Loss D: 1.4520\n",
      "epsilon is 1.7369644705615428, alpha is 15.0\n",
      "Epoch 77, Loss G: 0.4576, Loss D: 1.4781\n",
      "epsilon is 1.7491604442707651, alpha is 15.0\n",
      "Epoch 78, Loss G: 0.4461, Loss D: 1.4812\n",
      "epsilon is 1.761356417979987, alpha is 15.0\n",
      "Epoch 79, Loss G: 0.4425, Loss D: 1.4909\n",
      "epsilon is 1.7735523916892093, alpha is 15.0\n",
      "Epoch 80, Loss G: 0.4403, Loss D: 1.4794\n",
      "epsilon is 1.7857483653984312, alpha is 15.0\n",
      "Epoch 81, Loss G: 0.4267, Loss D: 1.4926\n",
      "epsilon is 1.7979443391076535, alpha is 15.0\n",
      "Epoch 82, Loss G: 0.4305, Loss D: 1.4878\n",
      "epsilon is 1.8101403128168756, alpha is 15.0\n",
      "Epoch 83, Loss G: 0.4319, Loss D: 1.5113\n",
      "epsilon is 1.8223362865260977, alpha is 15.0\n",
      "Epoch 84, Loss G: 0.4293, Loss D: 1.5054\n",
      "epsilon is 1.8345322602353198, alpha is 15.0\n",
      "Epoch 85, Loss G: 0.4283, Loss D: 1.5048\n",
      "epsilon is 1.8463913103053533, alpha is 14.0\n",
      "Epoch 86, Loss G: 0.4256, Loss D: 1.4893\n",
      "epsilon is 1.857764815256347, alpha is 14.0\n",
      "Epoch 87, Loss G: 0.4246, Loss D: 1.5056\n",
      "epsilon is 1.8691383202073408, alpha is 14.0\n",
      "Epoch 88, Loss G: 0.4177, Loss D: 1.5068\n",
      "epsilon is 1.880511825158335, alpha is 14.0\n",
      "Epoch 89, Loss G: 0.4217, Loss D: 1.4970\n",
      "epsilon is 1.8918853301093288, alpha is 14.0\n",
      "Epoch 90, Loss G: 0.4165, Loss D: 1.5039\n",
      "epsilon is 1.9032588350603226, alpha is 14.0\n",
      "Epoch 91, Loss G: 0.4221, Loss D: 1.5025\n",
      "epsilon is 1.9146323400113165, alpha is 14.0\n",
      "Epoch 92, Loss G: 0.4031, Loss D: 1.5194\n",
      "epsilon is 1.9260058449623105, alpha is 14.0\n",
      "Epoch 93, Loss G: 0.4154, Loss D: 1.5063\n",
      "epsilon is 1.9373793499133043, alpha is 14.0\n",
      "Epoch 94, Loss G: 0.4151, Loss D: 1.5181\n",
      "epsilon is 1.948752854864298, alpha is 14.0\n",
      "Epoch 95, Loss G: 0.4089, Loss D: 1.5177\n",
      "epsilon is 1.9601263598152918, alpha is 14.0\n",
      "Epoch 96, Loss G: 0.4058, Loss D: 1.5149\n",
      "epsilon is 1.971499864766286, alpha is 14.0\n",
      "Epoch 97, Loss G: 0.4073, Loss D: 1.5166\n",
      "epsilon is 1.9828733697172802, alpha is 14.0\n",
      "Epoch 98, Loss G: 0.4035, Loss D: 1.5230\n",
      "epsilon is 1.994246874668274, alpha is 14.0\n",
      "Epoch 99, Loss G: 0.3907, Loss D: 1.5434\n",
      "epsilon is 2.005620379619268, alpha is 14.0\n",
      "Epoch 100, Loss G: 0.3859, Loss D: 1.5632\n",
      "epsilon is 2.01637239401409, alpha is 13.0\n",
      "Epoch 101, Loss G: 0.3738, Loss D: 1.5687\n",
      "epsilon is 2.0269247929893552, alpha is 13.0\n",
      "Epoch 102, Loss G: 0.3710, Loss D: 1.5648\n",
      "epsilon is 2.03747719196462, alpha is 13.0\n",
      "Epoch 103, Loss G: 0.3670, Loss D: 1.5695\n",
      "epsilon is 2.0480295909398856, alpha is 13.0\n",
      "Epoch 104, Loss G: 0.3544, Loss D: 1.5805\n",
      "epsilon is 2.058581989915151, alpha is 13.0\n",
      "Epoch 105, Loss G: 0.3625, Loss D: 1.5847\n",
      "epsilon is 2.069134388890416, alpha is 13.0\n",
      "Epoch 106, Loss G: 0.3612, Loss D: 1.5824\n",
      "epsilon is 2.0796867878656817, alpha is 13.0\n",
      "Epoch 107, Loss G: 0.3618, Loss D: 1.5783\n",
      "epsilon is 2.0902391868409467, alpha is 13.0\n",
      "Epoch 108, Loss G: 0.3633, Loss D: 1.5793\n",
      "epsilon is 2.100791585816212, alpha is 13.0\n",
      "Epoch 109, Loss G: 0.3558, Loss D: 1.5982\n",
      "epsilon is 2.1113439847914774, alpha is 13.0\n",
      "Epoch 110, Loss G: 0.3568, Loss D: 1.5870\n",
      "epsilon is 2.1218963837667424, alpha is 13.0\n",
      "Epoch 111, Loss G: 0.3525, Loss D: 1.5726\n",
      "epsilon is 2.1324487827420078, alpha is 13.0\n",
      "Epoch 112, Loss G: 0.3598, Loss D: 1.5800\n",
      "epsilon is 2.143001181717273, alpha is 13.0\n",
      "Epoch 113, Loss G: 0.3616, Loss D: 1.5673\n",
      "epsilon is 2.153553580692538, alpha is 13.0\n",
      "Epoch 114, Loss G: 0.3542, Loss D: 1.5907\n",
      "epsilon is 2.164105979667804, alpha is 13.0\n",
      "Epoch 115, Loss G: 0.3427, Loss D: 1.6017\n",
      "epsilon is 2.174658378643069, alpha is 13.0\n",
      "Epoch 116, Loss G: 0.3347, Loss D: 1.6300\n",
      "epsilon is 2.1852107776183343, alpha is 13.0\n",
      "Epoch 117, Loss G: 0.3099, Loss D: 1.6878\n",
      "epsilon is 2.1957631765935997, alpha is 13.0\n",
      "Epoch 118, Loss G: 0.3171, Loss D: 1.6529\n",
      "epsilon is 2.2063155755688646, alpha is 13.0\n",
      "Epoch 119, Loss G: 0.2980, Loss D: 1.6995\n",
      "epsilon is 2.2160572825895373, alpha is 12.0\n",
      "Epoch 120, Loss G: 0.2933, Loss D: 1.7019\n",
      "epsilon is 2.2257899338299536, alpha is 12.0\n",
      "Epoch 121, Loss G: 0.2849, Loss D: 1.7051\n",
      "epsilon is 2.2355225850703704, alpha is 12.0\n",
      "Epoch 122, Loss G: 0.2860, Loss D: 1.7343\n",
      "epsilon is 2.245255236310787, alpha is 12.0\n",
      "Epoch 123, Loss G: 0.2765, Loss D: 1.7226\n",
      "epsilon is 2.254987887551204, alpha is 12.0\n",
      "Epoch 124, Loss G: 0.2845, Loss D: 1.7017\n",
      "epsilon is 2.2647205387916207, alpha is 12.0\n",
      "Epoch 125, Loss G: 0.2821, Loss D: 1.7068\n",
      "epsilon is 2.2744531900320375, alpha is 12.0\n",
      "Epoch 126, Loss G: 0.2864, Loss D: 1.7025\n",
      "epsilon is 2.284185841272454, alpha is 12.0\n",
      "Epoch 127, Loss G: 0.2997, Loss D: 1.6913\n",
      "epsilon is 2.2939184925128706, alpha is 12.0\n",
      "Epoch 128, Loss G: 0.2933, Loss D: 1.6894\n",
      "epsilon is 2.3036511437532874, alpha is 12.0\n",
      "Epoch 129, Loss G: 0.3018, Loss D: 1.6792\n",
      "epsilon is 2.313383794993704, alpha is 12.0\n",
      "Epoch 130, Loss G: 0.3028, Loss D: 1.6791\n",
      "epsilon is 2.323116446234121, alpha is 12.0\n",
      "Epoch 131, Loss G: 0.2957, Loss D: 1.6766\n",
      "epsilon is 2.3328490974745377, alpha is 12.0\n",
      "Epoch 132, Loss G: 0.3028, Loss D: 1.6789\n",
      "epsilon is 2.3425817487149545, alpha is 12.0\n",
      "Epoch 133, Loss G: 0.2983, Loss D: 1.6854\n",
      "epsilon is 2.3523143999553713, alpha is 12.0\n",
      "Epoch 134, Loss G: 0.2815, Loss D: 1.7280\n",
      "epsilon is 2.362047051195788, alpha is 12.0\n",
      "Epoch 135, Loss G: 0.2797, Loss D: 1.7503\n",
      "epsilon is 2.371779702436205, alpha is 12.0\n",
      "Epoch 136, Loss G: 0.2710, Loss D: 1.7401\n",
      "epsilon is 2.3815123536766216, alpha is 12.0\n",
      "Epoch 137, Loss G: 0.2602, Loss D: 1.7654\n",
      "epsilon is 2.3912450049170384, alpha is 12.0\n",
      "Epoch 138, Loss G: 0.2599, Loss D: 1.7662\n",
      "epsilon is 2.400977656157455, alpha is 12.0\n",
      "Epoch 139, Loss G: 0.2598, Loss D: 1.7815\n",
      "epsilon is 2.410710307397872, alpha is 12.0\n",
      "Epoch 140, Loss G: 0.2640, Loss D: 1.7457\n",
      "epsilon is 2.4204429586382887, alpha is 12.0\n",
      "Epoch 141, Loss G: 0.2604, Loss D: 1.7730\n",
      "epsilon is 2.4301756098787055, alpha is 12.0\n",
      "Epoch 142, Loss G: 0.2629, Loss D: 1.7795\n",
      "epsilon is 2.4399082611191223, alpha is 12.0\n",
      "Epoch 143, Loss G: 0.2654, Loss D: 1.7587\n",
      "epsilon is 2.4496409123595386, alpha is 12.0\n",
      "Epoch 144, Loss G: 0.2589, Loss D: 1.7935\n",
      "epsilon is 2.4593735635999554, alpha is 12.0\n",
      "Epoch 145, Loss G: 0.2578, Loss D: 1.7641\n",
      "epsilon is 2.468268791783387, alpha is 10.9\n",
      "Epoch 146, Loss G: 0.2559, Loss D: 1.7767\n",
      "epsilon is 2.4771012838923436, alpha is 10.9\n",
      "Epoch 147, Loss G: 0.2599, Loss D: 1.7878\n",
      "epsilon is 2.4859337760013007, alpha is 10.9\n",
      "Epoch 148, Loss G: 0.2568, Loss D: 1.7836\n",
      "epsilon is 2.4947662681102574, alpha is 10.9\n",
      "Epoch 149, Loss G: 0.2578, Loss D: 1.7791\n",
      "epsilon is 2.503598760219214, alpha is 10.9\n",
      "Epoch 150, Loss G: 0.2531, Loss D: 1.8142\n",
      "epsilon is 2.512431252328171, alpha is 10.9\n",
      "Epoch 151, Loss G: 0.2513, Loss D: 1.7943\n",
      "epsilon is 2.5212637444371278, alpha is 10.9\n",
      "Epoch 152, Loss G: 0.2480, Loss D: 1.8255\n",
      "epsilon is 2.5300962365460844, alpha is 10.9\n",
      "Epoch 153, Loss G: 0.2370, Loss D: 1.8896\n",
      "epsilon is 2.5389287286550415, alpha is 10.9\n",
      "Epoch 154, Loss G: 0.2301, Loss D: 1.8778\n",
      "epsilon is 2.547761220763998, alpha is 10.9\n",
      "Epoch 155, Loss G: 0.2297, Loss D: 1.8879\n",
      "epsilon is 2.556593712872955, alpha is 10.9\n",
      "Epoch 156, Loss G: 0.2300, Loss D: 1.8860\n",
      "epsilon is 2.565426204981912, alpha is 10.9\n",
      "Epoch 157, Loss G: 0.2218, Loss D: 1.8852\n",
      "epsilon is 2.5742586970908685, alpha is 10.9\n",
      "Epoch 158, Loss G: 0.2188, Loss D: 1.9053\n",
      "epsilon is 2.583091189199825, alpha is 10.9\n",
      "Epoch 159, Loss G: 0.2143, Loss D: 1.9273\n",
      "epsilon is 2.5919236813087823, alpha is 10.9\n",
      "Epoch 160, Loss G: 0.2154, Loss D: 1.9025\n",
      "epsilon is 2.600756173417739, alpha is 10.9\n",
      "Epoch 161, Loss G: 0.2223, Loss D: 1.8839\n",
      "epsilon is 2.6095886655266956, alpha is 10.9\n",
      "Epoch 162, Loss G: 0.2197, Loss D: 1.8775\n",
      "epsilon is 2.6184211576356526, alpha is 10.9\n",
      "Epoch 163, Loss G: 0.2193, Loss D: 1.8767\n",
      "epsilon is 2.6272046232198916, alpha is 10.8\n",
      "Epoch 164, Loss G: 0.2284, Loss D: 1.9001\n",
      "epsilon is 2.6359553636969846, alpha is 10.8\n",
      "Epoch 165, Loss G: 0.2220, Loss D: 1.8646\n",
      "epsilon is 2.6447061041740776, alpha is 10.8\n",
      "Epoch 166, Loss G: 0.2201, Loss D: 1.8720\n",
      "epsilon is 2.6534465853263964, alpha is 10.7\n",
      "Epoch 167, Loss G: 0.2230, Loss D: 1.8561\n",
      "epsilon is 2.66211558765494, alpha is 10.7\n",
      "Epoch 168, Loss G: 0.2217, Loss D: 1.8954\n",
      "epsilon is 2.6707845899834832, alpha is 10.7\n",
      "Epoch 169, Loss G: 0.2116, Loss D: 1.9561\n",
      "epsilon is 2.6794535923120266, alpha is 10.7\n",
      "Epoch 170, Loss G: 0.2066, Loss D: 1.9409\n",
      "epsilon is 2.6880784585701423, alpha is 10.6\n",
      "Epoch 171, Loss G: 0.2058, Loss D: 1.9720\n",
      "epsilon is 2.696665736228968, alpha is 10.6\n",
      "Epoch 172, Loss G: 0.2004, Loss D: 1.9685\n",
      "epsilon is 2.705253013887793, alpha is 10.6\n",
      "Epoch 173, Loss G: 0.2020, Loss D: 1.9323\n",
      "epsilon is 2.713840291546618, alpha is 10.6\n",
      "Epoch 174, Loss G: 0.2022, Loss D: 1.9512\n",
      "epsilon is 2.722359048878536, alpha is 10.5\n",
      "Epoch 175, Loss G: 0.2075, Loss D: 1.9255\n",
      "epsilon is 2.730864615341999, alpha is 10.5\n",
      "Epoch 176, Loss G: 0.2109, Loss D: 1.9261\n",
      "epsilon is 2.739370181805463, alpha is 10.5\n",
      "Epoch 177, Loss G: 0.2051, Loss D: 1.9656\n",
      "epsilon is 2.74787443941357, alpha is 10.4\n",
      "Epoch 178, Loss G: 0.2049, Loss D: 1.9371\n",
      "epsilon is 2.756298308151558, alpha is 10.4\n",
      "Epoch 179, Loss G: 0.2027, Loss D: 1.9568\n",
      "epsilon is 2.7647221768895465, alpha is 10.4\n",
      "Epoch 180, Loss G: 0.2036, Loss D: 1.9331\n",
      "epsilon is 2.7731460456275348, alpha is 10.4\n",
      "Epoch 181, Loss G: 0.2070, Loss D: 1.9551\n",
      "epsilon is 2.7815644313658536, alpha is 10.3\n",
      "Epoch 182, Loss G: 0.1986, Loss D: 1.9597\n",
      "epsilon is 2.7899066158437806, alpha is 10.3\n",
      "Epoch 183, Loss G: 0.2066, Loss D: 1.9295\n",
      "epsilon is 2.7982488003217085, alpha is 10.3\n",
      "Epoch 184, Loss G: 0.1987, Loss D: 1.9933\n",
      "epsilon is 2.8065909847996355, alpha is 10.3\n",
      "Epoch 185, Loss G: 0.2044, Loss D: 1.9640\n",
      "epsilon is 2.814933169277563, alpha is 10.3\n",
      "Epoch 186, Loss G: 0.2017, Loss D: 1.9365\n",
      "epsilon is 2.8231948024768827, alpha is 10.2\n",
      "Epoch 187, Loss G: 0.2066, Loss D: 1.9495\n",
      "epsilon is 2.8314553161556986, alpha is 10.2\n",
      "Epoch 188, Loss G: 0.1948, Loss D: 1.9425\n",
      "epsilon is 2.8397158298345135, alpha is 10.2\n",
      "Epoch 189, Loss G: 0.2088, Loss D: 1.9844\n",
      "epsilon is 2.8479763435133294, alpha is 10.2\n",
      "Epoch 190, Loss G: 0.1953, Loss D: 2.0264\n",
      "epsilon is 2.8561741747149854, alpha is 10.1\n",
      "Epoch 191, Loss G: 0.1930, Loss D: 1.9900\n",
      "epsilon is 2.8643530310511722, alpha is 10.1\n",
      "Epoch 192, Loss G: 0.1999, Loss D: 1.9751\n",
      "epsilon is 2.872531887387359, alpha is 10.1\n",
      "Epoch 193, Loss G: 0.2056, Loss D: 1.9491\n",
      "epsilon is 2.880710743723546, alpha is 10.1\n",
      "Epoch 194, Loss G: 0.2043, Loss D: 1.9911\n",
      "epsilon is 2.888856542128456, alpha is 10.0\n",
      "Epoch 195, Loss G: 0.2058, Loss D: 1.9751\n",
      "epsilon is 2.896953754574036, alpha is 10.0\n",
      "Epoch 196, Loss G: 0.1988, Loss D: 1.9946\n",
      "epsilon is 2.905050967019616, alpha is 10.0\n",
      "Epoch 197, Loss G: 0.2019, Loss D: 2.0071\n",
      "epsilon is 2.9131481794651966, alpha is 10.0\n",
      "Epoch 198, Loss G: 0.1776, Loss D: 2.0555\n",
      "epsilon is 2.921245391910776, alpha is 10.0\n",
      "Epoch 199, Loss G: 0.1909, Loss D: 2.0323\n",
      "epsilon is 2.9292698277795344, alpha is 9.9\n",
      "Epoch 200, Loss G: 0.1836, Loss D: 2.0447\n",
      "epsilon is 2.937285409782066, alpha is 9.9\n",
      "Epoch 201, Loss G: 0.1843, Loss D: 2.0373\n",
      "epsilon is 2.9453009917845985, alpha is 9.9\n",
      "Epoch 202, Loss G: 0.1824, Loss D: 2.0775\n",
      "epsilon is 2.9533165737871307, alpha is 9.9\n",
      "Epoch 203, Loss G: 0.1821, Loss D: 2.0661\n",
      "epsilon is 2.9613141537645884, alpha is 9.8\n",
      "Epoch 204, Loss G: 0.1859, Loss D: 2.0397\n",
      "epsilon is 2.969248118767176, alpha is 9.8\n",
      "Epoch 205, Loss G: 0.1823, Loss D: 2.0037\n",
      "epsilon is 2.977182083769764, alpha is 9.8\n",
      "Epoch 206, Loss G: 0.1917, Loss D: 2.0320\n",
      "epsilon is 2.9851160487723516, alpha is 9.8\n",
      "Epoch 207, Loss G: 0.1955, Loss D: 1.9879\n",
      "epsilon is 2.993050013774939, alpha is 9.8\n",
      "Epoch 208, Loss G: 0.1970, Loss D: 1.9691\n",
      "epsilon is 3.000952591784167, alpha is 9.7\n",
      "Epoch 209, Loss G: 0.2000, Loss D: 1.9426\n",
      "epsilon is 3.0088049532254564, alpha is 9.7\n",
      "Epoch 210, Loss G: 0.2051, Loss D: 1.9398\n",
      "epsilon is 3.0166573146667455, alpha is 9.7\n",
      "Epoch 211, Loss G: 0.2038, Loss D: 1.9322\n",
      "epsilon is 3.0245096761080354, alpha is 9.7\n",
      "Epoch 212, Loss G: 0.2074, Loss D: 1.9372\n",
      "epsilon is 3.0323620375493245, alpha is 9.7\n",
      "Epoch 213, Loss G: 0.2105, Loss D: 1.9312\n",
      "epsilon is 3.0401837276516326, alpha is 9.6\n",
      "Epoch 214, Loss G: 0.2090, Loss D: 1.9466\n",
      "epsilon is 3.0479544989658183, alpha is 9.6\n",
      "Epoch 215, Loss G: 0.2130, Loss D: 1.9135\n",
      "epsilon is 3.055725270280004, alpha is 9.6\n",
      "Epoch 216, Loss G: 0.2132, Loss D: 1.9497\n",
      "epsilon is 3.0634960415941896, alpha is 9.6\n",
      "Epoch 217, Loss G: 0.2022, Loss D: 1.9433\n",
      "epsilon is 3.0712668129083753, alpha is 9.6\n",
      "Epoch 218, Loss G: 0.2004, Loss D: 1.9654\n",
      "epsilon is 3.079022396327727, alpha is 9.5\n",
      "Epoch 219, Loss G: 0.1990, Loss D: 2.0088\n",
      "epsilon is 3.086711590944551, alpha is 9.5\n",
      "Epoch 220, Loss G: 0.1953, Loss D: 1.9770\n",
      "epsilon is 3.094400785561374, alpha is 9.5\n",
      "Epoch 221, Loss G: 0.1923, Loss D: 1.9901\n",
      "epsilon is 3.102089980178198, alpha is 9.5\n",
      "Epoch 222, Loss G: 0.1951, Loss D: 1.9774\n",
      "epsilon is 3.109779174795021, alpha is 9.5\n",
      "Epoch 223, Loss G: 0.1929, Loss D: 1.9751\n",
      "epsilon is 3.1174683694118452, alpha is 9.5\n",
      "Epoch 224, Loss G: 0.1938, Loss D: 2.0154\n",
      "epsilon is 3.1250917714325563, alpha is 9.4\n",
      "Epoch 225, Loss G: 0.2028, Loss D: 1.9745\n",
      "epsilon is 3.1326994027773116, alpha is 9.4\n",
      "Epoch 226, Loss G: 0.2002, Loss D: 1.9678\n",
      "epsilon is 3.140307034122067, alpha is 9.4\n",
      "Epoch 227, Loss G: 0.2081, Loss D: 1.9443\n",
      "epsilon is 3.147914665466822, alpha is 9.4\n",
      "Epoch 228, Loss G: 0.1964, Loss D: 1.9821\n",
      "epsilon is 3.1555222968115775, alpha is 9.4\n",
      "Epoch 229, Loss G: 0.1926, Loss D: 1.9856\n",
      "epsilon is 3.163111333113673, alpha is 9.3\n",
      "Epoch 230, Loss G: 0.1962, Loss D: 1.9964\n",
      "epsilon is 3.1706374146072074, alpha is 9.3\n",
      "Epoch 231, Loss G: 0.1519, Loss D: 2.2273\n",
      "epsilon is 3.1781634961007423, alpha is 9.3\n",
      "Epoch 232, Loss G: 0.1688, Loss D: 2.1367\n",
      "epsilon is 3.1856895775942773, alpha is 9.3\n",
      "Epoch 233, Loss G: 0.1799, Loss D: 2.0308\n",
      "epsilon is 3.1932156590878114, alpha is 9.3\n",
      "Epoch 234, Loss G: 0.1742, Loss D: 2.0974\n",
      "epsilon is 3.2007417405813463, alpha is 9.3\n",
      "Epoch 235, Loss G: 0.1746, Loss D: 2.0589\n",
      "epsilon is 3.208231910423759, alpha is 9.2\n",
      "Epoch 236, Loss G: 0.1852, Loss D: 2.0422\n",
      "epsilon is 3.2156764554824764, alpha is 9.2\n",
      "Epoch 237, Loss G: 0.1887, Loss D: 2.0104\n",
      "epsilon is 3.2231210005411937, alpha is 9.2\n",
      "Epoch 238, Loss G: 0.1959, Loss D: 2.0127\n",
      "epsilon is 3.2305655455999114, alpha is 9.2\n",
      "Epoch 239, Loss G: 0.1868, Loss D: 2.0038\n",
      "epsilon is 3.238010090658629, alpha is 9.2\n",
      "Epoch 240, Loss G: 0.1909, Loss D: 1.9793\n",
      "epsilon is 3.245454635717347, alpha is 9.2\n",
      "Epoch 241, Loss G: 0.1907, Loss D: 2.0395\n",
      "epsilon is 3.2528638480680554, alpha is 9.1\n",
      "Epoch 242, Loss G: 0.1871, Loss D: 2.0258\n",
      "epsilon is 3.260226870103917, alpha is 9.1\n",
      "Epoch 243, Loss G: 0.1812, Loss D: 2.0675\n",
      "epsilon is 3.2675898921397795, alpha is 9.1\n",
      "Epoch 244, Loss G: 0.1794, Loss D: 2.0180\n",
      "epsilon is 3.2749529141756417, alpha is 9.1\n",
      "Epoch 245, Loss G: 0.1864, Loss D: 2.0640\n",
      "epsilon is 3.2823159362115035, alpha is 9.1\n",
      "Epoch 246, Loss G: 0.1830, Loss D: 2.0203\n",
      "epsilon is 3.289678958247366, alpha is 9.1\n",
      "Epoch 247, Loss G: 0.1773, Loss D: 2.0447\n",
      "epsilon is 3.2970260220141356, alpha is 9.0\n",
      "Epoch 248, Loss G: 0.1830, Loss D: 2.0357\n",
      "epsilon is 3.3043075344346655, alpha is 9.0\n",
      "Epoch 249, Loss G: 0.1734, Loss D: 2.0849\n",
      "epsilon is 3.311589046855195, alpha is 9.0\n",
      "Epoch 250, Loss G: 0.1831, Loss D: 2.0801\n",
      "epsilon is 3.3188705592757244, alpha is 9.0\n",
      "Epoch 251, Loss G: 0.1800, Loss D: 2.0319\n",
      "epsilon is 3.3261520716962543, alpha is 9.0\n",
      "Epoch 252, Loss G: 0.1743, Loss D: 2.1045\n",
      "epsilon is 3.333433584116784, alpha is 9.0\n",
      "Epoch 253, Loss G: 0.1818, Loss D: 2.0236\n",
      "epsilon is 3.340715096537314, alpha is 9.0\n",
      "Epoch 254, Loss G: 0.1875, Loss D: 2.0252\n",
      "epsilon is 3.347938281956484, alpha is 8.9\n",
      "Epoch 255, Loss G: 0.1830, Loss D: 2.0549\n",
      "epsilon is 3.355138298164765, alpha is 8.9\n",
      "Epoch 256, Loss G: 0.1910, Loss D: 2.0634\n",
      "epsilon is 3.3623383143730456, alpha is 8.9\n",
      "Epoch 257, Loss G: 0.1888, Loss D: 2.0169\n",
      "epsilon is 3.3695383305813262, alpha is 8.9\n",
      "Epoch 258, Loss G: 0.1883, Loss D: 2.0271\n",
      "epsilon is 3.3767383467896073, alpha is 8.9\n",
      "Epoch 259, Loss G: 0.1883, Loss D: 1.9950\n",
      "epsilon is 3.3839383629978883, alpha is 8.9\n",
      "Epoch 260, Loss G: 0.1878, Loss D: 2.0123\n",
      "epsilon is 3.391138379206169, alpha is 8.9\n",
      "Epoch 261, Loss G: 0.1762, Loss D: 2.0594\n",
      "epsilon is 3.398258499138359, alpha is 8.8\n",
      "Epoch 262, Loss G: 0.1815, Loss D: 1.9990\n",
      "epsilon is 3.405377032533042, alpha is 8.8\n",
      "Epoch 263, Loss G: 0.1896, Loss D: 2.0214\n",
      "epsilon is 3.4124955659277245, alpha is 8.8\n",
      "Epoch 264, Loss G: 0.1694, Loss D: 2.0955\n",
      "epsilon is 3.419614099322408, alpha is 8.8\n",
      "Epoch 265, Loss G: 0.1792, Loss D: 2.0358\n",
      "epsilon is 3.42673263271709, alpha is 8.8\n",
      "Epoch 266, Loss G: 0.1659, Loss D: 2.1152\n",
      "epsilon is 3.433851166111773, alpha is 8.8\n",
      "Epoch 267, Loss G: 0.1738, Loss D: 2.1210\n",
      "epsilon is 3.440969699506456, alpha is 8.8\n",
      "Epoch 268, Loss G: 0.1724, Loss D: 2.0882\n",
      "epsilon is 3.4480086533626415, alpha is 8.7\n",
      "Epoch 269, Loss G: 0.1827, Loss D: 2.0738\n",
      "epsilon is 3.4550457173379425, alpha is 8.7\n",
      "Epoch 270, Loss G: 0.1758, Loss D: 2.0526\n",
      "epsilon is 3.462082781313244, alpha is 8.7\n",
      "Epoch 271, Loss G: 0.1832, Loss D: 2.0414\n",
      "epsilon is 3.4691198452885454, alpha is 8.7\n",
      "Epoch 272, Loss G: 0.1753, Loss D: 2.0608\n",
      "epsilon is 3.4761569092638465, alpha is 8.7\n",
      "Epoch 273, Loss G: 0.1848, Loss D: 2.0440\n",
      "epsilon is 3.483193973239148, alpha is 8.7\n",
      "Epoch 274, Loss G: 0.1805, Loss D: 2.0350\n",
      "epsilon is 3.4902310372144494, alpha is 8.7\n",
      "Epoch 275, Loss G: 0.1879, Loss D: 2.0316\n",
      "epsilon is 3.497211883240985, alpha is 8.6\n",
      "Epoch 276, Loss G: 0.1765, Loss D: 2.0674\n",
      "epsilon is 3.5041674911866934, alpha is 8.6\n",
      "Epoch 277, Loss G: 0.1796, Loss D: 2.0955\n",
      "epsilon is 3.511123099132402, alpha is 8.6\n",
      "Epoch 278, Loss G: 0.1781, Loss D: 2.0459\n",
      "epsilon is 3.5180787070781103, alpha is 8.6\n",
      "Epoch 279, Loss G: 0.1844, Loss D: 2.0391\n",
      "epsilon is 3.5250343150238193, alpha is 8.6\n",
      "Epoch 280, Loss G: 0.1905, Loss D: 2.0206\n",
      "epsilon is 3.5319899229695277, alpha is 8.6\n",
      "Epoch 281, Loss G: 0.1989, Loss D: 1.9849\n",
      "epsilon is 3.5389455309152367, alpha is 8.6\n",
      "Epoch 282, Loss G: 0.1926, Loss D: 2.0330\n",
      "epsilon is 3.545892564307625, alpha is 8.5\n",
      "Epoch 283, Loss G: 0.1812, Loss D: 2.0416\n",
      "epsilon is 3.552766729609101, alpha is 8.5\n",
      "Epoch 284, Loss G: 0.1774, Loss D: 2.0369\n",
      "epsilon is 3.5596408949105767, alpha is 8.5\n",
      "Epoch 285, Loss G: 0.1825, Loss D: 2.1013\n",
      "epsilon is 3.5665150602120526, alpha is 8.5\n",
      "Epoch 286, Loss G: 0.1740, Loss D: 2.0785\n",
      "epsilon is 3.573389225513529, alpha is 8.5\n",
      "Epoch 287, Loss G: 0.1792, Loss D: 2.0650\n",
      "epsilon is 3.5802633908150048, alpha is 8.5\n",
      "Epoch 288, Loss G: 0.1833, Loss D: 2.0707\n",
      "epsilon is 3.5871375561164807, alpha is 8.5\n",
      "Epoch 289, Loss G: 0.1883, Loss D: 2.0095\n",
      "epsilon is 3.5940117214179566, alpha is 8.5\n",
      "Epoch 290, Loss G: 0.1920, Loss D: 2.0154\n",
      "epsilon is 3.6008691295626627, alpha is 8.4\n",
      "Epoch 291, Loss G: 0.1871, Loss D: 2.0192\n",
      "epsilon is 3.6076618656008392, alpha is 8.4\n",
      "Epoch 292, Loss G: 0.1957, Loss D: 2.0184\n",
      "epsilon is 3.614454601639016, alpha is 8.4\n",
      "Epoch 293, Loss G: 0.1842, Loss D: 2.0531\n",
      "epsilon is 3.621247337677193, alpha is 8.4\n",
      "Epoch 294, Loss G: 0.1791, Loss D: 2.0953\n",
      "epsilon is 3.6280400737153697, alpha is 8.4\n",
      "Epoch 295, Loss G: 0.1848, Loss D: 2.0419\n",
      "epsilon is 3.6348328097535463, alpha is 8.4\n",
      "Epoch 296, Loss G: 0.1743, Loss D: 2.0139\n",
      "epsilon is 3.6416255457917233, alpha is 8.4\n",
      "Epoch 297, Loss G: 0.1745, Loss D: 2.0792\n",
      "epsilon is 3.6484182818299002, alpha is 8.4\n",
      "Epoch 298, Loss G: 0.1863, Loss D: 2.0504\n",
      "epsilon is 3.6552110178680763, alpha is 8.4\n",
      "Epoch 299, Loss G: 0.1731, Loss D: 2.0907\n",
      "epsilon is 3.6619244412458656, alpha is 8.3\n",
      "Epoch 300, Loss G: 0.1812, Loss D: 2.0655\n",
      "epsilon is 3.6686357613972542, alpha is 8.3\n",
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 1263.5538 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 24929 rows (same as raw) in 2.5093 sec.\n",
      "Now is Postprocessor with default-smartnoise...\n",
      "Now is Evaluator with anonymeter-singlingout_univariate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.0009585236406264672, baseline = 0.0009585236406264672. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is 20240322_exp7[Report]_anonymeter-singlingout_univariate_[global] save to csv...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with anonymeter-linkability...\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is 20240322_exp7[Report]_anonymeter-linkability_[global] save to csv...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with anonymeter-inference...\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is 20240322_exp7[Report]_anonymeter-inference_[global] save to csv...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with sdmetrics-diag...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|| 13/13 [00:00<00:00, 529.89it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|| 1/1 [00:00<00:00, 528.92it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is 20240321_exp7[Report]_sdmetrics-diag_[columnwise] save to csv...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with sdmetrics-qual...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|| 13/13 [00:00<00:00, 196.58it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|| 78/78 [00:03<00:00, 24.45it/s]\n",
      "\n",
      "Overall Score: 54.25%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 63.96%\n",
      "- Column Pair Trends: 44.53%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is 20240321_exp7[Report]_sdmetrics-qual_[columnwise] save to csv...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Regression: 100%|| 5/5 [02:04<00:00, 24.95s/it]\n",
      "Regression: 100%|| 5/5 [01:17<00:00, 15.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is 20240321_exp7[Report]_automl-regression_[global] save to csv...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classification: 100%|| 5/5 [05:10<00:00, 62.07s/it]\n",
      "Classification: 100%|| 5/5 [01:10<00:00, 14.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is 20240321_exp7[Report]_automl-classification_[global] save to csv...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering: 100%|| 5/5 [00:10<00:00,  2.16s/it]\n",
      "Clustering: 100%|| 5/5 [00:06<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is 20240321_exp7[Report]_automl-cluster_[global] save to csv...\n",
      "Now is Synthesizer with smartnoise-dpctgan5...\n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1352: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.6622, Loss D: 1.4060\n",
      "epsilon is 0.1621052371810809, alpha is 63.0\n",
      "Epoch 2, Loss G: 0.6886, Loss D: 1.3912\n",
      "epsilon is 0.2154777899194668, alpha is 63.0\n",
      "Epoch 3, Loss G: 0.6900, Loss D: 1.3844\n",
      "epsilon is 0.2688503426578527, alpha is 63.0\n",
      "Epoch 4, Loss G: 0.6765, Loss D: 1.3934\n",
      "epsilon is 0.32222289539623855, alpha is 63.0\n",
      "Epoch 5, Loss G: 0.6683, Loss D: 1.3955\n",
      "epsilon is 0.37341275087699954, alpha is 57.0\n",
      "Epoch 6, Loss G: 0.6680, Loss D: 1.3927\n",
      "epsilon is 0.41901084464897975, alpha is 52.0\n",
      "Epoch 7, Loss G: 0.6620, Loss D: 1.3996\n",
      "epsilon is 0.46047921301009653, alpha is 48.0\n",
      "Epoch 8, Loss G: 0.6571, Loss D: 1.3975\n",
      "epsilon is 0.49879327014201535, alpha is 44.0\n",
      "Epoch 9, Loss G: 0.6550, Loss D: 1.3917\n",
      "epsilon is 0.5346025437355053, alpha is 42.0\n",
      "Epoch 10, Loss G: 0.6468, Loss D: 1.4035\n",
      "epsilon is 0.5684014701443807, alpha is 40.0\n",
      "Epoch 11, Loss G: 0.6500, Loss D: 1.3946\n",
      "epsilon is 0.6004394015460149, alpha is 38.0\n",
      "Epoch 12, Loss G: 0.6490, Loss D: 1.3996\n",
      "epsilon is 0.6310196395077151, alpha is 36.0\n",
      "Epoch 13, Loss G: 0.6491, Loss D: 1.3927\n",
      "epsilon is 0.6603460122722166, alpha is 35.0\n",
      "Epoch 14, Loss G: 0.6419, Loss D: 1.3981\n",
      "epsilon is 0.6886041442379658, alpha is 34.0\n",
      "Epoch 15, Loss G: 0.6461, Loss D: 1.3934\n",
      "epsilon is 0.7157875852128055, alpha is 32.0\n",
      "Epoch 16, Loss G: 0.6416, Loss D: 1.3954\n",
      "epsilon is 0.7421024871575375, alpha is 31.0\n",
      "Epoch 17, Loss G: 0.6459, Loss D: 1.3956\n",
      "epsilon is 0.767647100288211, alpha is 31.0\n",
      "Epoch 18, Loss G: 0.6364, Loss D: 1.3953\n",
      "epsilon is 0.7923548741192558, alpha is 30.0\n",
      "Epoch 19, Loss G: 0.6394, Loss D: 1.3993\n",
      "epsilon is 0.816405988490787, alpha is 29.0\n",
      "Epoch 20, Loss G: 0.6392, Loss D: 1.3976\n",
      "epsilon is 0.8399196285202444, alpha is 28.0\n",
      "Epoch 21, Loss G: 0.6351, Loss D: 1.3985\n",
      "epsilon is 0.8629338200947815, alpha is 28.0\n",
      "Epoch 22, Loss G: 0.6292, Loss D: 1.3976\n",
      "epsilon is 0.8852065804317902, alpha is 27.0\n",
      "Epoch 23, Loss G: 0.6256, Loss D: 1.4014\n",
      "epsilon is 0.90723938148027, alpha is 26.0\n",
      "Epoch 24, Loss G: 0.6170, Loss D: 1.3945\n",
      "epsilon is 0.9285737784052924, alpha is 26.0\n",
      "Epoch 25, Loss G: 0.6097, Loss D: 1.4003\n",
      "epsilon is 0.9497140109656055, alpha is 25.0\n",
      "Epoch 26, Loss G: 0.6083, Loss D: 1.4024\n",
      "epsilon is 0.970210641801423, alpha is 25.0\n",
      "Epoch 27, Loss G: 0.6031, Loss D: 1.4070\n",
      "epsilon is 0.9906783712641867, alpha is 24.0\n",
      "Epoch 28, Loss G: 0.6004, Loss D: 1.4006\n",
      "epsilon is 1.0103386503711411, alpha is 24.0\n",
      "Epoch 29, Loss G: 0.5965, Loss D: 1.4043\n",
      "epsilon is 1.0299989294780953, alpha is 24.0\n",
      "Epoch 30, Loss G: 0.6020, Loss D: 1.4016\n",
      "epsilon is 1.0492187527163617, alpha is 23.0\n",
      "Epoch 31, Loss G: 0.5916, Loss D: 1.4045\n",
      "epsilon is 1.0680440896397936, alpha is 23.0\n",
      "Epoch 32, Loss G: 0.5924, Loss D: 1.4102\n",
      "epsilon is 1.0868694265632255, alpha is 23.0\n",
      "Epoch 33, Loss G: 0.5921, Loss D: 1.4042\n",
      "epsilon is 1.1051527178449858, alpha is 22.0\n",
      "Epoch 34, Loss G: 0.5876, Loss D: 1.4057\n",
      "epsilon is 1.1231445173410244, alpha is 22.0\n",
      "Epoch 35, Loss G: 0.5855, Loss D: 1.4008\n",
      "epsilon is 1.141136316837063, alpha is 22.0\n",
      "Epoch 36, Loss G: 0.5844, Loss D: 1.4054\n",
      "epsilon is 1.158855915839736, alpha is 21.0\n",
      "Epoch 37, Loss G: 0.5765, Loss D: 1.4092\n",
      "epsilon is 1.1760155779008916, alpha is 21.0\n",
      "Epoch 38, Loss G: 0.5776, Loss D: 1.4097\n",
      "epsilon is 1.1931752399620472, alpha is 21.0\n",
      "Epoch 39, Loss G: 0.5823, Loss D: 1.4117\n",
      "epsilon is 1.2103349020232026, alpha is 21.0\n",
      "Epoch 40, Loss G: 0.5745, Loss D: 1.4050\n",
      "epsilon is 1.2271108084042925, alpha is 20.0\n",
      "Epoch 41, Loss G: 0.5745, Loss D: 1.4105\n",
      "epsilon is 1.2434397282848608, alpha is 20.0\n",
      "Epoch 42, Loss G: 0.5707, Loss D: 1.4136\n",
      "epsilon is 1.259768648165429, alpha is 20.0\n",
      "Epoch 43, Loss G: 0.5736, Loss D: 1.4121\n",
      "epsilon is 1.2760975680459974, alpha is 20.0\n",
      "Epoch 44, Loss G: 0.5765, Loss D: 1.4033\n",
      "epsilon is 1.2924264879265657, alpha is 20.0\n",
      "Epoch 45, Loss G: 0.5720, Loss D: 1.4065\n",
      "epsilon is 1.3079827600088128, alpha is 19.0\n",
      "Epoch 46, Loss G: 0.5751, Loss D: 1.4093\n",
      "epsilon is 1.323482328250091, alpha is 19.0\n",
      "Epoch 47, Loss G: 0.5730, Loss D: 1.4053\n",
      "epsilon is 1.3389818964913687, alpha is 19.0\n",
      "Epoch 48, Loss G: 0.5772, Loss D: 1.4107\n",
      "epsilon is 1.3544814647326469, alpha is 19.0\n",
      "Epoch 49, Loss G: 0.5669, Loss D: 1.4093\n",
      "epsilon is 1.3699810329739246, alpha is 19.0\n",
      "Epoch 50, Loss G: 0.5690, Loss D: 1.4145\n",
      "epsilon is 1.3850035674822065, alpha is 18.0\n",
      "Epoch 51, Loss G: 0.5659, Loss D: 1.4165\n",
      "epsilon is 1.3996751699375183, alpha is 18.0\n",
      "Epoch 52, Loss G: 0.5577, Loss D: 1.4236\n",
      "epsilon is 1.4143467723928305, alpha is 18.0\n",
      "Epoch 53, Loss G: 0.5531, Loss D: 1.4110\n",
      "epsilon is 1.4290183748481424, alpha is 18.0\n",
      "Epoch 54, Loss G: 0.5468, Loss D: 1.4171\n",
      "epsilon is 1.4436899773034544, alpha is 18.0\n",
      "Epoch 55, Loss G: 0.5508, Loss D: 1.4190\n",
      "epsilon is 1.4583615797587666, alpha is 18.0\n",
      "Epoch 56, Loss G: 0.5400, Loss D: 1.4171\n",
      "epsilon is 1.4728805636486564, alpha is 17.0\n",
      "Epoch 57, Loss G: 0.5393, Loss D: 1.4253\n",
      "epsilon is 1.4867255815082014, alpha is 17.0\n",
      "Epoch 58, Loss G: 0.5427, Loss D: 1.4215\n",
      "epsilon is 1.5005705993677465, alpha is 17.0\n",
      "Epoch 59, Loss G: 0.5405, Loss D: 1.4184\n",
      "epsilon is 1.5144156172272918, alpha is 17.0\n",
      "Epoch 60, Loss G: 0.5422, Loss D: 1.4252\n",
      "epsilon is 1.528260635086837, alpha is 17.0\n",
      "Epoch 61, Loss G: 0.5301, Loss D: 1.4193\n",
      "epsilon is 1.5421056529463821, alpha is 17.0\n",
      "Epoch 62, Loss G: 0.5328, Loss D: 1.4256\n",
      "epsilon is 1.5559506708059274, alpha is 17.0\n",
      "Epoch 63, Loss G: 0.5244, Loss D: 1.4368\n",
      "epsilon is 1.5697956886654725, alpha is 17.0\n",
      "Epoch 64, Loss G: 0.5198, Loss D: 1.4340\n",
      "epsilon is 1.5832489554301077, alpha is 16.0\n",
      "Epoch 65, Loss G: 0.5121, Loss D: 1.4420\n",
      "epsilon is 1.5962687652456178, alpha is 16.0\n",
      "Epoch 66, Loss G: 0.4907, Loss D: 1.4628\n",
      "epsilon is 1.6092885750611279, alpha is 16.0\n",
      "Epoch 67, Loss G: 0.5009, Loss D: 1.4473\n",
      "epsilon is 1.622308384876638, alpha is 16.0\n",
      "Epoch 68, Loss G: 0.4965, Loss D: 1.4511\n",
      "epsilon is 1.635328194692148, alpha is 16.0\n",
      "Epoch 69, Loss G: 0.4926, Loss D: 1.4409\n",
      "epsilon is 1.6483480045076582, alpha is 16.0\n",
      "Epoch 70, Loss G: 0.4844, Loss D: 1.4458\n",
      "epsilon is 1.6613678143231683, alpha is 16.0\n",
      "Epoch 71, Loss G: 0.4836, Loss D: 1.4497\n",
      "epsilon is 1.6743876241386784, alpha is 16.0\n",
      "Epoch 72, Loss G: 0.4852, Loss D: 1.4484\n",
      "epsilon is 1.6874074339541885, alpha is 16.0\n",
      "Epoch 73, Loss G: 0.4822, Loss D: 1.4515\n",
      "epsilon is 1.7003765494338765, alpha is 15.0\n",
      "Epoch 74, Loss G: 0.4784, Loss D: 1.4551\n",
      "epsilon is 1.7125725231430986, alpha is 15.0\n",
      "Epoch 75, Loss G: 0.4830, Loss D: 1.4567\n",
      "epsilon is 1.7247684968523207, alpha is 15.0\n",
      "Epoch 76, Loss G: 0.4842, Loss D: 1.4493\n",
      "epsilon is 1.7369644705615428, alpha is 15.0\n",
      "Epoch 77, Loss G: 0.4825, Loss D: 1.4532\n",
      "epsilon is 1.7491604442707651, alpha is 15.0\n",
      "Epoch 78, Loss G: 0.4799, Loss D: 1.4628\n",
      "epsilon is 1.761356417979987, alpha is 15.0\n",
      "Epoch 79, Loss G: 0.4808, Loss D: 1.4384\n",
      "epsilon is 1.7735523916892093, alpha is 15.0\n",
      "Epoch 80, Loss G: 0.4796, Loss D: 1.4514\n",
      "epsilon is 1.7857483653984312, alpha is 15.0\n",
      "Epoch 81, Loss G: 0.4815, Loss D: 1.4676\n",
      "epsilon is 1.7979443391076535, alpha is 15.0\n",
      "Epoch 82, Loss G: 0.4753, Loss D: 1.4568\n",
      "epsilon is 1.8101403128168756, alpha is 15.0\n",
      "Epoch 83, Loss G: 0.4826, Loss D: 1.4554\n",
      "epsilon is 1.8223362865260977, alpha is 15.0\n",
      "Epoch 84, Loss G: 0.4856, Loss D: 1.4525\n",
      "epsilon is 1.8345322602353198, alpha is 15.0\n",
      "Epoch 85, Loss G: 0.4791, Loss D: 1.4536\n",
      "epsilon is 1.8463913103053533, alpha is 14.0\n",
      "Epoch 86, Loss G: 0.4696, Loss D: 1.4558\n",
      "epsilon is 1.857764815256347, alpha is 14.0\n",
      "Epoch 87, Loss G: 0.4647, Loss D: 1.4702\n",
      "epsilon is 1.8691383202073408, alpha is 14.0\n",
      "Epoch 88, Loss G: 0.4583, Loss D: 1.4720\n",
      "epsilon is 1.880511825158335, alpha is 14.0\n",
      "Epoch 89, Loss G: 0.4408, Loss D: 1.4998\n",
      "epsilon is 1.8918853301093288, alpha is 14.0\n",
      "Epoch 90, Loss G: 0.4397, Loss D: 1.4996\n",
      "epsilon is 1.9032588350603226, alpha is 14.0\n",
      "Epoch 91, Loss G: 0.4306, Loss D: 1.5048\n",
      "epsilon is 1.9146323400113165, alpha is 14.0\n",
      "Epoch 92, Loss G: 0.4311, Loss D: 1.5064\n",
      "epsilon is 1.9260058449623105, alpha is 14.0\n",
      "Epoch 93, Loss G: 0.4223, Loss D: 1.4954\n",
      "epsilon is 1.9373793499133043, alpha is 14.0\n",
      "Epoch 94, Loss G: 0.4213, Loss D: 1.5031\n",
      "epsilon is 1.948752854864298, alpha is 14.0\n",
      "Epoch 95, Loss G: 0.4260, Loss D: 1.5063\n",
      "epsilon is 1.9601263598152918, alpha is 14.0\n",
      "Epoch 96, Loss G: 0.4153, Loss D: 1.5119\n",
      "epsilon is 1.971499864766286, alpha is 14.0\n",
      "Epoch 97, Loss G: 0.4218, Loss D: 1.5032\n",
      "epsilon is 1.9828733697172802, alpha is 14.0\n",
      "Epoch 98, Loss G: 0.4215, Loss D: 1.5016\n",
      "epsilon is 1.994246874668274, alpha is 14.0\n",
      "Epoch 99, Loss G: 0.4260, Loss D: 1.4968\n",
      "epsilon is 2.005620379619268, alpha is 14.0\n",
      "Epoch 100, Loss G: 0.4239, Loss D: 1.5070\n",
      "epsilon is 2.01637239401409, alpha is 13.0\n",
      "Epoch 101, Loss G: 0.4242, Loss D: 1.5069\n",
      "epsilon is 2.0269247929893552, alpha is 13.0\n",
      "Epoch 102, Loss G: 0.4276, Loss D: 1.5018\n",
      "epsilon is 2.03747719196462, alpha is 13.0\n",
      "Epoch 103, Loss G: 0.4214, Loss D: 1.5188\n",
      "epsilon is 2.0480295909398856, alpha is 13.0\n",
      "Epoch 104, Loss G: 0.4121, Loss D: 1.5193\n",
      "epsilon is 2.058581989915151, alpha is 13.0\n",
      "Epoch 105, Loss G: 0.4078, Loss D: 1.5258\n",
      "epsilon is 2.069134388890416, alpha is 13.0\n",
      "Epoch 106, Loss G: 0.4030, Loss D: 1.5381\n",
      "epsilon is 2.0796867878656817, alpha is 13.0\n",
      "Epoch 107, Loss G: 0.4029, Loss D: 1.5196\n",
      "epsilon is 2.0902391868409467, alpha is 13.0\n",
      "Epoch 108, Loss G: 0.3903, Loss D: 1.5418\n",
      "epsilon is 2.100791585816212, alpha is 13.0\n",
      "Epoch 109, Loss G: 0.3722, Loss D: 1.5504\n",
      "epsilon is 2.1113439847914774, alpha is 13.0\n",
      "Epoch 110, Loss G: 0.3793, Loss D: 1.5437\n",
      "epsilon is 2.1218963837667424, alpha is 13.0\n",
      "Epoch 111, Loss G: 0.3686, Loss D: 1.5706\n",
      "epsilon is 2.1324487827420078, alpha is 13.0\n",
      "Epoch 112, Loss G: 0.3611, Loss D: 1.5720\n",
      "epsilon is 2.143001181717273, alpha is 13.0\n",
      "Epoch 113, Loss G: 0.3615, Loss D: 1.5921\n",
      "epsilon is 2.153553580692538, alpha is 13.0\n",
      "Epoch 114, Loss G: 0.3464, Loss D: 1.5840\n",
      "epsilon is 2.164105979667804, alpha is 13.0\n",
      "Epoch 115, Loss G: 0.3551, Loss D: 1.5946\n",
      "epsilon is 2.174658378643069, alpha is 13.0\n",
      "Epoch 116, Loss G: 0.3534, Loss D: 1.5949\n",
      "epsilon is 2.1852107776183343, alpha is 13.0\n",
      "Epoch 117, Loss G: 0.3575, Loss D: 1.5847\n",
      "epsilon is 2.1957631765935997, alpha is 13.0\n",
      "Epoch 118, Loss G: 0.3477, Loss D: 1.6006\n",
      "epsilon is 2.2063155755688646, alpha is 13.0\n",
      "Epoch 119, Loss G: 0.3451, Loss D: 1.6010\n",
      "epsilon is 2.2160572825895373, alpha is 12.0\n",
      "Epoch 120, Loss G: 0.3338, Loss D: 1.6080\n",
      "epsilon is 2.2257899338299536, alpha is 12.0\n",
      "Epoch 121, Loss G: 0.3385, Loss D: 1.5984\n",
      "epsilon is 2.2355225850703704, alpha is 12.0\n",
      "Epoch 122, Loss G: 0.3421, Loss D: 1.6062\n",
      "epsilon is 2.245255236310787, alpha is 12.0\n",
      "Epoch 123, Loss G: 0.3390, Loss D: 1.6079\n",
      "epsilon is 2.254987887551204, alpha is 12.0\n",
      "Epoch 124, Loss G: 0.3423, Loss D: 1.6089\n",
      "epsilon is 2.2647205387916207, alpha is 12.0\n",
      "Epoch 125, Loss G: 0.3369, Loss D: 1.6151\n",
      "epsilon is 2.2744531900320375, alpha is 12.0\n",
      "Epoch 126, Loss G: 0.3328, Loss D: 1.6103\n",
      "epsilon is 2.284185841272454, alpha is 12.0\n",
      "Epoch 127, Loss G: 0.3274, Loss D: 1.6242\n",
      "epsilon is 2.2939184925128706, alpha is 12.0\n",
      "Epoch 128, Loss G: 0.3219, Loss D: 1.6400\n",
      "epsilon is 2.3036511437532874, alpha is 12.0\n",
      "Epoch 129, Loss G: 0.3216, Loss D: 1.6546\n",
      "epsilon is 2.313383794993704, alpha is 12.0\n",
      "Epoch 130, Loss G: 0.3159, Loss D: 1.6484\n",
      "epsilon is 2.323116446234121, alpha is 12.0\n",
      "Epoch 131, Loss G: 0.3125, Loss D: 1.6424\n",
      "epsilon is 2.3328490974745377, alpha is 12.0\n",
      "Epoch 132, Loss G: 0.3152, Loss D: 1.6419\n",
      "epsilon is 2.3425817487149545, alpha is 12.0\n",
      "Epoch 133, Loss G: 0.3130, Loss D: 1.6507\n",
      "epsilon is 2.3523143999553713, alpha is 12.0\n",
      "Epoch 134, Loss G: 0.3127, Loss D: 1.6474\n",
      "epsilon is 2.362047051195788, alpha is 12.0\n",
      "Epoch 135, Loss G: 0.3255, Loss D: 1.6400\n",
      "epsilon is 2.371779702436205, alpha is 12.0\n",
      "Epoch 136, Loss G: 0.3106, Loss D: 1.6517\n",
      "epsilon is 2.3815123536766216, alpha is 12.0\n",
      "Epoch 137, Loss G: 0.3136, Loss D: 1.6633\n",
      "epsilon is 2.3912450049170384, alpha is 12.0\n",
      "Epoch 138, Loss G: 0.3055, Loss D: 1.6754\n",
      "epsilon is 2.400977656157455, alpha is 12.0\n",
      "Epoch 139, Loss G: 0.3107, Loss D: 1.6609\n",
      "epsilon is 2.410710307397872, alpha is 12.0\n",
      "Epoch 140, Loss G: 0.3031, Loss D: 1.6697\n",
      "epsilon is 2.4204429586382887, alpha is 12.0\n",
      "Epoch 141, Loss G: 0.2999, Loss D: 1.6823\n",
      "epsilon is 2.4301756098787055, alpha is 12.0\n",
      "Epoch 142, Loss G: 0.2956, Loss D: 1.6916\n",
      "epsilon is 2.4399082611191223, alpha is 12.0\n",
      "Epoch 143, Loss G: 0.2862, Loss D: 1.7180\n",
      "epsilon is 2.4496409123595386, alpha is 12.0\n",
      "Epoch 144, Loss G: 0.2770, Loss D: 1.7432\n",
      "epsilon is 2.4593735635999554, alpha is 12.0\n",
      "Epoch 145, Loss G: 0.2726, Loss D: 1.7338\n",
      "epsilon is 2.468268791783387, alpha is 10.9\n",
      "Epoch 146, Loss G: 0.2810, Loss D: 1.7186\n",
      "epsilon is 2.4771012838923436, alpha is 10.9\n",
      "Epoch 147, Loss G: 0.2629, Loss D: 1.7625\n",
      "epsilon is 2.4859337760013007, alpha is 10.9\n",
      "Epoch 148, Loss G: 0.2723, Loss D: 1.7674\n",
      "epsilon is 2.4947662681102574, alpha is 10.9\n",
      "Epoch 149, Loss G: 0.2639, Loss D: 1.7683\n",
      "epsilon is 2.503598760219214, alpha is 10.9\n",
      "Epoch 150, Loss G: 0.2673, Loss D: 1.7566\n",
      "epsilon is 2.512431252328171, alpha is 10.9\n",
      "Epoch 151, Loss G: 0.2592, Loss D: 1.7767\n",
      "epsilon is 2.5212637444371278, alpha is 10.9\n",
      "Epoch 152, Loss G: 0.2544, Loss D: 1.8088\n",
      "epsilon is 2.5300962365460844, alpha is 10.9\n",
      "Epoch 153, Loss G: 0.2536, Loss D: 1.8095\n",
      "epsilon is 2.5389287286550415, alpha is 10.9\n",
      "Epoch 154, Loss G: 0.2455, Loss D: 1.8275\n",
      "epsilon is 2.547761220763998, alpha is 10.9\n",
      "Epoch 155, Loss G: 0.2390, Loss D: 1.8244\n",
      "epsilon is 2.556593712872955, alpha is 10.9\n",
      "Epoch 156, Loss G: 0.2439, Loss D: 1.8411\n",
      "epsilon is 2.565426204981912, alpha is 10.9\n",
      "Epoch 157, Loss G: 0.2408, Loss D: 1.8292\n",
      "epsilon is 2.5742586970908685, alpha is 10.9\n",
      "Epoch 158, Loss G: 0.2424, Loss D: 1.8214\n",
      "epsilon is 2.583091189199825, alpha is 10.9\n",
      "Epoch 159, Loss G: 0.2376, Loss D: 1.8212\n",
      "epsilon is 2.5919236813087823, alpha is 10.9\n",
      "Epoch 160, Loss G: 0.2311, Loss D: 1.8875\n",
      "epsilon is 2.600756173417739, alpha is 10.9\n",
      "Epoch 161, Loss G: 0.2152, Loss D: 1.8873\n",
      "epsilon is 2.6095886655266956, alpha is 10.9\n",
      "Epoch 162, Loss G: 0.2228, Loss D: 1.8603\n",
      "epsilon is 2.6184211576356526, alpha is 10.9\n",
      "Epoch 163, Loss G: 0.2278, Loss D: 1.8741\n",
      "epsilon is 2.6272046232198916, alpha is 10.8\n",
      "Epoch 164, Loss G: 0.2285, Loss D: 1.8723\n",
      "epsilon is 2.6359553636969846, alpha is 10.8\n",
      "Epoch 165, Loss G: 0.2249, Loss D: 1.8811\n",
      "epsilon is 2.6447061041740776, alpha is 10.8\n",
      "Epoch 166, Loss G: 0.2315, Loss D: 1.8796\n",
      "epsilon is 2.6534465853263964, alpha is 10.7\n",
      "Epoch 167, Loss G: 0.2249, Loss D: 1.8722\n",
      "epsilon is 2.66211558765494, alpha is 10.7\n",
      "Epoch 168, Loss G: 0.1956, Loss D: 1.9704\n",
      "epsilon is 2.6707845899834832, alpha is 10.7\n",
      "Epoch 169, Loss G: 0.2078, Loss D: 1.9288\n",
      "epsilon is 2.6794535923120266, alpha is 10.7\n",
      "Epoch 170, Loss G: 0.2054, Loss D: 1.9482\n",
      "epsilon is 2.6880784585701423, alpha is 10.6\n",
      "Epoch 171, Loss G: 0.2069, Loss D: 1.9312\n",
      "epsilon is 2.696665736228968, alpha is 10.6\n",
      "Epoch 172, Loss G: 0.2193, Loss D: 1.9075\n",
      "epsilon is 2.705253013887793, alpha is 10.6\n",
      "Epoch 173, Loss G: 0.2157, Loss D: 1.9231\n",
      "epsilon is 2.713840291546618, alpha is 10.6\n",
      "Epoch 174, Loss G: 0.2078, Loss D: 1.9120\n",
      "epsilon is 2.722359048878536, alpha is 10.5\n",
      "Epoch 175, Loss G: 0.2016, Loss D: 1.9836\n",
      "epsilon is 2.730864615341999, alpha is 10.5\n",
      "Epoch 176, Loss G: 0.1858, Loss D: 2.0399\n",
      "epsilon is 2.739370181805463, alpha is 10.5\n",
      "Epoch 177, Loss G: 0.1814, Loss D: 2.0581\n",
      "epsilon is 2.74787443941357, alpha is 10.4\n",
      "Epoch 178, Loss G: 0.1964, Loss D: 1.9704\n",
      "epsilon is 2.756298308151558, alpha is 10.4\n",
      "Epoch 179, Loss G: 0.1937, Loss D: 1.9948\n",
      "epsilon is 2.7647221768895465, alpha is 10.4\n",
      "Epoch 180, Loss G: 0.1902, Loss D: 1.9724\n",
      "epsilon is 2.7731460456275348, alpha is 10.4\n",
      "Epoch 181, Loss G: 0.2042, Loss D: 1.9406\n",
      "epsilon is 2.7815644313658536, alpha is 10.3\n",
      "Epoch 182, Loss G: 0.2025, Loss D: 1.9515\n",
      "epsilon is 2.7899066158437806, alpha is 10.3\n",
      "Epoch 183, Loss G: 0.2046, Loss D: 1.9734\n",
      "epsilon is 2.7982488003217085, alpha is 10.3\n",
      "Epoch 184, Loss G: 0.2111, Loss D: 1.9333\n",
      "epsilon is 2.8065909847996355, alpha is 10.3\n",
      "Epoch 185, Loss G: 0.2060, Loss D: 1.9264\n",
      "epsilon is 2.814933169277563, alpha is 10.3\n",
      "Epoch 186, Loss G: 0.2020, Loss D: 1.9357\n",
      "epsilon is 2.8231948024768827, alpha is 10.2\n",
      "Epoch 187, Loss G: 0.2022, Loss D: 1.9594\n",
      "epsilon is 2.8314553161556986, alpha is 10.2\n",
      "Epoch 188, Loss G: 0.1868, Loss D: 2.0371\n",
      "epsilon is 2.8397158298345135, alpha is 10.2\n",
      "Epoch 189, Loss G: 0.1977, Loss D: 1.9979\n",
      "epsilon is 2.8479763435133294, alpha is 10.2\n",
      "Epoch 190, Loss G: 0.1966, Loss D: 1.9892\n",
      "epsilon is 2.8561741747149854, alpha is 10.1\n",
      "Epoch 191, Loss G: 0.1956, Loss D: 1.9906\n",
      "epsilon is 2.8643530310511722, alpha is 10.1\n",
      "Epoch 192, Loss G: 0.1873, Loss D: 2.0244\n",
      "epsilon is 2.872531887387359, alpha is 10.1\n",
      "Epoch 193, Loss G: 0.1944, Loss D: 2.0114\n",
      "epsilon is 2.880710743723546, alpha is 10.1\n",
      "Epoch 194, Loss G: 0.1991, Loss D: 1.9945\n",
      "epsilon is 2.888856542128456, alpha is 10.0\n",
      "Epoch 195, Loss G: 0.1934, Loss D: 1.9778\n",
      "epsilon is 2.896953754574036, alpha is 10.0\n",
      "Epoch 196, Loss G: 0.1899, Loss D: 2.0120\n",
      "epsilon is 2.905050967019616, alpha is 10.0\n",
      "Epoch 197, Loss G: 0.1892, Loss D: 2.0024\n",
      "epsilon is 2.9131481794651966, alpha is 10.0\n",
      "Epoch 198, Loss G: 0.1939, Loss D: 1.9934\n",
      "epsilon is 2.921245391910776, alpha is 10.0\n",
      "Epoch 199, Loss G: 0.2006, Loss D: 1.9776\n",
      "epsilon is 2.9292698277795344, alpha is 9.9\n",
      "Epoch 200, Loss G: 0.1971, Loss D: 1.9593\n",
      "epsilon is 2.937285409782066, alpha is 9.9\n",
      "Epoch 201, Loss G: 0.2035, Loss D: 1.9383\n",
      "epsilon is 2.9453009917845985, alpha is 9.9\n",
      "Epoch 202, Loss G: 0.1981, Loss D: 1.9759\n",
      "epsilon is 2.9533165737871307, alpha is 9.9\n",
      "Epoch 203, Loss G: 0.2027, Loss D: 1.9615\n",
      "epsilon is 2.9613141537645884, alpha is 9.8\n",
      "Epoch 204, Loss G: 0.1932, Loss D: 1.9935\n",
      "epsilon is 2.969248118767176, alpha is 9.8\n",
      "Epoch 205, Loss G: 0.1926, Loss D: 1.9654\n",
      "epsilon is 2.977182083769764, alpha is 9.8\n",
      "Epoch 206, Loss G: 0.1906, Loss D: 1.9926\n",
      "epsilon is 2.9851160487723516, alpha is 9.8\n",
      "Epoch 207, Loss G: 0.1972, Loss D: 2.0009\n",
      "epsilon is 2.993050013774939, alpha is 9.8\n",
      "Epoch 208, Loss G: 0.1940, Loss D: 1.9775\n",
      "epsilon is 3.000952591784167, alpha is 9.7\n",
      "Epoch 209, Loss G: 0.1936, Loss D: 2.0133\n",
      "epsilon is 3.0088049532254564, alpha is 9.7\n",
      "Epoch 210, Loss G: 0.2044, Loss D: 1.9324\n",
      "epsilon is 3.0166573146667455, alpha is 9.7\n",
      "Epoch 211, Loss G: 0.2021, Loss D: 1.9586\n",
      "epsilon is 3.0245096761080354, alpha is 9.7\n",
      "Epoch 212, Loss G: 0.1958, Loss D: 2.0165\n",
      "epsilon is 3.0323620375493245, alpha is 9.7\n",
      "Epoch 213, Loss G: 0.1860, Loss D: 1.9888\n",
      "epsilon is 3.0401837276516326, alpha is 9.6\n",
      "Epoch 214, Loss G: 0.1898, Loss D: 2.0390\n",
      "epsilon is 3.0479544989658183, alpha is 9.6\n",
      "Epoch 215, Loss G: 0.1947, Loss D: 2.0292\n",
      "epsilon is 3.055725270280004, alpha is 9.6\n",
      "Epoch 216, Loss G: 0.1912, Loss D: 2.0127\n",
      "epsilon is 3.0634960415941896, alpha is 9.6\n",
      "Epoch 217, Loss G: 0.1859, Loss D: 2.0379\n",
      "epsilon is 3.0712668129083753, alpha is 9.6\n",
      "Epoch 218, Loss G: 0.1732, Loss D: 2.0733\n",
      "epsilon is 3.079022396327727, alpha is 9.5\n",
      "Epoch 219, Loss G: 0.1845, Loss D: 2.0272\n",
      "epsilon is 3.086711590944551, alpha is 9.5\n",
      "Epoch 220, Loss G: 0.1869, Loss D: 1.9968\n",
      "epsilon is 3.094400785561374, alpha is 9.5\n",
      "Epoch 221, Loss G: 0.1975, Loss D: 1.9894\n",
      "epsilon is 3.102089980178198, alpha is 9.5\n",
      "Epoch 222, Loss G: 0.2012, Loss D: 1.9722\n",
      "epsilon is 3.109779174795021, alpha is 9.5\n",
      "Epoch 223, Loss G: 0.2011, Loss D: 1.9577\n",
      "epsilon is 3.1174683694118452, alpha is 9.5\n",
      "Epoch 224, Loss G: 0.1972, Loss D: 1.9689\n",
      "epsilon is 3.1250917714325563, alpha is 9.4\n",
      "Epoch 225, Loss G: 0.2030, Loss D: 1.9860\n",
      "epsilon is 3.1326994027773116, alpha is 9.4\n",
      "Epoch 226, Loss G: 0.2050, Loss D: 1.9443\n",
      "epsilon is 3.140307034122067, alpha is 9.4\n",
      "Epoch 227, Loss G: 0.2075, Loss D: 1.9572\n",
      "epsilon is 3.147914665466822, alpha is 9.4\n",
      "Epoch 228, Loss G: 0.2000, Loss D: 1.9442\n",
      "epsilon is 3.1555222968115775, alpha is 9.4\n",
      "Epoch 229, Loss G: 0.1868, Loss D: 2.0122\n",
      "epsilon is 3.163111333113673, alpha is 9.3\n",
      "Epoch 230, Loss G: 0.1925, Loss D: 2.0219\n",
      "epsilon is 3.1706374146072074, alpha is 9.3\n",
      "Epoch 231, Loss G: 0.1935, Loss D: 2.0184\n",
      "epsilon is 3.1781634961007423, alpha is 9.3\n",
      "Epoch 232, Loss G: 0.1761, Loss D: 2.0887\n",
      "epsilon is 3.1856895775942773, alpha is 9.3\n",
      "Epoch 233, Loss G: 0.1638, Loss D: 2.1919\n",
      "epsilon is 3.1932156590878114, alpha is 9.3\n",
      "Epoch 234, Loss G: 0.1620, Loss D: 2.0892\n",
      "epsilon is 3.2007417405813463, alpha is 9.3\n",
      "Epoch 235, Loss G: 0.1764, Loss D: 2.1219\n",
      "epsilon is 3.208231910423759, alpha is 9.2\n",
      "Epoch 236, Loss G: 0.1742, Loss D: 2.0657\n",
      "epsilon is 3.2156764554824764, alpha is 9.2\n",
      "Epoch 237, Loss G: 0.1860, Loss D: 2.0242\n",
      "epsilon is 3.2231210005411937, alpha is 9.2\n",
      "Epoch 238, Loss G: 0.1861, Loss D: 1.9875\n",
      "epsilon is 3.2305655455999114, alpha is 9.2\n",
      "Epoch 239, Loss G: 0.1868, Loss D: 2.0187\n",
      "epsilon is 3.238010090658629, alpha is 9.2\n",
      "Epoch 240, Loss G: 0.1821, Loss D: 2.0417\n",
      "epsilon is 3.245454635717347, alpha is 9.2\n",
      "Epoch 241, Loss G: 0.1880, Loss D: 2.0082\n",
      "epsilon is 3.2528638480680554, alpha is 9.1\n",
      "Epoch 242, Loss G: 0.1926, Loss D: 1.9702\n",
      "epsilon is 3.260226870103917, alpha is 9.1\n",
      "Epoch 243, Loss G: 0.1992, Loss D: 1.9581\n",
      "epsilon is 3.2675898921397795, alpha is 9.1\n",
      "Epoch 244, Loss G: 0.2095, Loss D: 1.9569\n",
      "epsilon is 3.2749529141756417, alpha is 9.1\n",
      "Epoch 245, Loss G: 0.1937, Loss D: 2.0163\n",
      "epsilon is 3.2823159362115035, alpha is 9.1\n",
      "Epoch 246, Loss G: 0.1947, Loss D: 2.0030\n",
      "epsilon is 3.289678958247366, alpha is 9.1\n",
      "Epoch 247, Loss G: 0.1890, Loss D: 2.0225\n",
      "epsilon is 3.2970260220141356, alpha is 9.0\n",
      "Epoch 248, Loss G: 0.1778, Loss D: 2.0430\n",
      "epsilon is 3.3043075344346655, alpha is 9.0\n",
      "Epoch 249, Loss G: 0.1779, Loss D: 2.0585\n",
      "epsilon is 3.311589046855195, alpha is 9.0\n",
      "Epoch 250, Loss G: 0.1866, Loss D: 2.0450\n",
      "epsilon is 3.3188705592757244, alpha is 9.0\n",
      "Epoch 251, Loss G: 0.1787, Loss D: 2.0176\n",
      "epsilon is 3.3261520716962543, alpha is 9.0\n",
      "Epoch 252, Loss G: 0.1819, Loss D: 2.0735\n",
      "epsilon is 3.333433584116784, alpha is 9.0\n",
      "Epoch 253, Loss G: 0.1783, Loss D: 2.0350\n",
      "epsilon is 3.340715096537314, alpha is 9.0\n",
      "Epoch 254, Loss G: 0.1872, Loss D: 2.0337\n",
      "epsilon is 3.347938281956484, alpha is 8.9\n",
      "Epoch 255, Loss G: 0.1906, Loss D: 2.0341\n",
      "epsilon is 3.355138298164765, alpha is 8.9\n",
      "Epoch 256, Loss G: 0.1909, Loss D: 1.9801\n",
      "epsilon is 3.3623383143730456, alpha is 8.9\n",
      "Epoch 257, Loss G: 0.1971, Loss D: 1.9615\n",
      "epsilon is 3.3695383305813262, alpha is 8.9\n",
      "Epoch 258, Loss G: 0.1948, Loss D: 1.9705\n",
      "epsilon is 3.3767383467896073, alpha is 8.9\n",
      "Epoch 259, Loss G: 0.2012, Loss D: 1.9859\n",
      "epsilon is 3.3839383629978883, alpha is 8.9\n",
      "Epoch 260, Loss G: 0.2019, Loss D: 1.9994\n",
      "epsilon is 3.391138379206169, alpha is 8.9\n",
      "Epoch 261, Loss G: 0.1961, Loss D: 1.9929\n",
      "epsilon is 3.398258499138359, alpha is 8.8\n",
      "Epoch 262, Loss G: 0.1890, Loss D: 2.0113\n",
      "epsilon is 3.405377032533042, alpha is 8.8\n",
      "Epoch 263, Loss G: 0.1810, Loss D: 2.0344\n",
      "epsilon is 3.4124955659277245, alpha is 8.8\n",
      "Epoch 264, Loss G: 0.1882, Loss D: 2.0300\n",
      "epsilon is 3.419614099322408, alpha is 8.8\n",
      "Epoch 265, Loss G: 0.1833, Loss D: 2.0376\n",
      "epsilon is 3.42673263271709, alpha is 8.8\n",
      "Epoch 266, Loss G: 0.1838, Loss D: 2.0358\n",
      "epsilon is 3.433851166111773, alpha is 8.8\n",
      "Epoch 267, Loss G: 0.1889, Loss D: 2.0046\n",
      "epsilon is 3.440969699506456, alpha is 8.8\n",
      "Epoch 268, Loss G: 0.1929, Loss D: 2.0120\n",
      "epsilon is 3.4480086533626415, alpha is 8.7\n",
      "Epoch 269, Loss G: 0.1985, Loss D: 1.9905\n",
      "epsilon is 3.4550457173379425, alpha is 8.7\n",
      "Epoch 270, Loss G: 0.1948, Loss D: 1.9752\n",
      "epsilon is 3.462082781313244, alpha is 8.7\n",
      "Epoch 271, Loss G: 0.1945, Loss D: 1.9740\n",
      "epsilon is 3.4691198452885454, alpha is 8.7\n",
      "Epoch 272, Loss G: 0.1880, Loss D: 2.0011\n",
      "epsilon is 3.4761569092638465, alpha is 8.7\n",
      "Epoch 273, Loss G: 0.1874, Loss D: 2.0239\n",
      "epsilon is 3.483193973239148, alpha is 8.7\n",
      "Epoch 274, Loss G: 0.1860, Loss D: 1.9926\n",
      "epsilon is 3.4902310372144494, alpha is 8.7\n",
      "Epoch 275, Loss G: 0.1720, Loss D: 2.0893\n",
      "epsilon is 3.497211883240985, alpha is 8.6\n",
      "Epoch 276, Loss G: 0.1778, Loss D: 2.0776\n",
      "epsilon is 3.5041674911866934, alpha is 8.6\n",
      "Epoch 277, Loss G: 0.1817, Loss D: 2.0609\n",
      "epsilon is 3.511123099132402, alpha is 8.6\n",
      "Epoch 278, Loss G: 0.1815, Loss D: 2.0558\n",
      "epsilon is 3.5180787070781103, alpha is 8.6\n",
      "Epoch 279, Loss G: 0.1818, Loss D: 2.0329\n",
      "epsilon is 3.5250343150238193, alpha is 8.6\n",
      "Epoch 280, Loss G: 0.1800, Loss D: 2.0163\n",
      "epsilon is 3.5319899229695277, alpha is 8.6\n",
      "Epoch 281, Loss G: 0.1878, Loss D: 2.0142\n",
      "epsilon is 3.5389455309152367, alpha is 8.6\n",
      "Epoch 282, Loss G: 0.1886, Loss D: 2.0431\n",
      "epsilon is 3.545892564307625, alpha is 8.5\n",
      "Epoch 283, Loss G: 0.1817, Loss D: 2.0326\n",
      "epsilon is 3.552766729609101, alpha is 8.5\n",
      "Epoch 284, Loss G: 0.1845, Loss D: 2.0165\n",
      "epsilon is 3.5596408949105767, alpha is 8.5\n",
      "Epoch 285, Loss G: 0.1873, Loss D: 2.0125\n",
      "epsilon is 3.5665150602120526, alpha is 8.5\n",
      "Epoch 286, Loss G: 0.1710, Loss D: 2.1069\n",
      "epsilon is 3.573389225513529, alpha is 8.5\n",
      "Epoch 287, Loss G: 0.1922, Loss D: 2.0370\n",
      "epsilon is 3.5802633908150048, alpha is 8.5\n",
      "Epoch 288, Loss G: 0.1763, Loss D: 2.0514\n",
      "epsilon is 3.5871375561164807, alpha is 8.5\n",
      "Epoch 289, Loss G: 0.1845, Loss D: 2.0657\n",
      "epsilon is 3.5940117214179566, alpha is 8.5\n",
      "Epoch 290, Loss G: 0.1779, Loss D: 2.0410\n",
      "epsilon is 3.6008691295626627, alpha is 8.4\n",
      "Epoch 291, Loss G: 0.1790, Loss D: 2.0495\n",
      "epsilon is 3.6076618656008392, alpha is 8.4\n",
      "Epoch 292, Loss G: 0.1775, Loss D: 2.0860\n",
      "epsilon is 3.614454601639016, alpha is 8.4\n",
      "Epoch 293, Loss G: 0.1794, Loss D: 2.0530\n",
      "epsilon is 3.621247337677193, alpha is 8.4\n",
      "Epoch 294, Loss G: 0.1789, Loss D: 2.0591\n",
      "epsilon is 3.6280400737153697, alpha is 8.4\n",
      "Epoch 295, Loss G: 0.1759, Loss D: 2.0642\n",
      "epsilon is 3.6348328097535463, alpha is 8.4\n",
      "Epoch 296, Loss G: 0.1788, Loss D: 2.0707\n",
      "epsilon is 3.6416255457917233, alpha is 8.4\n",
      "Epoch 297, Loss G: 0.1790, Loss D: 2.0676\n",
      "epsilon is 3.6484182818299002, alpha is 8.4\n",
      "Epoch 298, Loss G: 0.1766, Loss D: 2.1058\n",
      "epsilon is 3.6552110178680763, alpha is 8.4\n",
      "Epoch 299, Loss G: 0.1785, Loss D: 2.0541\n",
      "epsilon is 3.6619244412458656, alpha is 8.3\n",
      "Epoch 300, Loss G: 0.1776, Loss D: 2.0368\n",
      "epsilon is 3.6686357613972542, alpha is 8.3\n",
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 1239.4128 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 24929 rows (same as raw) in 2.4915 sec.\n",
      "Now is Postprocessor with default-smartnoise...\n",
      "Now is Evaluator with anonymeter-singlingout_univariate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.0009585236406264672, baseline = 0.0009585236406264672. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is 20240322_exp7[Report]_anonymeter-singlingout_univariate_[global] save to csv...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with anonymeter-linkability...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.0009585236406264672, baseline = 0.0009585236406264672. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is 20240322_exp7[Report]_anonymeter-linkability_[global] save to csv...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with anonymeter-inference...\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is 20240322_exp7[Report]_anonymeter-inference_[global] save to csv...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with sdmetrics-diag...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|| 13/13 [00:00<00:00, 519.64it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|| 1/1 [00:00<00:00, 692.59it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is 20240321_exp7[Report]_sdmetrics-diag_[columnwise] save to csv...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with sdmetrics-qual...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|| 13/13 [00:00<00:00, 197.68it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|| 78/78 [00:03<00:00, 24.31it/s]\n",
      "\n",
      "Overall Score: 63.08%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 72.72%\n",
      "- Column Pair Trends: 53.43%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is 20240321_exp7[Report]_sdmetrics-qual_[columnwise] save to csv...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Regression: 100%|| 5/5 [02:04<00:00, 25.00s/it]\n",
      "Regression: 100%|| 5/5 [01:26<00:00, 17.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is 20240321_exp7[Report]_automl-regression_[global] save to csv...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classification: 100%|| 5/5 [05:02<00:00, 60.48s/it]\n",
      "Classification: 100%|| 5/5 [01:29<00:00, 17.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is 20240321_exp7[Report]_automl-classification_[global] save to csv...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering: 100%|| 5/5 [00:10<00:00,  2.18s/it]\n",
      "Clustering: 100%|| 5/5 [00:05<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is 20240321_exp7[Report]_automl-cluster_[global] save to csv...\n",
      "Now is Synthesizer with smartnoise-dpctgan1...\n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1352: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.6729, Loss D: 1.4076\n",
      "epsilon is 0.1621052371810809, alpha is 63.0\n",
      "Epoch 2, Loss G: 0.6970, Loss D: 1.3975\n",
      "epsilon is 0.2154777899194668, alpha is 63.0\n",
      "Epoch 3, Loss G: 0.6904, Loss D: 1.3953\n",
      "epsilon is 0.2688503426578527, alpha is 63.0\n",
      "Epoch 4, Loss G: 0.6901, Loss D: 1.3813\n",
      "epsilon is 0.32222289539623855, alpha is 63.0\n",
      "Epoch 5, Loss G: 0.6647, Loss D: 1.4016\n",
      "epsilon is 0.37341275087699954, alpha is 57.0\n",
      "Epoch 6, Loss G: 0.6779, Loss D: 1.3934\n",
      "epsilon is 0.41901084464897975, alpha is 52.0\n",
      "Epoch 7, Loss G: 0.6679, Loss D: 1.3900\n",
      "epsilon is 0.46047921301009653, alpha is 48.0\n",
      "Epoch 8, Loss G: 0.6705, Loss D: 1.3853\n",
      "epsilon is 0.49879327014201535, alpha is 44.0\n",
      "Epoch 9, Loss G: 0.6693, Loss D: 1.3990\n",
      "epsilon is 0.5346025437355053, alpha is 42.0\n",
      "Epoch 10, Loss G: 0.6642, Loss D: 1.3949\n",
      "epsilon is 0.5684014701443807, alpha is 40.0\n",
      "Epoch 11, Loss G: 0.6588, Loss D: 1.3933\n",
      "epsilon is 0.6004394015460149, alpha is 38.0\n",
      "Epoch 12, Loss G: 0.6597, Loss D: 1.3996\n",
      "epsilon is 0.6310196395077151, alpha is 36.0\n",
      "Epoch 13, Loss G: 0.6603, Loss D: 1.3922\n",
      "epsilon is 0.6603460122722166, alpha is 35.0\n",
      "Epoch 14, Loss G: 0.6585, Loss D: 1.3979\n",
      "epsilon is 0.6886041442379658, alpha is 34.0\n",
      "Epoch 15, Loss G: 0.6654, Loss D: 1.3899\n",
      "epsilon is 0.7157875852128055, alpha is 32.0\n",
      "Epoch 16, Loss G: 0.6586, Loss D: 1.3967\n",
      "epsilon is 0.7421024871575375, alpha is 31.0\n",
      "Epoch 17, Loss G: 0.6619, Loss D: 1.3918\n",
      "epsilon is 0.767647100288211, alpha is 31.0\n",
      "Epoch 18, Loss G: 0.6609, Loss D: 1.3859\n",
      "epsilon is 0.7923548741192558, alpha is 30.0\n",
      "Epoch 19, Loss G: 0.6506, Loss D: 1.3979\n",
      "epsilon is 0.816405988490787, alpha is 29.0\n",
      "Epoch 20, Loss G: 0.6496, Loss D: 1.3928\n",
      "epsilon is 0.8399196285202444, alpha is 28.0\n",
      "Epoch 21, Loss G: 0.6473, Loss D: 1.3967\n",
      "epsilon is 0.8629338200947815, alpha is 28.0\n",
      "Epoch 22, Loss G: 0.6451, Loss D: 1.3987\n",
      "epsilon is 0.8852065804317902, alpha is 27.0\n",
      "Epoch 23, Loss G: 0.6382, Loss D: 1.3923\n",
      "epsilon is 0.90723938148027, alpha is 26.0\n",
      "Epoch 24, Loss G: 0.6348, Loss D: 1.3987\n",
      "epsilon is 0.9285737784052924, alpha is 26.0\n",
      "Epoch 25, Loss G: 0.6236, Loss D: 1.4038\n",
      "epsilon is 0.9497140109656055, alpha is 25.0\n",
      "Epoch 26, Loss G: 0.6280, Loss D: 1.3970\n",
      "epsilon is 0.970210641801423, alpha is 25.0\n",
      "Epoch 27, Loss G: 0.6179, Loss D: 1.3982\n",
      "epsilon is 0.9906783712641867, alpha is 24.0\n",
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 116.106 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 24929 rows (same as raw) in 2.4834 sec.\n",
      "Now is Postprocessor with default-smartnoise...\n",
      "Now is Evaluator with anonymeter-singlingout_univariate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.0009585236406264672, baseline = 0.0009585236406264672. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is 20240322_exp7[Report]_anonymeter-singlingout_univariate_[global] save to csv...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with anonymeter-linkability...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.0009585236406264672, baseline = 0.0009585236406264672. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is 20240322_exp7[Report]_anonymeter-linkability_[global] save to csv...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with anonymeter-inference...\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is 20240322_exp7[Report]_anonymeter-inference_[global] save to csv...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with sdmetrics-diag...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|| 13/13 [00:00<00:00, 528.79it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|| 1/1 [00:00<00:00, 682.78it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is 20240321_exp7[Report]_sdmetrics-diag_[columnwise] save to csv...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with sdmetrics-qual...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|| 13/13 [00:00<00:00, 200.50it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|| 78/78 [00:03<00:00, 25.02it/s]\n",
      "\n",
      "Overall Score: 63.89%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 73.55%\n",
      "- Column Pair Trends: 54.24%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is 20240321_exp7[Report]_sdmetrics-qual_[columnwise] save to csv...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Regression: 100%|| 5/5 [02:04<00:00, 24.94s/it]\n",
      "Regression: 100%|| 5/5 [01:34<00:00, 18.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is 20240321_exp7[Report]_automl-regression_[global] save to csv...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classification: 100%|| 5/5 [05:06<00:00, 61.24s/it]\n",
      "Classification: 100%|| 5/5 [01:01<00:00, 12.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is 20240321_exp7[Report]_automl-classification_[global] save to csv...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering: 100%|| 5/5 [00:10<00:00,  2.17s/it]\n",
      "Clustering: 100%|| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-1]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is 20240321_exp7[Report]_automl-cluster_[global] save to csv...\n",
      "Now is Splitter with p80_[2-2]...\n",
      "Now is Preprocessor with default-smartnoise...\n",
      "Now is Synthesizer with smartnoise-dpctgan10...\n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1352: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.6656, Loss D: 1.4103\n",
      "epsilon is 0.16217888283723578, alpha is 63.0\n",
      "Epoch 2, Loss G: 0.6895, Loss D: 1.4040\n",
      "epsilon is 0.2163014051914117, alpha is 63.0\n",
      "Epoch 3, Loss G: 0.7036, Loss D: 1.3780\n",
      "epsilon is 0.27042392754558764, alpha is 63.0\n",
      "Epoch 4, Loss G: 0.6792, Loss D: 1.3924\n",
      "epsilon is 0.3245464498997635, alpha is 63.0\n",
      "Epoch 5, Loss G: 0.6750, Loss D: 1.3921\n",
      "epsilon is 0.376197456841065, alpha is 57.0\n",
      "Epoch 6, Loss G: 0.6674, Loss D: 1.3897\n",
      "epsilon is 0.4221411479824565, alpha is 51.0\n",
      "Epoch 7, Loss G: 0.6615, Loss D: 1.3931\n",
      "epsilon is 0.4639167774251823, alpha is 47.0\n",
      "Epoch 8, Loss G: 0.6594, Loss D: 1.3963\n",
      "epsilon is 0.5025193987805284, alpha is 44.0\n",
      "Epoch 9, Loss G: 0.6531, Loss D: 1.3936\n",
      "epsilon is 0.5386576819634908, alpha is 42.0\n",
      "Epoch 10, Loss G: 0.6530, Loss D: 1.3981\n",
      "epsilon is 0.5726766764984677, alpha is 39.0\n",
      "Epoch 11, Loss G: 0.6477, Loss D: 1.3981\n",
      "epsilon is 0.6050111960332332, alpha is 38.0\n",
      "Epoch 12, Loss G: 0.6442, Loss D: 1.3968\n",
      "epsilon is 0.6357796528187886, alpha is 36.0\n",
      "Epoch 13, Loss G: 0.6385, Loss D: 1.4035\n",
      "epsilon is 0.6653871970718096, alpha is 35.0\n",
      "Epoch 14, Loss G: 0.6347, Loss D: 1.3982\n",
      "epsilon is 0.6937671433528385, alpha is 33.0\n",
      "Epoch 15, Loss G: 0.6330, Loss D: 1.3944\n",
      "epsilon is 0.7211585434841012, alpha is 32.0\n",
      "Epoch 16, Loss G: 0.6283, Loss D: 1.3962\n",
      "epsilon is 0.7476730058511001, alpha is 31.0\n",
      "Epoch 17, Loss G: 0.6263, Loss D: 1.4001\n",
      "epsilon is 0.7734020455693197, alpha is 30.0\n",
      "Epoch 18, Loss G: 0.6235, Loss D: 1.3932\n",
      "epsilon is 0.7984498642333995, alpha is 29.0\n",
      "Epoch 19, Loss G: 0.6174, Loss D: 1.4001\n",
      "epsilon is 0.8226435666650334, alpha is 29.0\n",
      "Epoch 20, Loss G: 0.6179, Loss D: 1.3957\n",
      "epsilon is 0.8462755532142662, alpha is 28.0\n",
      "Epoch 21, Loss G: 0.6181, Loss D: 1.3956\n",
      "epsilon is 0.8694843445807604, alpha is 27.0\n",
      "Epoch 22, Loss G: 0.6224, Loss D: 1.3918\n",
      "epsilon is 0.8919717132862962, alpha is 27.0\n",
      "Epoch 23, Loss G: 0.6125, Loss D: 1.3949\n",
      "epsilon is 0.9140652932933118, alpha is 26.0\n",
      "Epoch 24, Loss G: 0.6133, Loss D: 1.4004\n",
      "epsilon is 0.9357016570631423, alpha is 26.0\n",
      "Epoch 25, Loss G: 0.5964, Loss D: 1.3994\n",
      "epsilon is 0.9568681678637022, alpha is 25.0\n",
      "Epoch 26, Loss G: 0.5872, Loss D: 1.4041\n",
      "epsilon is 0.9776549614336737, alpha is 25.0\n",
      "Epoch 27, Loss G: 0.5872, Loss D: 1.4113\n",
      "epsilon is 0.9981146214609729, alpha is 24.0\n",
      "Epoch 28, Loss G: 0.5857, Loss D: 1.4065\n",
      "epsilon is 1.0180532746880684, alpha is 24.0\n",
      "Epoch 29, Loss G: 0.5835, Loss D: 1.4113\n",
      "epsilon is 1.037991927915164, alpha is 24.0\n",
      "Epoch 30, Loss G: 0.5807, Loss D: 1.4082\n",
      "epsilon is 1.0571577275507311, alpha is 23.0\n",
      "Epoch 31, Loss G: 0.5746, Loss D: 1.4075\n",
      "epsilon is 1.0762496654391702, alpha is 23.0\n",
      "Epoch 32, Loss G: 0.5709, Loss D: 1.4086\n",
      "epsilon is 1.0952784885458546, alpha is 22.0\n",
      "Epoch 33, Loss G: 0.5682, Loss D: 1.4168\n",
      "epsilon is 1.1135251312730043, alpha is 22.0\n",
      "Epoch 34, Loss G: 0.5612, Loss D: 1.4212\n",
      "epsilon is 1.131771774000154, alpha is 22.0\n",
      "Epoch 35, Loss G: 0.5598, Loss D: 1.4155\n",
      "epsilon is 1.150018416727304, alpha is 22.0\n",
      "Epoch 36, Loss G: 0.5536, Loss D: 1.4169\n",
      "epsilon is 1.1675927482064763, alpha is 21.0\n",
      "Epoch 37, Loss G: 0.5569, Loss D: 1.4112\n",
      "epsilon is 1.184995511148565, alpha is 21.0\n",
      "Epoch 38, Loss G: 0.5510, Loss D: 1.4160\n",
      "epsilon is 1.2023982740906538, alpha is 21.0\n",
      "Epoch 39, Loss G: 0.5462, Loss D: 1.4288\n",
      "epsilon is 1.2198010370327423, alpha is 21.0\n",
      "Epoch 40, Loss G: 0.5430, Loss D: 1.4273\n",
      "epsilon is 1.236374707014578, alpha is 20.0\n",
      "Epoch 41, Loss G: 0.5465, Loss D: 1.4179\n",
      "epsilon is 1.2529350007722229, alpha is 20.0\n",
      "Epoch 42, Loss G: 0.5465, Loss D: 1.4092\n",
      "epsilon is 1.2694952945298679, alpha is 20.0\n",
      "Epoch 43, Loss G: 0.5453, Loss D: 1.4189\n",
      "epsilon is 1.2860555882875129, alpha is 20.0\n",
      "Epoch 44, Loss G: 0.5432, Loss D: 1.4258\n",
      "epsilon is 1.3021823339760972, alpha is 19.0\n",
      "Epoch 45, Loss G: 0.5397, Loss D: 1.4185\n",
      "epsilon is 1.3179015643996395, alpha is 19.0\n",
      "Epoch 46, Loss G: 0.5373, Loss D: 1.4281\n",
      "epsilon is 1.3336207948231817, alpha is 19.0\n",
      "Epoch 47, Loss G: 0.5281, Loss D: 1.4344\n",
      "epsilon is 1.3493400252467238, alpha is 19.0\n",
      "Epoch 48, Loss G: 0.5267, Loss D: 1.4166\n",
      "epsilon is 1.3650592556702659, alpha is 19.0\n",
      "Epoch 49, Loss G: 0.5113, Loss D: 1.4381\n",
      "epsilon is 1.3805829115154877, alpha is 18.0\n",
      "Epoch 50, Loss G: 0.5142, Loss D: 1.4338\n",
      "epsilon is 1.3954624797301436, alpha is 18.0\n",
      "Epoch 51, Loss G: 0.5100, Loss D: 1.4490\n",
      "epsilon is 1.410342047944799, alpha is 18.0\n",
      "Epoch 52, Loss G: 0.5111, Loss D: 1.4337\n",
      "epsilon is 1.4252216161594549, alpha is 18.0\n",
      "Epoch 53, Loss G: 0.5010, Loss D: 1.4415\n",
      "epsilon is 1.4401011843741107, alpha is 18.0\n",
      "Epoch 54, Loss G: 0.5034, Loss D: 1.4361\n",
      "epsilon is 1.4549807525887664, alpha is 18.0\n",
      "Epoch 55, Loss G: 0.5083, Loss D: 1.4345\n",
      "epsilon is 1.469860320803422, alpha is 18.0\n",
      "Epoch 56, Loss G: 0.5013, Loss D: 1.4506\n",
      "epsilon is 1.4839615919866171, alpha is 17.0\n",
      "Epoch 57, Loss G: 0.5054, Loss D: 1.4292\n",
      "epsilon is 1.4980028944174417, alpha is 17.0\n",
      "Epoch 58, Loss G: 0.4984, Loss D: 1.4468\n",
      "epsilon is 1.5120441968482663, alpha is 17.0\n",
      "Epoch 59, Loss G: 0.4986, Loss D: 1.4414\n",
      "epsilon is 1.5260854992790907, alpha is 17.0\n",
      "Epoch 60, Loss G: 0.4908, Loss D: 1.4551\n",
      "epsilon is 1.540126801709915, alpha is 17.0\n",
      "Epoch 61, Loss G: 0.4811, Loss D: 1.4565\n",
      "epsilon is 1.5541681041407396, alpha is 17.0\n",
      "Epoch 62, Loss G: 0.4771, Loss D: 1.4599\n",
      "epsilon is 1.5682094065715642, alpha is 17.0\n",
      "Epoch 63, Loss G: 0.4741, Loss D: 1.4633\n",
      "epsilon is 1.5819798996918735, alpha is 16.0\n",
      "Epoch 64, Loss G: 0.4739, Loss D: 1.4605\n",
      "epsilon is 1.5951843280885423, alpha is 16.0\n",
      "Epoch 65, Loss G: 0.4648, Loss D: 1.4636\n",
      "epsilon is 1.6083887564852108, alpha is 16.0\n",
      "Epoch 66, Loss G: 0.4687, Loss D: 1.4597\n",
      "epsilon is 1.6215931848818796, alpha is 16.0\n",
      "Epoch 67, Loss G: 0.4606, Loss D: 1.4740\n",
      "epsilon is 1.6347976132785484, alpha is 16.0\n",
      "Epoch 68, Loss G: 0.4518, Loss D: 1.4779\n",
      "epsilon is 1.648002041675217, alpha is 16.0\n",
      "Epoch 69, Loss G: 0.4544, Loss D: 1.4794\n",
      "epsilon is 1.6612064700718858, alpha is 16.0\n",
      "Epoch 70, Loss G: 0.4440, Loss D: 1.4783\n",
      "epsilon is 1.6744108984685546, alpha is 16.0\n",
      "Epoch 71, Loss G: 0.4506, Loss D: 1.4789\n",
      "epsilon is 1.6876153268652234, alpha is 16.0\n",
      "Epoch 72, Loss G: 0.4286, Loss D: 1.5049\n",
      "epsilon is 1.7007874311786957, alpha is 15.0\n",
      "Epoch 73, Loss G: 0.4283, Loss D: 1.5024\n",
      "epsilon is 1.7131563726401058, alpha is 15.0\n",
      "Epoch 74, Loss G: 0.4322, Loss D: 1.4977\n",
      "epsilon is 1.725525314101516, alpha is 15.0\n",
      "Epoch 75, Loss G: 0.4248, Loss D: 1.5058\n",
      "epsilon is 1.7378942555629264, alpha is 15.0\n",
      "Epoch 76, Loss G: 0.4220, Loss D: 1.5106\n",
      "epsilon is 1.7502631970243365, alpha is 15.0\n",
      "Epoch 77, Loss G: 0.4126, Loss D: 1.5199\n",
      "epsilon is 1.7626321384857466, alpha is 15.0\n",
      "Epoch 78, Loss G: 0.4116, Loss D: 1.5261\n",
      "epsilon is 1.775001079947157, alpha is 15.0\n",
      "Epoch 79, Loss G: 0.4107, Loss D: 1.5065\n",
      "epsilon is 1.7873700214085673, alpha is 15.0\n",
      "Epoch 80, Loss G: 0.3841, Loss D: 1.5506\n",
      "epsilon is 1.7997389628699774, alpha is 15.0\n",
      "Epoch 81, Loss G: 0.3864, Loss D: 1.5539\n",
      "epsilon is 1.8121079043313877, alpha is 15.0\n",
      "Epoch 82, Loss G: 0.3761, Loss D: 1.5522\n",
      "epsilon is 1.8244768457927978, alpha is 15.0\n",
      "Epoch 83, Loss G: 0.3775, Loss D: 1.5618\n",
      "epsilon is 1.836845787254208, alpha is 15.0\n",
      "Epoch 84, Loss G: 0.3821, Loss D: 1.5589\n",
      "epsilon is 1.8487595984423735, alpha is 14.0\n",
      "Epoch 85, Loss G: 0.3819, Loss D: 1.5453\n",
      "epsilon is 1.8602944354410622, alpha is 14.0\n",
      "Epoch 86, Loss G: 0.3758, Loss D: 1.5604\n",
      "epsilon is 1.871829272439751, alpha is 14.0\n",
      "Epoch 87, Loss G: 0.3823, Loss D: 1.5556\n",
      "epsilon is 1.8833641094384395, alpha is 14.0\n",
      "Epoch 88, Loss G: 0.3752, Loss D: 1.5656\n",
      "epsilon is 1.894898946437128, alpha is 14.0\n",
      "Epoch 89, Loss G: 0.3691, Loss D: 1.5710\n",
      "epsilon is 1.9064337834358167, alpha is 14.0\n",
      "Epoch 90, Loss G: 0.3681, Loss D: 1.5930\n",
      "epsilon is 1.9179686204345054, alpha is 14.0\n",
      "Epoch 91, Loss G: 0.3618, Loss D: 1.5636\n",
      "epsilon is 1.9295034574331937, alpha is 14.0\n",
      "Epoch 92, Loss G: 0.3570, Loss D: 1.5891\n",
      "epsilon is 1.9410382944318825, alpha is 14.0\n",
      "Epoch 93, Loss G: 0.3599, Loss D: 1.5983\n",
      "epsilon is 1.9525731314305712, alpha is 14.0\n",
      "Epoch 94, Loss G: 0.3532, Loss D: 1.6012\n",
      "epsilon is 1.9641079684292595, alpha is 14.0\n",
      "Epoch 95, Loss G: 0.3593, Loss D: 1.5978\n",
      "epsilon is 1.9756428054279482, alpha is 14.0\n",
      "Epoch 96, Loss G: 0.3571, Loss D: 1.5957\n",
      "epsilon is 1.987177642426637, alpha is 14.0\n",
      "Epoch 97, Loss G: 0.3438, Loss D: 1.5940\n",
      "epsilon is 1.9987124794253253, alpha is 14.0\n",
      "Epoch 98, Loss G: 0.3443, Loss D: 1.6190\n",
      "epsilon is 2.010170107439399, alpha is 13.0\n",
      "Epoch 99, Loss G: 0.3364, Loss D: 1.6170\n",
      "epsilon is 2.0208722178457883, alpha is 13.0\n",
      "Epoch 100, Loss G: 0.3347, Loss D: 1.6285\n",
      "epsilon is 2.031574328252178, alpha is 13.0\n",
      "Epoch 101, Loss G: 0.3431, Loss D: 1.6138\n",
      "epsilon is 2.0422764386585675, alpha is 13.0\n",
      "Epoch 102, Loss G: 0.3316, Loss D: 1.6293\n",
      "epsilon is 2.0529785490649566, alpha is 13.0\n",
      "Epoch 103, Loss G: 0.3314, Loss D: 1.6013\n",
      "epsilon is 2.063680659471346, alpha is 13.0\n",
      "Epoch 104, Loss G: 0.3236, Loss D: 1.6417\n",
      "epsilon is 2.0743827698777357, alpha is 13.0\n",
      "Epoch 105, Loss G: 0.3193, Loss D: 1.6228\n",
      "epsilon is 2.085084880284125, alpha is 13.0\n",
      "Epoch 106, Loss G: 0.3272, Loss D: 1.6360\n",
      "epsilon is 2.095786990690514, alpha is 13.0\n",
      "Epoch 107, Loss G: 0.3214, Loss D: 1.6546\n",
      "epsilon is 2.106489101096904, alpha is 13.0\n",
      "Epoch 108, Loss G: 0.3075, Loss D: 1.6618\n",
      "epsilon is 2.117191211503293, alpha is 13.0\n",
      "Epoch 109, Loss G: 0.3083, Loss D: 1.6678\n",
      "epsilon is 2.1278933219096823, alpha is 13.0\n",
      "Epoch 110, Loss G: 0.2983, Loss D: 1.6790\n",
      "epsilon is 2.138595432316072, alpha is 13.0\n",
      "Epoch 111, Loss G: 0.3085, Loss D: 1.6551\n",
      "epsilon is 2.1492975427224614, alpha is 13.0\n",
      "Epoch 112, Loss G: 0.3064, Loss D: 1.6612\n",
      "epsilon is 2.1599996531288506, alpha is 13.0\n",
      "Epoch 113, Loss G: 0.3032, Loss D: 1.6827\n",
      "epsilon is 2.17070176353524, alpha is 13.0\n",
      "Epoch 114, Loss G: 0.3021, Loss D: 1.6630\n",
      "epsilon is 2.1814038739416297, alpha is 13.0\n",
      "Epoch 115, Loss G: 0.2893, Loss D: 1.7081\n",
      "epsilon is 2.192105984348019, alpha is 13.0\n",
      "Epoch 116, Loss G: 0.2876, Loss D: 1.7253\n",
      "epsilon is 2.202808094754408, alpha is 13.0\n",
      "Epoch 117, Loss G: 0.2824, Loss D: 1.7292\n",
      "epsilon is 2.2130273542678722, alpha is 12.0\n",
      "Epoch 118, Loss G: 0.2673, Loss D: 1.7746\n",
      "epsilon is 2.2228981113743305, alpha is 12.0\n",
      "Epoch 119, Loss G: 0.2711, Loss D: 1.7499\n",
      "epsilon is 2.232768868480789, alpha is 12.0\n",
      "Epoch 120, Loss G: 0.2619, Loss D: 1.7578\n",
      "epsilon is 2.242639625587248, alpha is 12.0\n",
      "Epoch 121, Loss G: 0.2746, Loss D: 1.7276\n",
      "epsilon is 2.2525103826937065, alpha is 12.0\n",
      "Epoch 122, Loss G: 0.2708, Loss D: 1.7472\n",
      "epsilon is 2.2623811398001648, alpha is 12.0\n",
      "Epoch 123, Loss G: 0.2710, Loss D: 1.7727\n",
      "epsilon is 2.272251896906623, alpha is 12.0\n",
      "Epoch 124, Loss G: 0.2670, Loss D: 1.7677\n",
      "epsilon is 2.2821226540130817, alpha is 12.0\n",
      "Epoch 125, Loss G: 0.2638, Loss D: 1.7580\n",
      "epsilon is 2.2919934111195404, alpha is 12.0\n",
      "Epoch 126, Loss G: 0.2652, Loss D: 1.7703\n",
      "epsilon is 2.3018641682259986, alpha is 12.0\n",
      "Epoch 127, Loss G: 0.2650, Loss D: 1.7739\n",
      "epsilon is 2.311734925332457, alpha is 12.0\n",
      "Epoch 128, Loss G: 0.2544, Loss D: 1.7794\n",
      "epsilon is 2.3216056824389155, alpha is 12.0\n",
      "Epoch 129, Loss G: 0.2507, Loss D: 1.8051\n",
      "epsilon is 2.331476439545374, alpha is 12.0\n",
      "Epoch 130, Loss G: 0.2552, Loss D: 1.8208\n",
      "epsilon is 2.3413471966518324, alpha is 12.0\n",
      "Epoch 131, Loss G: 0.2475, Loss D: 1.8123\n",
      "epsilon is 2.3512179537582907, alpha is 12.0\n",
      "Epoch 132, Loss G: 0.2459, Loss D: 1.8386\n",
      "epsilon is 2.3610887108647494, alpha is 12.0\n",
      "Epoch 133, Loss G: 0.2072, Loss D: 1.9466\n",
      "epsilon is 2.370959467971208, alpha is 12.0\n",
      "Epoch 134, Loss G: 0.2080, Loss D: 1.9608\n",
      "epsilon is 2.3808302250776667, alpha is 12.0\n",
      "Epoch 135, Loss G: 0.2147, Loss D: 1.9305\n",
      "epsilon is 2.390700982184125, alpha is 12.0\n",
      "Epoch 136, Loss G: 0.1998, Loss D: 1.9440\n",
      "epsilon is 2.400571739290583, alpha is 12.0\n",
      "Epoch 137, Loss G: 0.2058, Loss D: 1.9595\n",
      "epsilon is 2.410442496397042, alpha is 12.0\n",
      "Epoch 138, Loss G: 0.2145, Loss D: 1.9375\n",
      "epsilon is 2.4203132535035006, alpha is 12.0\n",
      "Epoch 139, Loss G: 0.2118, Loss D: 1.9274\n",
      "epsilon is 2.430184010609959, alpha is 12.0\n",
      "Epoch 140, Loss G: 0.2117, Loss D: 1.9402\n",
      "epsilon is 2.440054767716417, alpha is 12.0\n",
      "Epoch 141, Loss G: 0.2002, Loss D: 1.9715\n",
      "epsilon is 2.4499255248228757, alpha is 12.0\n",
      "Epoch 142, Loss G: 0.1924, Loss D: 1.9607\n",
      "epsilon is 2.4597962819293344, alpha is 12.0\n",
      "Epoch 143, Loss G: 0.2042, Loss D: 1.9651\n",
      "epsilon is 2.468865728938444, alpha is 10.9\n",
      "Epoch 144, Loss G: 0.1961, Loss D: 1.9733\n",
      "epsilon is 2.4778235781329827, alpha is 10.9\n",
      "Epoch 145, Loss G: 0.1984, Loss D: 1.9557\n",
      "epsilon is 2.4867814273275215, alpha is 10.9\n",
      "Epoch 146, Loss G: 0.2018, Loss D: 1.9947\n",
      "epsilon is 2.49573927652206, alpha is 10.9\n",
      "Epoch 147, Loss G: 0.2046, Loss D: 1.9402\n",
      "epsilon is 2.504697125716598, alpha is 10.9\n",
      "Epoch 148, Loss G: 0.2059, Loss D: 1.9435\n",
      "epsilon is 2.5136549749111365, alpha is 10.9\n",
      "Epoch 149, Loss G: 0.2065, Loss D: 1.9538\n",
      "epsilon is 2.5226128241056753, alpha is 10.9\n",
      "Epoch 150, Loss G: 0.2161, Loss D: 1.9568\n",
      "epsilon is 2.531570673300214, alpha is 10.9\n",
      "Epoch 151, Loss G: 0.2162, Loss D: 1.9020\n",
      "epsilon is 2.5405285224947525, alpha is 10.9\n",
      "Epoch 152, Loss G: 0.2102, Loss D: 1.9141\n",
      "epsilon is 2.549486371689291, alpha is 10.9\n",
      "Epoch 153, Loss G: 0.2066, Loss D: 1.9736\n",
      "epsilon is 2.558444220883829, alpha is 10.9\n",
      "Epoch 154, Loss G: 0.2012, Loss D: 1.9313\n",
      "epsilon is 2.567402070078368, alpha is 10.9\n",
      "Epoch 155, Loss G: 0.2077, Loss D: 1.9489\n",
      "epsilon is 2.5763599192729068, alpha is 10.9\n",
      "Epoch 156, Loss G: 0.2071, Loss D: 1.9769\n",
      "epsilon is 2.585317768467445, alpha is 10.9\n",
      "Epoch 157, Loss G: 0.2016, Loss D: 1.9351\n",
      "epsilon is 2.5942756176619834, alpha is 10.9\n",
      "Epoch 158, Loss G: 0.2063, Loss D: 1.9473\n",
      "epsilon is 2.603233466856522, alpha is 10.9\n",
      "Epoch 159, Loss G: 0.1992, Loss D: 1.9640\n",
      "epsilon is 2.6121913160510606, alpha is 10.9\n",
      "Epoch 160, Loss G: 0.2129, Loss D: 1.9483\n",
      "epsilon is 2.6211491652455994, alpha is 10.9\n",
      "Epoch 161, Loss G: 0.1968, Loss D: 1.9677\n",
      "epsilon is 2.6300409045292916, alpha is 10.8\n",
      "Epoch 162, Loss G: 0.2000, Loss D: 1.9568\n",
      "epsilon is 2.6389158440111684, alpha is 10.8\n",
      "Epoch 163, Loss G: 0.1978, Loss D: 1.9772\n",
      "epsilon is 2.647790783493046, alpha is 10.8\n",
      "Epoch 164, Loss G: 0.2013, Loss D: 1.9876\n",
      "epsilon is 2.6566350004955486, alpha is 10.7\n",
      "Epoch 165, Loss G: 0.2068, Loss D: 1.9547\n",
      "epsilon is 2.6654270438977954, alpha is 10.7\n",
      "Epoch 166, Loss G: 0.2014, Loss D: 1.9644\n",
      "epsilon is 2.6742190873000427, alpha is 10.7\n",
      "Epoch 167, Loss G: 0.1980, Loss D: 1.9797\n",
      "epsilon is 2.68301113070229, alpha is 10.7\n",
      "Epoch 168, Loss G: 0.2039, Loss D: 1.9427\n",
      "epsilon is 2.6917340412633344, alpha is 10.6\n",
      "Epoch 169, Loss G: 0.2087, Loss D: 1.9426\n",
      "epsilon is 2.7004432022144638, alpha is 10.6\n",
      "Epoch 170, Loss G: 0.2040, Loss D: 1.9482\n",
      "epsilon is 2.7091523631655936, alpha is 10.6\n",
      "Epoch 171, Loss G: 0.2042, Loss D: 1.9263\n",
      "epsilon is 2.717846346590364, alpha is 10.5\n",
      "Epoch 172, Loss G: 0.2066, Loss D: 1.9560\n",
      "epsilon is 2.7264726387143794, alpha is 10.5\n",
      "Epoch 173, Loss G: 0.2104, Loss D: 1.9136\n",
      "epsilon is 2.7350989308383937, alpha is 10.5\n",
      "Epoch 174, Loss G: 0.1479, Loss D: 2.2602\n",
      "epsilon is 2.743725222962409, alpha is 10.5\n",
      "Epoch 175, Loss G: 0.1576, Loss D: 2.2139\n",
      "epsilon is 2.752317312925168, alpha is 10.4\n",
      "Epoch 176, Loss G: 0.1689, Loss D: 2.1487\n",
      "epsilon is 2.760860749841563, alpha is 10.4\n",
      "Epoch 177, Loss G: 0.1691, Loss D: 2.1563\n",
      "epsilon is 2.7694041867579577, alpha is 10.4\n",
      "Epoch 178, Loss G: 0.1677, Loss D: 2.1153\n",
      "epsilon is 2.7779476236743523, alpha is 10.4\n",
      "Epoch 179, Loss G: 0.1765, Loss D: 2.0332\n",
      "epsilon is 2.786448164009606, alpha is 10.3\n",
      "Epoch 180, Loss G: 0.1840, Loss D: 2.0202\n",
      "epsilon is 2.794908759333368, alpha is 10.3\n",
      "Epoch 181, Loss G: 0.1888, Loss D: 2.0076\n",
      "epsilon is 2.8033693546571303, alpha is 10.3\n",
      "Epoch 182, Loss G: 0.2071, Loss D: 1.9626\n",
      "epsilon is 2.811829949980892, alpha is 10.3\n",
      "Epoch 183, Loss G: 0.1955, Loss D: 1.9750\n",
      "epsilon is 2.8202497357528533, alpha is 10.2\n",
      "Epoch 184, Loss G: 0.1993, Loss D: 1.9686\n",
      "epsilon is 2.8286275030944688, alpha is 10.2\n",
      "Epoch 185, Loss G: 0.1940, Loss D: 2.0054\n",
      "epsilon is 2.837005270436084, alpha is 10.2\n",
      "Epoch 186, Loss G: 0.1961, Loss D: 1.9994\n",
      "epsilon is 2.8453830377776996, alpha is 10.2\n",
      "Epoch 187, Loss G: 0.2024, Loss D: 1.9796\n",
      "epsilon is 2.8537333403634495, alpha is 10.1\n",
      "Epoch 188, Loss G: 0.2005, Loss D: 1.9750\n",
      "epsilon is 2.8620282933289034, alpha is 10.1\n",
      "Epoch 189, Loss G: 0.2042, Loss D: 1.9799\n",
      "epsilon is 2.870323246294357, alpha is 10.1\n",
      "Epoch 190, Loss G: 0.1895, Loss D: 2.0438\n",
      "epsilon is 2.878618199259811, alpha is 10.1\n",
      "Epoch 191, Loss G: 0.1869, Loss D: 2.0348\n",
      "epsilon is 2.8869107931218054, alpha is 10.0\n",
      "Epoch 192, Loss G: 0.1860, Loss D: 2.0146\n",
      "epsilon is 2.895122945312584, alpha is 10.0\n",
      "Epoch 193, Loss G: 0.1878, Loss D: 2.0327\n",
      "epsilon is 2.9033350975033625, alpha is 10.0\n",
      "Epoch 194, Loss G: 0.1841, Loss D: 2.0406\n",
      "epsilon is 2.911547249694141, alpha is 10.0\n",
      "Epoch 195, Loss G: 0.1913, Loss D: 2.0093\n",
      "epsilon is 2.9197594018849196, alpha is 10.0\n",
      "Epoch 196, Loss G: 0.1836, Loss D: 2.0381\n",
      "epsilon is 2.9279238059859876, alpha is 9.9\n",
      "Epoch 197, Loss G: 0.1802, Loss D: 2.0611\n",
      "epsilon is 2.936053170999078, alpha is 9.9\n",
      "Epoch 198, Loss G: 0.1804, Loss D: 2.0417\n",
      "epsilon is 2.9441825360121685, alpha is 9.9\n",
      "Epoch 199, Loss G: 0.1834, Loss D: 1.9915\n",
      "epsilon is 2.9523119010252588, alpha is 9.9\n",
      "Epoch 200, Loss G: 0.1885, Loss D: 2.0151\n",
      "epsilon is 2.960441266038349, alpha is 9.9\n",
      "Epoch 201, Loss G: 0.1919, Loss D: 2.0289\n",
      "epsilon is 2.968490375944482, alpha is 9.8\n",
      "Epoch 202, Loss G: 0.1776, Loss D: 2.0434\n",
      "epsilon is 2.9765369673723807, alpha is 9.8\n",
      "Epoch 203, Loss G: 0.1863, Loss D: 2.0581\n",
      "epsilon is 2.9845835588002787, alpha is 9.8\n",
      "Epoch 204, Loss G: 0.1778, Loss D: 2.0456\n",
      "epsilon is 2.9926301502281776, alpha is 9.8\n",
      "Epoch 205, Loss G: 0.1860, Loss D: 2.0686\n",
      "epsilon is 3.0006602164148797, alpha is 9.7\n",
      "Epoch 206, Loss G: 0.1815, Loss D: 2.0319\n",
      "epsilon is 3.008624047845589, alpha is 9.7\n",
      "Epoch 207, Loss G: 0.1882, Loss D: 2.0628\n",
      "epsilon is 3.0165878792762992, alpha is 9.7\n",
      "Epoch 208, Loss G: 0.1934, Loss D: 2.0156\n",
      "epsilon is 3.024551710707009, alpha is 9.7\n",
      "Epoch 209, Loss G: 0.1913, Loss D: 2.0116\n",
      "epsilon is 3.032515542137719, alpha is 9.7\n",
      "Epoch 210, Loss G: 0.1969, Loss D: 2.0019\n",
      "epsilon is 3.040457911405058, alpha is 9.6\n",
      "Epoch 211, Loss G: 0.1834, Loss D: 2.0403\n",
      "epsilon is 3.0483389964220944, alpha is 9.6\n",
      "Epoch 212, Loss G: 0.1866, Loss D: 2.0707\n",
      "epsilon is 3.0562200814391307, alpha is 9.6\n",
      "Epoch 213, Loss G: 0.1600, Loss D: 2.1442\n",
      "epsilon is 3.064101166456167, alpha is 9.6\n",
      "Epoch 214, Loss G: 0.1724, Loss D: 2.0955\n",
      "epsilon is 3.071982251473203, alpha is 9.6\n",
      "Epoch 215, Loss G: 0.1806, Loss D: 2.0723\n",
      "epsilon is 3.079851711588741, alpha is 9.5\n",
      "Epoch 216, Loss G: 0.1862, Loss D: 2.0612\n",
      "epsilon is 3.087650063771131, alpha is 9.5\n",
      "Epoch 217, Loss G: 0.1880, Loss D: 2.0294\n",
      "epsilon is 3.0954484159535216, alpha is 9.5\n",
      "Epoch 218, Loss G: 0.1934, Loss D: 1.9956\n",
      "epsilon is 3.103246768135912, alpha is 9.5\n",
      "Epoch 219, Loss G: 0.1894, Loss D: 1.9927\n",
      "epsilon is 3.1110451203183023, alpha is 9.5\n",
      "Epoch 220, Loss G: 0.1818, Loss D: 1.9997\n",
      "epsilon is 3.118843472500693, alpha is 9.5\n",
      "Epoch 221, Loss G: 0.1906, Loss D: 2.0352\n",
      "epsilon is 3.1265727995362274, alpha is 9.4\n",
      "Epoch 222, Loss G: 0.1877, Loss D: 2.0070\n",
      "epsilon is 3.1342884324585136, alpha is 9.4\n",
      "Epoch 223, Loss G: 0.1928, Loss D: 2.0332\n",
      "epsilon is 3.1420040653807995, alpha is 9.4\n",
      "Epoch 224, Loss G: 0.1924, Loss D: 1.9874\n",
      "epsilon is 3.1497196983030857, alpha is 9.4\n",
      "Epoch 225, Loss G: 0.1874, Loss D: 2.0456\n",
      "epsilon is 3.157435331225372, alpha is 9.4\n",
      "Epoch 226, Loss G: 0.1835, Loss D: 2.0055\n",
      "epsilon is 3.1651235040210497, alpha is 9.3\n",
      "Epoch 227, Loss G: 0.1841, Loss D: 2.0339\n",
      "epsilon is 3.172756431253293, alpha is 9.3\n",
      "Epoch 228, Loss G: 0.1833, Loss D: 2.0250\n",
      "epsilon is 3.1803893584855367, alpha is 9.3\n",
      "Epoch 229, Loss G: 0.1875, Loss D: 2.0057\n",
      "epsilon is 3.1880222857177802, alpha is 9.3\n",
      "Epoch 230, Loss G: 0.1923, Loss D: 2.0027\n",
      "epsilon is 3.1956552129500237, alpha is 9.3\n",
      "Epoch 231, Loss G: 0.1946, Loss D: 2.0221\n",
      "epsilon is 3.2032881401822673, alpha is 9.3\n",
      "Epoch 232, Loss G: 0.1937, Loss D: 2.0104\n",
      "epsilon is 3.210869509591073, alpha is 9.2\n",
      "Epoch 233, Loss G: 0.1961, Loss D: 1.9963\n",
      "epsilon is 3.2184197446988536, alpha is 9.2\n",
      "Epoch 234, Loss G: 0.1800, Loss D: 2.0685\n",
      "epsilon is 3.225969979806634, alpha is 9.2\n",
      "Epoch 235, Loss G: 0.1726, Loss D: 2.0934\n",
      "epsilon is 3.233520214914414, alpha is 9.2\n",
      "Epoch 236, Loss G: 0.1795, Loss D: 2.0654\n",
      "epsilon is 3.2410704500221947, alpha is 9.2\n",
      "Epoch 237, Loss G: 0.1769, Loss D: 2.0382\n",
      "epsilon is 3.248620685129975, alpha is 9.2\n",
      "Epoch 238, Loss G: 0.1839, Loss D: 2.0298\n",
      "epsilon is 3.2561131679803137, alpha is 9.1\n",
      "Epoch 239, Loss G: 0.1885, Loss D: 2.0476\n",
      "epsilon is 3.263580724524734, alpha is 9.1\n",
      "Epoch 240, Loss G: 0.1847, Loss D: 2.0294\n",
      "epsilon is 3.271048281069154, alpha is 9.1\n",
      "Epoch 241, Loss G: 0.1912, Loss D: 1.9907\n",
      "epsilon is 3.2785158376135746, alpha is 9.1\n",
      "Epoch 242, Loss G: 0.1931, Loss D: 2.0010\n",
      "epsilon is 3.285983394157995, alpha is 9.1\n",
      "Epoch 243, Loss G: 0.1781, Loss D: 2.0601\n",
      "epsilon is 3.293450950702415, alpha is 9.1\n",
      "Epoch 244, Loss G: 0.1828, Loss D: 2.0157\n",
      "epsilon is 3.300873364057096, alpha is 9.0\n",
      "Epoch 245, Loss G: 0.1792, Loss D: 2.0234\n",
      "epsilon is 3.308258255594784, alpha is 9.0\n",
      "Epoch 246, Loss G: 0.1823, Loss D: 2.0332\n",
      "epsilon is 3.3156431471324717, alpha is 9.0\n",
      "Epoch 247, Loss G: 0.1868, Loss D: 1.9870\n",
      "epsilon is 3.323028038670159, alpha is 9.0\n",
      "Epoch 248, Loss G: 0.1834, Loss D: 2.0396\n",
      "epsilon is 3.3304129302078462, alpha is 9.0\n",
      "Epoch 249, Loss G: 0.1845, Loss D: 2.0350\n",
      "epsilon is 3.337797821745534, alpha is 9.0\n",
      "Epoch 250, Loss G: 0.1832, Loss D: 2.0394\n",
      "epsilon is 3.345169940522746, alpha is 8.9\n",
      "Epoch 251, Loss G: 0.1788, Loss D: 2.0112\n",
      "epsilon is 3.3524721806058553, alpha is 8.9\n",
      "Epoch 252, Loss G: 0.1803, Loss D: 2.0463\n",
      "epsilon is 3.3597744206889635, alpha is 8.9\n",
      "Epoch 253, Loss G: 0.1840, Loss D: 2.0630\n",
      "epsilon is 3.3670766607720717, alpha is 8.9\n",
      "Epoch 254, Loss G: 0.1739, Loss D: 2.0442\n",
      "epsilon is 3.3743789008551803, alpha is 8.9\n",
      "Epoch 255, Loss G: 0.1819, Loss D: 2.0239\n",
      "epsilon is 3.381681140938289, alpha is 8.9\n",
      "Epoch 256, Loss G: 0.1812, Loss D: 2.0539\n",
      "epsilon is 3.388983381021397, alpha is 8.9\n",
      "Epoch 257, Loss G: 0.1673, Loss D: 2.1203\n",
      "epsilon is 3.396243362180573, alpha is 8.8\n",
      "Epoch 258, Loss G: 0.1743, Loss D: 2.1028\n",
      "epsilon is 3.403462964356787, alpha is 8.8\n",
      "Epoch 259, Loss G: 0.1817, Loss D: 2.0577\n",
      "epsilon is 3.410682566533001, alpha is 8.8\n",
      "Epoch 260, Loss G: 0.1826, Loss D: 2.0467\n",
      "epsilon is 3.4179021687092153, alpha is 8.8\n",
      "Epoch 261, Loss G: 0.1765, Loss D: 2.1034\n",
      "epsilon is 3.4251217708854296, alpha is 8.8\n",
      "Epoch 262, Loss G: 0.1749, Loss D: 2.0599\n",
      "epsilon is 3.4323413730616434, alpha is 8.8\n",
      "Epoch 263, Loss G: 0.1808, Loss D: 2.0435\n",
      "epsilon is 3.4395609752378573, alpha is 8.8\n",
      "Epoch 264, Loss G: 0.1765, Loss D: 2.0617\n",
      "epsilon is 3.4467307276511234, alpha is 8.7\n",
      "Epoch 265, Loss G: 0.1714, Loss D: 2.0654\n",
      "epsilon is 3.4538677054636566, alpha is 8.7\n",
      "Epoch 266, Loss G: 0.1759, Loss D: 2.0943\n",
      "epsilon is 3.4610046832761907, alpha is 8.7\n",
      "Epoch 267, Loss G: 0.1817, Loss D: 2.0825\n",
      "epsilon is 3.468141661088724, alpha is 8.7\n",
      "Epoch 268, Loss G: 0.1792, Loss D: 2.0455\n",
      "epsilon is 3.475278638901257, alpha is 8.7\n",
      "Epoch 269, Loss G: 0.1787, Loss D: 2.0625\n",
      "epsilon is 3.482415616713791, alpha is 8.7\n",
      "Epoch 270, Loss G: 0.1774, Loss D: 2.0310\n",
      "epsilon is 3.4895525945263244, alpha is 8.7\n",
      "Epoch 271, Loss G: 0.1808, Loss D: 2.0416\n",
      "epsilon is 3.496655186280539, alpha is 8.6\n",
      "Epoch 272, Loss G: 0.1873, Loss D: 2.0352\n",
      "epsilon is 3.5037095532681426, alpha is 8.6\n",
      "Epoch 273, Loss G: 0.1798, Loss D: 2.0415\n",
      "epsilon is 3.5107639202557466, alpha is 8.6\n",
      "Epoch 274, Loss G: 0.1808, Loss D: 2.0450\n",
      "epsilon is 3.5178182872433497, alpha is 8.6\n",
      "Epoch 275, Loss G: 0.1774, Loss D: 2.0460\n",
      "epsilon is 3.5248726542309536, alpha is 8.6\n",
      "Epoch 276, Loss G: 0.1655, Loss D: 2.1042\n",
      "epsilon is 3.531927021218557, alpha is 8.6\n",
      "Epoch 277, Loss G: 0.1806, Loss D: 2.0387\n",
      "epsilon is 3.5389813882061607, alpha is 8.6\n",
      "Epoch 278, Loss G: 0.1804, Loss D: 2.0762\n",
      "epsilon is 3.5460357551937647, alpha is 8.6\n",
      "Epoch 279, Loss G: 0.1679, Loss D: 2.1062\n",
      "epsilon is 3.5530128944381025, alpha is 8.5\n",
      "Epoch 280, Loss G: 0.1681, Loss D: 2.1262\n",
      "epsilon is 3.5599846641350603, alpha is 8.5\n",
      "Epoch 281, Loss G: 0.1717, Loss D: 2.0817\n",
      "epsilon is 3.5669564338320185, alpha is 8.5\n",
      "Epoch 282, Loss G: 0.1754, Loss D: 2.0759\n",
      "epsilon is 3.5739282035289768, alpha is 8.5\n",
      "Epoch 283, Loss G: 0.1833, Loss D: 2.0033\n",
      "epsilon is 3.5808999732259346, alpha is 8.5\n",
      "Epoch 284, Loss G: 0.1826, Loss D: 2.0722\n",
      "epsilon is 3.587871742922893, alpha is 8.5\n",
      "Epoch 285, Loss G: 0.1790, Loss D: 2.0370\n",
      "epsilon is 3.594843512619851, alpha is 8.5\n",
      "Epoch 286, Loss G: 0.1779, Loss D: 2.0982\n",
      "epsilon is 3.6018034375018138, alpha is 8.4\n",
      "Epoch 287, Loss G: 0.1722, Loss D: 2.0639\n",
      "epsilon is 3.608692623437951, alpha is 8.4\n",
      "Epoch 288, Loss G: 0.1767, Loss D: 2.0671\n",
      "epsilon is 3.615581809374088, alpha is 8.4\n",
      "Epoch 289, Loss G: 0.1717, Loss D: 2.0771\n",
      "epsilon is 3.622470995310225, alpha is 8.4\n",
      "Epoch 290, Loss G: 0.1752, Loss D: 2.0574\n",
      "epsilon is 3.629360181246362, alpha is 8.4\n",
      "Epoch 291, Loss G: 0.1764, Loss D: 2.0835\n",
      "epsilon is 3.636249367182499, alpha is 8.4\n",
      "Epoch 292, Loss G: 0.1834, Loss D: 2.0181\n",
      "epsilon is 3.6431385531186358, alpha is 8.4\n",
      "Epoch 293, Loss G: 0.1766, Loss D: 2.0496\n",
      "epsilon is 3.6500277390547726, alpha is 8.4\n",
      "Epoch 294, Loss G: 0.1890, Loss D: 2.0685\n",
      "epsilon is 3.656914920086205, alpha is 8.3\n",
      "Epoch 295, Loss G: 0.1734, Loss D: 2.0752\n",
      "epsilon is 3.663721535786885, alpha is 8.3\n",
      "Epoch 296, Loss G: 0.1851, Loss D: 2.0445\n",
      "epsilon is 3.6705281514875647, alpha is 8.3\n",
      "Epoch 297, Loss G: 0.1806, Loss D: 2.0393\n",
      "epsilon is 3.6773347671882446, alpha is 8.3\n",
      "Epoch 298, Loss G: 0.1804, Loss D: 2.0443\n",
      "epsilon is 3.684141382888925, alpha is 8.3\n",
      "Epoch 299, Loss G: 0.1909, Loss D: 2.0438\n",
      "epsilon is 3.6909479985896048, alpha is 8.3\n",
      "Epoch 300, Loss G: 0.1859, Loss D: 2.0059\n",
      "epsilon is 3.6977546142902846, alpha is 8.3\n",
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 922.3926 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 25005 rows (same as raw) in 2.5071 sec.\n",
      "Now is Postprocessor with default-smartnoise...\n",
      "Now is Evaluator with anonymeter-singlingout_univariate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.0009585236406264672, baseline = 0.0009585236406264672. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is 20240322_exp7[Report]_anonymeter-singlingout_univariate_[global] save to csv...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with anonymeter-linkability...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.0009585236406264672, baseline = 0.0009585236406264672. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is 20240322_exp7[Report]_anonymeter-linkability_[global] save to csv...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with anonymeter-inference...\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is 20240322_exp7[Report]_anonymeter-inference_[global] save to csv...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with sdmetrics-diag...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|| 13/13 [00:00<00:00, 529.31it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|| 1/1 [00:00<00:00, 571.04it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is 20240321_exp7[Report]_sdmetrics-diag_[columnwise] save to csv...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with sdmetrics-qual...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|| 13/13 [00:00<00:00, 200.62it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|| 78/78 [00:03<00:00, 24.57it/s]\n",
      "\n",
      "Overall Score: 61.61%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 72.08%\n",
      "- Column Pair Trends: 51.14%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is 20240321_exp7[Report]_sdmetrics-qual_[columnwise] save to csv...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Regression: 100%|| 5/5 [02:07<00:00, 25.42s/it]\n",
      "Regression: 100%|| 5/5 [01:28<00:00, 17.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is 20240321_exp7[Report]_automl-regression_[global] save to csv...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classification: 100%|| 5/5 [05:09<00:00, 61.87s/it]\n",
      "Classification: 100%|| 5/5 [01:12<00:00, 14.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is 20240321_exp7[Report]_automl-classification_[global] save to csv...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering: 100%|| 5/5 [00:11<00:00,  2.36s/it]\n",
      "Clustering: 100%|| 5/5 [00:06<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan10]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is 20240321_exp7[Report]_automl-cluster_[global] save to csv...\n",
      "Now is Synthesizer with smartnoise-dpctgan5...\n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1352: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.6569, Loss D: 1.4162\n",
      "epsilon is 0.16217888283723578, alpha is 63.0\n",
      "Epoch 2, Loss G: 0.6812, Loss D: 1.3940\n",
      "epsilon is 0.2163014051914117, alpha is 63.0\n",
      "Epoch 3, Loss G: 0.6894, Loss D: 1.3898\n",
      "epsilon is 0.27042392754558764, alpha is 63.0\n",
      "Epoch 4, Loss G: 0.6712, Loss D: 1.3948\n",
      "epsilon is 0.3245464498997635, alpha is 63.0\n",
      "Epoch 5, Loss G: 0.6592, Loss D: 1.3926\n",
      "epsilon is 0.376197456841065, alpha is 57.0\n",
      "Epoch 6, Loss G: 0.6590, Loss D: 1.3853\n",
      "epsilon is 0.4221411479824565, alpha is 51.0\n",
      "Epoch 7, Loss G: 0.6567, Loss D: 1.3806\n",
      "epsilon is 0.4639167774251823, alpha is 47.0\n",
      "Epoch 8, Loss G: 0.6438, Loss D: 1.3917\n",
      "epsilon is 0.5025193987805284, alpha is 44.0\n",
      "Epoch 9, Loss G: 0.6463, Loss D: 1.3945\n",
      "epsilon is 0.5386576819634908, alpha is 42.0\n",
      "Epoch 10, Loss G: 0.6479, Loss D: 1.3965\n",
      "epsilon is 0.5726766764984677, alpha is 39.0\n",
      "Epoch 11, Loss G: 0.6474, Loss D: 1.3987\n",
      "epsilon is 0.6050111960332332, alpha is 38.0\n",
      "Epoch 12, Loss G: 0.6458, Loss D: 1.3907\n",
      "epsilon is 0.6357796528187886, alpha is 36.0\n",
      "Epoch 13, Loss G: 0.6399, Loss D: 1.3978\n",
      "epsilon is 0.6653871970718096, alpha is 35.0\n",
      "Epoch 14, Loss G: 0.6413, Loss D: 1.3970\n",
      "epsilon is 0.6937671433528385, alpha is 33.0\n",
      "Epoch 15, Loss G: 0.6428, Loss D: 1.3968\n",
      "epsilon is 0.7211585434841012, alpha is 32.0\n",
      "Epoch 16, Loss G: 0.6426, Loss D: 1.3941\n",
      "epsilon is 0.7476730058511001, alpha is 31.0\n",
      "Epoch 17, Loss G: 0.6362, Loss D: 1.3975\n",
      "epsilon is 0.7734020455693197, alpha is 30.0\n",
      "Epoch 18, Loss G: 0.6407, Loss D: 1.3938\n",
      "epsilon is 0.7984498642333995, alpha is 29.0\n",
      "Epoch 19, Loss G: 0.6285, Loss D: 1.3983\n",
      "epsilon is 0.8226435666650334, alpha is 29.0\n",
      "Epoch 20, Loss G: 0.6275, Loss D: 1.4072\n",
      "epsilon is 0.8462755532142662, alpha is 28.0\n",
      "Epoch 21, Loss G: 0.6307, Loss D: 1.4038\n",
      "epsilon is 0.8694843445807604, alpha is 27.0\n",
      "Epoch 22, Loss G: 0.6281, Loss D: 1.3959\n",
      "epsilon is 0.8919717132862962, alpha is 27.0\n",
      "Epoch 23, Loss G: 0.6165, Loss D: 1.3995\n",
      "epsilon is 0.9140652932933118, alpha is 26.0\n",
      "Epoch 24, Loss G: 0.6161, Loss D: 1.3979\n",
      "epsilon is 0.9357016570631423, alpha is 26.0\n",
      "Epoch 25, Loss G: 0.5989, Loss D: 1.4073\n",
      "epsilon is 0.9568681678637022, alpha is 25.0\n",
      "Epoch 26, Loss G: 0.5914, Loss D: 1.4067\n",
      "epsilon is 0.9776549614336737, alpha is 25.0\n",
      "Epoch 27, Loss G: 0.5935, Loss D: 1.4001\n",
      "epsilon is 0.9981146214609729, alpha is 24.0\n",
      "Epoch 28, Loss G: 0.5919, Loss D: 1.4024\n",
      "epsilon is 1.0180532746880684, alpha is 24.0\n",
      "Epoch 29, Loss G: 0.5763, Loss D: 1.4078\n",
      "epsilon is 1.037991927915164, alpha is 24.0\n",
      "Epoch 30, Loss G: 0.5768, Loss D: 1.4080\n",
      "epsilon is 1.0571577275507311, alpha is 23.0\n",
      "Epoch 31, Loss G: 0.5735, Loss D: 1.4117\n",
      "epsilon is 1.0762496654391702, alpha is 23.0\n",
      "Epoch 32, Loss G: 0.5688, Loss D: 1.4116\n",
      "epsilon is 1.0952784885458546, alpha is 22.0\n",
      "Epoch 33, Loss G: 0.5666, Loss D: 1.4115\n",
      "epsilon is 1.1135251312730043, alpha is 22.0\n",
      "Epoch 34, Loss G: 0.5685, Loss D: 1.4102\n",
      "epsilon is 1.131771774000154, alpha is 22.0\n",
      "Epoch 35, Loss G: 0.5656, Loss D: 1.4147\n",
      "epsilon is 1.150018416727304, alpha is 22.0\n",
      "Epoch 36, Loss G: 0.5699, Loss D: 1.4023\n",
      "epsilon is 1.1675927482064763, alpha is 21.0\n",
      "Epoch 37, Loss G: 0.5556, Loss D: 1.4140\n",
      "epsilon is 1.184995511148565, alpha is 21.0\n",
      "Epoch 38, Loss G: 0.5590, Loss D: 1.4215\n",
      "epsilon is 1.2023982740906538, alpha is 21.0\n",
      "Epoch 39, Loss G: 0.5582, Loss D: 1.4178\n",
      "epsilon is 1.2198010370327423, alpha is 21.0\n",
      "Epoch 40, Loss G: 0.5559, Loss D: 1.4194\n",
      "epsilon is 1.236374707014578, alpha is 20.0\n",
      "Epoch 41, Loss G: 0.5479, Loss D: 1.4219\n",
      "epsilon is 1.2529350007722229, alpha is 20.0\n",
      "Epoch 42, Loss G: 0.5446, Loss D: 1.4153\n",
      "epsilon is 1.2694952945298679, alpha is 20.0\n",
      "Epoch 43, Loss G: 0.5432, Loss D: 1.4278\n",
      "epsilon is 1.2860555882875129, alpha is 20.0\n",
      "Epoch 44, Loss G: 0.5361, Loss D: 1.4281\n",
      "epsilon is 1.3021823339760972, alpha is 19.0\n",
      "Epoch 45, Loss G: 0.5339, Loss D: 1.4307\n",
      "epsilon is 1.3179015643996395, alpha is 19.0\n",
      "Epoch 46, Loss G: 0.5218, Loss D: 1.4359\n",
      "epsilon is 1.3336207948231817, alpha is 19.0\n",
      "Epoch 47, Loss G: 0.5176, Loss D: 1.4281\n",
      "epsilon is 1.3493400252467238, alpha is 19.0\n",
      "Epoch 48, Loss G: 0.5172, Loss D: 1.4298\n",
      "epsilon is 1.3650592556702659, alpha is 19.0\n",
      "Epoch 49, Loss G: 0.5113, Loss D: 1.4349\n",
      "epsilon is 1.3805829115154877, alpha is 18.0\n",
      "Epoch 50, Loss G: 0.5124, Loss D: 1.4372\n",
      "epsilon is 1.3954624797301436, alpha is 18.0\n",
      "Epoch 51, Loss G: 0.5042, Loss D: 1.4397\n",
      "epsilon is 1.410342047944799, alpha is 18.0\n",
      "Epoch 52, Loss G: 0.5086, Loss D: 1.4366\n",
      "epsilon is 1.4252216161594549, alpha is 18.0\n",
      "Epoch 53, Loss G: 0.5044, Loss D: 1.4297\n",
      "epsilon is 1.4401011843741107, alpha is 18.0\n",
      "Epoch 54, Loss G: 0.5080, Loss D: 1.4354\n",
      "epsilon is 1.4549807525887664, alpha is 18.0\n",
      "Epoch 55, Loss G: 0.5094, Loss D: 1.4388\n",
      "epsilon is 1.469860320803422, alpha is 18.0\n",
      "Epoch 56, Loss G: 0.5147, Loss D: 1.4323\n",
      "epsilon is 1.4839615919866171, alpha is 17.0\n",
      "Epoch 57, Loss G: 0.5128, Loss D: 1.4453\n",
      "epsilon is 1.4980028944174417, alpha is 17.0\n",
      "Epoch 58, Loss G: 0.5141, Loss D: 1.4410\n",
      "epsilon is 1.5120441968482663, alpha is 17.0\n",
      "Epoch 59, Loss G: 0.4998, Loss D: 1.4519\n",
      "epsilon is 1.5260854992790907, alpha is 17.0\n",
      "Epoch 60, Loss G: 0.4907, Loss D: 1.4461\n",
      "epsilon is 1.540126801709915, alpha is 17.0\n",
      "Epoch 61, Loss G: 0.4869, Loss D: 1.4522\n",
      "epsilon is 1.5541681041407396, alpha is 17.0\n",
      "Epoch 62, Loss G: 0.4811, Loss D: 1.4510\n",
      "epsilon is 1.5682094065715642, alpha is 17.0\n",
      "Epoch 63, Loss G: 0.4725, Loss D: 1.4657\n",
      "epsilon is 1.5819798996918735, alpha is 16.0\n",
      "Epoch 64, Loss G: 0.4744, Loss D: 1.4664\n",
      "epsilon is 1.5951843280885423, alpha is 16.0\n",
      "Epoch 65, Loss G: 0.4695, Loss D: 1.4581\n",
      "epsilon is 1.6083887564852108, alpha is 16.0\n",
      "Epoch 66, Loss G: 0.4680, Loss D: 1.4653\n",
      "epsilon is 1.6215931848818796, alpha is 16.0\n",
      "Epoch 67, Loss G: 0.4614, Loss D: 1.4675\n",
      "epsilon is 1.6347976132785484, alpha is 16.0\n",
      "Epoch 68, Loss G: 0.4721, Loss D: 1.4628\n",
      "epsilon is 1.648002041675217, alpha is 16.0\n",
      "Epoch 69, Loss G: 0.4608, Loss D: 1.4657\n",
      "epsilon is 1.6612064700718858, alpha is 16.0\n",
      "Epoch 70, Loss G: 0.4619, Loss D: 1.4748\n",
      "epsilon is 1.6744108984685546, alpha is 16.0\n",
      "Epoch 71, Loss G: 0.4608, Loss D: 1.4835\n",
      "epsilon is 1.6876153268652234, alpha is 16.0\n",
      "Epoch 72, Loss G: 0.4342, Loss D: 1.4946\n",
      "epsilon is 1.7007874311786957, alpha is 15.0\n",
      "Epoch 73, Loss G: 0.4449, Loss D: 1.4812\n",
      "epsilon is 1.7131563726401058, alpha is 15.0\n",
      "Epoch 74, Loss G: 0.4352, Loss D: 1.4956\n",
      "epsilon is 1.725525314101516, alpha is 15.0\n",
      "Epoch 75, Loss G: 0.4295, Loss D: 1.4985\n",
      "epsilon is 1.7378942555629264, alpha is 15.0\n",
      "Epoch 76, Loss G: 0.4299, Loss D: 1.4914\n",
      "epsilon is 1.7502631970243365, alpha is 15.0\n",
      "Epoch 77, Loss G: 0.4181, Loss D: 1.5148\n",
      "epsilon is 1.7626321384857466, alpha is 15.0\n",
      "Epoch 78, Loss G: 0.4103, Loss D: 1.5243\n",
      "epsilon is 1.775001079947157, alpha is 15.0\n",
      "Epoch 79, Loss G: 0.4130, Loss D: 1.5183\n",
      "epsilon is 1.7873700214085673, alpha is 15.0\n",
      "Epoch 80, Loss G: 0.4134, Loss D: 1.5065\n",
      "epsilon is 1.7997389628699774, alpha is 15.0\n",
      "Epoch 81, Loss G: 0.4195, Loss D: 1.5042\n",
      "epsilon is 1.8121079043313877, alpha is 15.0\n",
      "Epoch 82, Loss G: 0.4199, Loss D: 1.5072\n",
      "epsilon is 1.8244768457927978, alpha is 15.0\n",
      "Epoch 83, Loss G: 0.4226, Loss D: 1.5159\n",
      "epsilon is 1.836845787254208, alpha is 15.0\n",
      "Epoch 84, Loss G: 0.4237, Loss D: 1.4956\n",
      "epsilon is 1.8487595984423735, alpha is 14.0\n",
      "Epoch 85, Loss G: 0.4112, Loss D: 1.5275\n",
      "epsilon is 1.8602944354410622, alpha is 14.0\n",
      "Epoch 86, Loss G: 0.4112, Loss D: 1.5323\n",
      "epsilon is 1.871829272439751, alpha is 14.0\n",
      "Epoch 87, Loss G: 0.4044, Loss D: 1.5244\n",
      "epsilon is 1.8833641094384395, alpha is 14.0\n",
      "Epoch 88, Loss G: 0.3976, Loss D: 1.5266\n",
      "epsilon is 1.894898946437128, alpha is 14.0\n",
      "Epoch 89, Loss G: 0.4038, Loss D: 1.5107\n",
      "epsilon is 1.9064337834358167, alpha is 14.0\n",
      "Epoch 90, Loss G: 0.4064, Loss D: 1.5217\n",
      "epsilon is 1.9179686204345054, alpha is 14.0\n",
      "Epoch 91, Loss G: 0.4061, Loss D: 1.5292\n",
      "epsilon is 1.9295034574331937, alpha is 14.0\n",
      "Epoch 92, Loss G: 0.4016, Loss D: 1.5289\n",
      "epsilon is 1.9410382944318825, alpha is 14.0\n",
      "Epoch 93, Loss G: 0.3854, Loss D: 1.5511\n",
      "epsilon is 1.9525731314305712, alpha is 14.0\n",
      "Epoch 94, Loss G: 0.3822, Loss D: 1.5431\n",
      "epsilon is 1.9641079684292595, alpha is 14.0\n",
      "Epoch 95, Loss G: 0.3771, Loss D: 1.5790\n",
      "epsilon is 1.9756428054279482, alpha is 14.0\n",
      "Epoch 96, Loss G: 0.3710, Loss D: 1.5541\n",
      "epsilon is 1.987177642426637, alpha is 14.0\n",
      "Epoch 97, Loss G: 0.3608, Loss D: 1.5917\n",
      "epsilon is 1.9987124794253253, alpha is 14.0\n",
      "Epoch 98, Loss G: 0.3572, Loss D: 1.5981\n",
      "epsilon is 2.010170107439399, alpha is 13.0\n",
      "Epoch 99, Loss G: 0.3477, Loss D: 1.5826\n",
      "epsilon is 2.0208722178457883, alpha is 13.0\n",
      "Epoch 100, Loss G: 0.3480, Loss D: 1.5945\n",
      "epsilon is 2.031574328252178, alpha is 13.0\n",
      "Epoch 101, Loss G: 0.3567, Loss D: 1.5795\n",
      "epsilon is 2.0422764386585675, alpha is 13.0\n",
      "Epoch 102, Loss G: 0.3656, Loss D: 1.5740\n",
      "epsilon is 2.0529785490649566, alpha is 13.0\n",
      "Epoch 103, Loss G: 0.3611, Loss D: 1.5770\n",
      "epsilon is 2.063680659471346, alpha is 13.0\n",
      "Epoch 104, Loss G: 0.3591, Loss D: 1.5774\n",
      "epsilon is 2.0743827698777357, alpha is 13.0\n",
      "Epoch 105, Loss G: 0.3459, Loss D: 1.6120\n",
      "epsilon is 2.085084880284125, alpha is 13.0\n",
      "Epoch 106, Loss G: 0.3354, Loss D: 1.6149\n",
      "epsilon is 2.095786990690514, alpha is 13.0\n",
      "Epoch 107, Loss G: 0.3278, Loss D: 1.6331\n",
      "epsilon is 2.106489101096904, alpha is 13.0\n",
      "Epoch 108, Loss G: 0.3208, Loss D: 1.6345\n",
      "epsilon is 2.117191211503293, alpha is 13.0\n",
      "Epoch 109, Loss G: 0.3323, Loss D: 1.6218\n",
      "epsilon is 2.1278933219096823, alpha is 13.0\n",
      "Epoch 110, Loss G: 0.3352, Loss D: 1.6277\n",
      "epsilon is 2.138595432316072, alpha is 13.0\n",
      "Epoch 111, Loss G: 0.3318, Loss D: 1.6135\n",
      "epsilon is 2.1492975427224614, alpha is 13.0\n",
      "Epoch 112, Loss G: 0.3302, Loss D: 1.6185\n",
      "epsilon is 2.1599996531288506, alpha is 13.0\n",
      "Epoch 113, Loss G: 0.3264, Loss D: 1.6323\n",
      "epsilon is 2.17070176353524, alpha is 13.0\n",
      "Epoch 114, Loss G: 0.3293, Loss D: 1.6332\n",
      "epsilon is 2.1814038739416297, alpha is 13.0\n",
      "Epoch 115, Loss G: 0.3346, Loss D: 1.6368\n",
      "epsilon is 2.192105984348019, alpha is 13.0\n",
      "Epoch 116, Loss G: 0.3302, Loss D: 1.6566\n",
      "epsilon is 2.202808094754408, alpha is 13.0\n",
      "Epoch 117, Loss G: 0.3178, Loss D: 1.6664\n",
      "epsilon is 2.2130273542678722, alpha is 12.0\n",
      "Epoch 118, Loss G: 0.3091, Loss D: 1.6543\n",
      "epsilon is 2.2228981113743305, alpha is 12.0\n",
      "Epoch 119, Loss G: 0.3041, Loss D: 1.6901\n",
      "epsilon is 2.232768868480789, alpha is 12.0\n",
      "Epoch 120, Loss G: 0.3048, Loss D: 1.6760\n",
      "epsilon is 2.242639625587248, alpha is 12.0\n",
      "Epoch 121, Loss G: 0.3019, Loss D: 1.6774\n",
      "epsilon is 2.2525103826937065, alpha is 12.0\n",
      "Epoch 122, Loss G: 0.3067, Loss D: 1.6780\n",
      "epsilon is 2.2623811398001648, alpha is 12.0\n",
      "Epoch 123, Loss G: 0.3126, Loss D: 1.6775\n",
      "epsilon is 2.272251896906623, alpha is 12.0\n",
      "Epoch 124, Loss G: 0.3108, Loss D: 1.6995\n",
      "epsilon is 2.2821226540130817, alpha is 12.0\n",
      "Epoch 125, Loss G: 0.2923, Loss D: 1.6987\n",
      "epsilon is 2.2919934111195404, alpha is 12.0\n",
      "Epoch 126, Loss G: 0.2936, Loss D: 1.7071\n",
      "epsilon is 2.3018641682259986, alpha is 12.0\n",
      "Epoch 127, Loss G: 0.2972, Loss D: 1.7013\n",
      "epsilon is 2.311734925332457, alpha is 12.0\n",
      "Epoch 128, Loss G: 0.2961, Loss D: 1.7166\n",
      "epsilon is 2.3216056824389155, alpha is 12.0\n",
      "Epoch 129, Loss G: 0.2782, Loss D: 1.7402\n",
      "epsilon is 2.331476439545374, alpha is 12.0\n",
      "Epoch 130, Loss G: 0.2836, Loss D: 1.7214\n",
      "epsilon is 2.3413471966518324, alpha is 12.0\n",
      "Epoch 131, Loss G: 0.2785, Loss D: 1.7220\n",
      "epsilon is 2.3512179537582907, alpha is 12.0\n",
      "Epoch 132, Loss G: 0.2804, Loss D: 1.7328\n",
      "epsilon is 2.3610887108647494, alpha is 12.0\n",
      "Epoch 133, Loss G: 0.2812, Loss D: 1.7228\n",
      "epsilon is 2.370959467971208, alpha is 12.0\n",
      "Epoch 134, Loss G: 0.2812, Loss D: 1.7248\n",
      "epsilon is 2.3808302250776667, alpha is 12.0\n",
      "Epoch 135, Loss G: 0.2816, Loss D: 1.7247\n",
      "epsilon is 2.390700982184125, alpha is 12.0\n",
      "Epoch 136, Loss G: 0.2821, Loss D: 1.7397\n",
      "epsilon is 2.400571739290583, alpha is 12.0\n",
      "Epoch 137, Loss G: 0.2820, Loss D: 1.7232\n",
      "epsilon is 2.410442496397042, alpha is 12.0\n",
      "Epoch 138, Loss G: 0.2789, Loss D: 1.7566\n",
      "epsilon is 2.4203132535035006, alpha is 12.0\n",
      "Epoch 139, Loss G: 0.2694, Loss D: 1.7619\n",
      "epsilon is 2.430184010609959, alpha is 12.0\n",
      "Epoch 140, Loss G: 0.2813, Loss D: 1.7331\n",
      "epsilon is 2.440054767716417, alpha is 12.0\n",
      "Epoch 141, Loss G: 0.2570, Loss D: 1.7856\n",
      "epsilon is 2.4499255248228757, alpha is 12.0\n",
      "Epoch 142, Loss G: 0.2542, Loss D: 1.8126\n",
      "epsilon is 2.4597962819293344, alpha is 12.0\n",
      "Epoch 143, Loss G: 0.2495, Loss D: 1.8065\n",
      "epsilon is 2.468865728938444, alpha is 10.9\n",
      "Epoch 144, Loss G: 0.2570, Loss D: 1.7990\n",
      "epsilon is 2.4778235781329827, alpha is 10.9\n",
      "Epoch 145, Loss G: 0.2649, Loss D: 1.7748\n",
      "epsilon is 2.4867814273275215, alpha is 10.9\n",
      "Epoch 146, Loss G: 0.2659, Loss D: 1.7689\n",
      "epsilon is 2.49573927652206, alpha is 10.9\n",
      "Epoch 147, Loss G: 0.2698, Loss D: 1.7646\n",
      "epsilon is 2.504697125716598, alpha is 10.9\n",
      "Epoch 148, Loss G: 0.2743, Loss D: 1.7514\n",
      "epsilon is 2.5136549749111365, alpha is 10.9\n",
      "Epoch 149, Loss G: 0.2678, Loss D: 1.7719\n",
      "epsilon is 2.5226128241056753, alpha is 10.9\n",
      "Epoch 150, Loss G: 0.2650, Loss D: 1.7673\n",
      "epsilon is 2.531570673300214, alpha is 10.9\n",
      "Epoch 151, Loss G: 0.2454, Loss D: 1.8377\n",
      "epsilon is 2.5405285224947525, alpha is 10.9\n",
      "Epoch 152, Loss G: 0.2431, Loss D: 1.7887\n",
      "epsilon is 2.549486371689291, alpha is 10.9\n",
      "Epoch 153, Loss G: 0.2400, Loss D: 1.8314\n",
      "epsilon is 2.558444220883829, alpha is 10.9\n",
      "Epoch 154, Loss G: 0.2488, Loss D: 1.8397\n",
      "epsilon is 2.567402070078368, alpha is 10.9\n",
      "Epoch 155, Loss G: 0.2342, Loss D: 1.8571\n",
      "epsilon is 2.5763599192729068, alpha is 10.9\n",
      "Epoch 156, Loss G: 0.2390, Loss D: 1.8134\n",
      "epsilon is 2.585317768467445, alpha is 10.9\n",
      "Epoch 157, Loss G: 0.2384, Loss D: 1.8502\n",
      "epsilon is 2.5942756176619834, alpha is 10.9\n",
      "Epoch 158, Loss G: 0.2331, Loss D: 1.8631\n",
      "epsilon is 2.603233466856522, alpha is 10.9\n",
      "Epoch 159, Loss G: 0.2302, Loss D: 1.8510\n",
      "epsilon is 2.6121913160510606, alpha is 10.9\n",
      "Epoch 160, Loss G: 0.2335, Loss D: 1.8486\n",
      "epsilon is 2.6211491652455994, alpha is 10.9\n",
      "Epoch 161, Loss G: 0.2333, Loss D: 1.8436\n",
      "epsilon is 2.6300409045292916, alpha is 10.8\n",
      "Epoch 162, Loss G: 0.2363, Loss D: 1.8611\n",
      "epsilon is 2.6389158440111684, alpha is 10.8\n",
      "Epoch 163, Loss G: 0.2320, Loss D: 1.8359\n",
      "epsilon is 2.647790783493046, alpha is 10.8\n",
      "Epoch 164, Loss G: 0.2366, Loss D: 1.8552\n",
      "epsilon is 2.6566350004955486, alpha is 10.7\n",
      "Epoch 165, Loss G: 0.2285, Loss D: 1.8884\n",
      "epsilon is 2.6654270438977954, alpha is 10.7\n",
      "Epoch 166, Loss G: 0.2215, Loss D: 1.8648\n",
      "epsilon is 2.6742190873000427, alpha is 10.7\n",
      "Epoch 167, Loss G: 0.2250, Loss D: 1.9114\n",
      "epsilon is 2.68301113070229, alpha is 10.7\n",
      "Epoch 168, Loss G: 0.2157, Loss D: 1.8924\n",
      "epsilon is 2.6917340412633344, alpha is 10.6\n",
      "Epoch 169, Loss G: 0.2142, Loss D: 1.8888\n",
      "epsilon is 2.7004432022144638, alpha is 10.6\n",
      "Epoch 170, Loss G: 0.2239, Loss D: 1.8897\n",
      "epsilon is 2.7091523631655936, alpha is 10.6\n",
      "Epoch 171, Loss G: 0.2294, Loss D: 1.8347\n",
      "epsilon is 2.717846346590364, alpha is 10.5\n",
      "Epoch 172, Loss G: 0.2290, Loss D: 1.8806\n",
      "epsilon is 2.7264726387143794, alpha is 10.5\n",
      "Epoch 173, Loss G: 0.2295, Loss D: 1.8445\n",
      "epsilon is 2.7350989308383937, alpha is 10.5\n",
      "Epoch 174, Loss G: 0.2303, Loss D: 1.8451\n",
      "epsilon is 2.743725222962409, alpha is 10.5\n",
      "Epoch 175, Loss G: 0.2336, Loss D: 1.8571\n",
      "epsilon is 2.752317312925168, alpha is 10.4\n",
      "Epoch 176, Loss G: 0.2349, Loss D: 1.8437\n",
      "epsilon is 2.760860749841563, alpha is 10.4\n",
      "Epoch 177, Loss G: 0.2281, Loss D: 1.8597\n",
      "epsilon is 2.7694041867579577, alpha is 10.4\n",
      "Epoch 178, Loss G: 0.2309, Loss D: 1.8832\n",
      "epsilon is 2.7779476236743523, alpha is 10.4\n",
      "Epoch 179, Loss G: 0.2248, Loss D: 1.8794\n",
      "epsilon is 2.786448164009606, alpha is 10.3\n",
      "Epoch 180, Loss G: 0.2296, Loss D: 1.8884\n",
      "epsilon is 2.794908759333368, alpha is 10.3\n",
      "Epoch 181, Loss G: 0.2043, Loss D: 2.0268\n",
      "epsilon is 2.8033693546571303, alpha is 10.3\n",
      "Epoch 182, Loss G: 0.2116, Loss D: 1.9531\n",
      "epsilon is 2.811829949980892, alpha is 10.3\n",
      "Epoch 183, Loss G: 0.1998, Loss D: 1.9779\n",
      "epsilon is 2.8202497357528533, alpha is 10.2\n",
      "Epoch 184, Loss G: 0.2009, Loss D: 1.9799\n",
      "epsilon is 2.8286275030944688, alpha is 10.2\n",
      "Epoch 185, Loss G: 0.2145, Loss D: 1.9613\n",
      "epsilon is 2.837005270436084, alpha is 10.2\n",
      "Epoch 186, Loss G: 0.2138, Loss D: 1.9281\n",
      "epsilon is 2.8453830377776996, alpha is 10.2\n",
      "Epoch 187, Loss G: 0.2177, Loss D: 1.8769\n",
      "epsilon is 2.8537333403634495, alpha is 10.1\n",
      "Epoch 188, Loss G: 0.2213, Loss D: 1.8877\n",
      "epsilon is 2.8620282933289034, alpha is 10.1\n",
      "Epoch 189, Loss G: 0.2259, Loss D: 1.8902\n",
      "epsilon is 2.870323246294357, alpha is 10.1\n",
      "Epoch 190, Loss G: 0.2233, Loss D: 1.8969\n",
      "epsilon is 2.878618199259811, alpha is 10.1\n",
      "Epoch 191, Loss G: 0.2179, Loss D: 1.9111\n",
      "epsilon is 2.8869107931218054, alpha is 10.0\n",
      "Epoch 192, Loss G: 0.2200, Loss D: 1.8877\n",
      "epsilon is 2.895122945312584, alpha is 10.0\n",
      "Epoch 193, Loss G: 0.2187, Loss D: 1.8851\n",
      "epsilon is 2.9033350975033625, alpha is 10.0\n",
      "Epoch 194, Loss G: 0.2188, Loss D: 1.8964\n",
      "epsilon is 2.911547249694141, alpha is 10.0\n",
      "Epoch 195, Loss G: 0.2066, Loss D: 1.9565\n",
      "epsilon is 2.9197594018849196, alpha is 10.0\n",
      "Epoch 196, Loss G: 0.2152, Loss D: 1.9484\n",
      "epsilon is 2.9279238059859876, alpha is 9.9\n",
      "Epoch 197, Loss G: 0.2091, Loss D: 1.9507\n",
      "epsilon is 2.936053170999078, alpha is 9.9\n",
      "Epoch 198, Loss G: 0.2073, Loss D: 1.9094\n",
      "epsilon is 2.9441825360121685, alpha is 9.9\n",
      "Epoch 199, Loss G: 0.2090, Loss D: 1.9197\n",
      "epsilon is 2.9523119010252588, alpha is 9.9\n",
      "Epoch 200, Loss G: 0.2230, Loss D: 1.9323\n",
      "epsilon is 2.960441266038349, alpha is 9.9\n",
      "Epoch 201, Loss G: 0.2207, Loss D: 1.9281\n",
      "epsilon is 2.968490375944482, alpha is 9.8\n",
      "Epoch 202, Loss G: 0.2161, Loss D: 1.9026\n",
      "epsilon is 2.9765369673723807, alpha is 9.8\n",
      "Epoch 203, Loss G: 0.2112, Loss D: 1.9067\n",
      "epsilon is 2.9845835588002787, alpha is 9.8\n",
      "Epoch 204, Loss G: 0.2116, Loss D: 1.9108\n",
      "epsilon is 2.9926301502281776, alpha is 9.8\n",
      "Epoch 205, Loss G: 0.2129, Loss D: 1.9468\n",
      "epsilon is 3.0006602164148797, alpha is 9.7\n",
      "Epoch 206, Loss G: 0.2036, Loss D: 1.9314\n",
      "epsilon is 3.008624047845589, alpha is 9.7\n",
      "Epoch 207, Loss G: 0.2091, Loss D: 1.9357\n",
      "epsilon is 3.0165878792762992, alpha is 9.7\n",
      "Epoch 208, Loss G: 0.2129, Loss D: 1.9041\n",
      "epsilon is 3.024551710707009, alpha is 9.7\n",
      "Epoch 209, Loss G: 0.1938, Loss D: 2.0243\n",
      "epsilon is 3.032515542137719, alpha is 9.7\n",
      "Epoch 210, Loss G: 0.1806, Loss D: 2.0549\n",
      "epsilon is 3.040457911405058, alpha is 9.6\n",
      "Epoch 211, Loss G: 0.1896, Loss D: 2.0475\n",
      "epsilon is 3.0483389964220944, alpha is 9.6\n",
      "Epoch 212, Loss G: 0.1851, Loss D: 2.0337\n",
      "epsilon is 3.0562200814391307, alpha is 9.6\n",
      "Epoch 213, Loss G: 0.1833, Loss D: 2.0605\n",
      "epsilon is 3.064101166456167, alpha is 9.6\n",
      "Epoch 214, Loss G: 0.1896, Loss D: 2.0316\n",
      "epsilon is 3.071982251473203, alpha is 9.6\n",
      "Epoch 215, Loss G: 0.1818, Loss D: 2.0522\n",
      "epsilon is 3.079851711588741, alpha is 9.5\n",
      "Epoch 216, Loss G: 0.1863, Loss D: 2.0103\n",
      "epsilon is 3.087650063771131, alpha is 9.5\n",
      "Epoch 217, Loss G: 0.1912, Loss D: 2.0350\n",
      "epsilon is 3.0954484159535216, alpha is 9.5\n",
      "Epoch 218, Loss G: 0.2058, Loss D: 1.9920\n",
      "epsilon is 3.103246768135912, alpha is 9.5\n",
      "Epoch 219, Loss G: 0.1972, Loss D: 1.9656\n",
      "epsilon is 3.1110451203183023, alpha is 9.5\n",
      "Epoch 220, Loss G: 0.2086, Loss D: 1.9625\n",
      "epsilon is 3.118843472500693, alpha is 9.5\n",
      "Epoch 221, Loss G: 0.2027, Loss D: 1.9307\n",
      "epsilon is 3.1265727995362274, alpha is 9.4\n",
      "Epoch 222, Loss G: 0.2059, Loss D: 1.9382\n",
      "epsilon is 3.1342884324585136, alpha is 9.4\n",
      "Epoch 223, Loss G: 0.1998, Loss D: 1.9522\n",
      "epsilon is 3.1420040653807995, alpha is 9.4\n",
      "Epoch 224, Loss G: 0.2001, Loss D: 1.9609\n",
      "epsilon is 3.1497196983030857, alpha is 9.4\n",
      "Epoch 225, Loss G: 0.1993, Loss D: 1.9973\n",
      "epsilon is 3.157435331225372, alpha is 9.4\n",
      "Epoch 226, Loss G: 0.2052, Loss D: 1.9655\n",
      "epsilon is 3.1651235040210497, alpha is 9.3\n",
      "Epoch 227, Loss G: 0.2051, Loss D: 1.9621\n",
      "epsilon is 3.172756431253293, alpha is 9.3\n",
      "Epoch 228, Loss G: 0.2053, Loss D: 1.9714\n",
      "epsilon is 3.1803893584855367, alpha is 9.3\n",
      "Epoch 229, Loss G: 0.1989, Loss D: 1.9633\n",
      "epsilon is 3.1880222857177802, alpha is 9.3\n",
      "Epoch 230, Loss G: 0.2073, Loss D: 1.9565\n",
      "epsilon is 3.1956552129500237, alpha is 9.3\n",
      "Epoch 231, Loss G: 0.2143, Loss D: 1.9626\n",
      "epsilon is 3.2032881401822673, alpha is 9.3\n",
      "Epoch 232, Loss G: 0.2125, Loss D: 1.9147\n",
      "epsilon is 3.210869509591073, alpha is 9.2\n",
      "Epoch 233, Loss G: 0.2173, Loss D: 1.9301\n",
      "epsilon is 3.2184197446988536, alpha is 9.2\n",
      "Epoch 234, Loss G: 0.2084, Loss D: 1.9350\n",
      "epsilon is 3.225969979806634, alpha is 9.2\n",
      "Epoch 235, Loss G: 0.1947, Loss D: 1.9669\n",
      "epsilon is 3.233520214914414, alpha is 9.2\n",
      "Epoch 236, Loss G: 0.1940, Loss D: 1.9969\n",
      "epsilon is 3.2410704500221947, alpha is 9.2\n",
      "Epoch 237, Loss G: 0.1942, Loss D: 2.0172\n",
      "epsilon is 3.248620685129975, alpha is 9.2\n",
      "Epoch 238, Loss G: 0.1962, Loss D: 2.0084\n",
      "epsilon is 3.2561131679803137, alpha is 9.1\n",
      "Epoch 239, Loss G: 0.1980, Loss D: 1.9931\n",
      "epsilon is 3.263580724524734, alpha is 9.1\n",
      "Epoch 240, Loss G: 0.1806, Loss D: 2.0897\n",
      "epsilon is 3.271048281069154, alpha is 9.1\n",
      "Epoch 241, Loss G: 0.1852, Loss D: 2.0428\n",
      "epsilon is 3.2785158376135746, alpha is 9.1\n",
      "Epoch 242, Loss G: 0.1876, Loss D: 1.9967\n",
      "epsilon is 3.285983394157995, alpha is 9.1\n",
      "Epoch 243, Loss G: 0.1936, Loss D: 1.9749\n",
      "epsilon is 3.293450950702415, alpha is 9.1\n",
      "Epoch 244, Loss G: 0.2019, Loss D: 1.9982\n",
      "epsilon is 3.300873364057096, alpha is 9.0\n",
      "Epoch 245, Loss G: 0.2049, Loss D: 1.9861\n",
      "epsilon is 3.308258255594784, alpha is 9.0\n",
      "Epoch 246, Loss G: 0.2019, Loss D: 1.9553\n",
      "epsilon is 3.3156431471324717, alpha is 9.0\n",
      "Epoch 247, Loss G: 0.2041, Loss D: 1.9840\n",
      "epsilon is 3.323028038670159, alpha is 9.0\n",
      "Epoch 248, Loss G: 0.2059, Loss D: 1.9601\n",
      "epsilon is 3.3304129302078462, alpha is 9.0\n",
      "Epoch 249, Loss G: 0.2030, Loss D: 1.9875\n",
      "epsilon is 3.337797821745534, alpha is 9.0\n",
      "Epoch 250, Loss G: 0.2046, Loss D: 1.9775\n",
      "epsilon is 3.345169940522746, alpha is 8.9\n",
      "Epoch 251, Loss G: 0.1970, Loss D: 2.0099\n",
      "epsilon is 3.3524721806058553, alpha is 8.9\n",
      "Epoch 252, Loss G: 0.1877, Loss D: 2.0304\n",
      "epsilon is 3.3597744206889635, alpha is 8.9\n",
      "Epoch 253, Loss G: 0.1826, Loss D: 2.0330\n",
      "epsilon is 3.3670766607720717, alpha is 8.9\n",
      "Epoch 254, Loss G: 0.1938, Loss D: 2.0081\n",
      "epsilon is 3.3743789008551803, alpha is 8.9\n",
      "Epoch 255, Loss G: 0.1777, Loss D: 2.0931\n",
      "epsilon is 3.381681140938289, alpha is 8.9\n",
      "Epoch 256, Loss G: 0.1808, Loss D: 2.0880\n",
      "epsilon is 3.388983381021397, alpha is 8.9\n",
      "Epoch 257, Loss G: 0.1878, Loss D: 1.9972\n",
      "epsilon is 3.396243362180573, alpha is 8.8\n",
      "Epoch 258, Loss G: 0.1898, Loss D: 2.0035\n",
      "epsilon is 3.403462964356787, alpha is 8.8\n",
      "Epoch 259, Loss G: 0.2001, Loss D: 1.9868\n",
      "epsilon is 3.410682566533001, alpha is 8.8\n",
      "Epoch 260, Loss G: 0.2015, Loss D: 1.9907\n",
      "epsilon is 3.4179021687092153, alpha is 8.8\n",
      "Epoch 261, Loss G: 0.1933, Loss D: 2.0120\n",
      "epsilon is 3.4251217708854296, alpha is 8.8\n",
      "Epoch 262, Loss G: 0.1946, Loss D: 2.0115\n",
      "epsilon is 3.4323413730616434, alpha is 8.8\n",
      "Epoch 263, Loss G: 0.1874, Loss D: 2.1045\n",
      "epsilon is 3.4395609752378573, alpha is 8.8\n",
      "Epoch 264, Loss G: 0.1962, Loss D: 2.0227\n",
      "epsilon is 3.4467307276511234, alpha is 8.7\n",
      "Epoch 265, Loss G: 0.1769, Loss D: 2.0940\n",
      "epsilon is 3.4538677054636566, alpha is 8.7\n",
      "Epoch 266, Loss G: 0.1853, Loss D: 2.0376\n",
      "epsilon is 3.4610046832761907, alpha is 8.7\n",
      "Epoch 267, Loss G: 0.1713, Loss D: 2.0888\n",
      "epsilon is 3.468141661088724, alpha is 8.7\n",
      "Epoch 268, Loss G: 0.1809, Loss D: 2.0538\n",
      "epsilon is 3.475278638901257, alpha is 8.7\n",
      "Epoch 269, Loss G: 0.1739, Loss D: 2.0957\n",
      "epsilon is 3.482415616713791, alpha is 8.7\n",
      "Epoch 270, Loss G: 0.1674, Loss D: 2.0635\n",
      "epsilon is 3.4895525945263244, alpha is 8.7\n",
      "Epoch 271, Loss G: 0.1782, Loss D: 2.0940\n",
      "epsilon is 3.496655186280539, alpha is 8.6\n",
      "Epoch 272, Loss G: 0.1846, Loss D: 2.0482\n",
      "epsilon is 3.5037095532681426, alpha is 8.6\n",
      "Epoch 273, Loss G: 0.1872, Loss D: 2.0075\n",
      "epsilon is 3.5107639202557466, alpha is 8.6\n",
      "Epoch 274, Loss G: 0.1888, Loss D: 2.0211\n",
      "epsilon is 3.5178182872433497, alpha is 8.6\n",
      "Epoch 275, Loss G: 0.1949, Loss D: 1.9954\n",
      "epsilon is 3.5248726542309536, alpha is 8.6\n",
      "Epoch 276, Loss G: 0.2005, Loss D: 2.0080\n",
      "epsilon is 3.531927021218557, alpha is 8.6\n",
      "Epoch 277, Loss G: 0.1847, Loss D: 2.0160\n",
      "epsilon is 3.5389813882061607, alpha is 8.6\n",
      "Epoch 278, Loss G: 0.1910, Loss D: 2.0074\n",
      "epsilon is 3.5460357551937647, alpha is 8.6\n",
      "Epoch 279, Loss G: 0.1938, Loss D: 1.9629\n",
      "epsilon is 3.5530128944381025, alpha is 8.5\n",
      "Epoch 280, Loss G: 0.1931, Loss D: 2.0195\n",
      "epsilon is 3.5599846641350603, alpha is 8.5\n",
      "Epoch 281, Loss G: 0.1877, Loss D: 2.0045\n",
      "epsilon is 3.5669564338320185, alpha is 8.5\n",
      "Epoch 282, Loss G: 0.1940, Loss D: 1.9704\n",
      "epsilon is 3.5739282035289768, alpha is 8.5\n",
      "Epoch 283, Loss G: 0.1922, Loss D: 1.9841\n",
      "epsilon is 3.5808999732259346, alpha is 8.5\n",
      "Epoch 284, Loss G: 0.2026, Loss D: 1.9564\n",
      "epsilon is 3.587871742922893, alpha is 8.5\n",
      "Epoch 285, Loss G: 0.1963, Loss D: 1.9651\n",
      "epsilon is 3.594843512619851, alpha is 8.5\n",
      "Epoch 286, Loss G: 0.2047, Loss D: 2.0038\n",
      "epsilon is 3.6018034375018138, alpha is 8.4\n",
      "Epoch 287, Loss G: 0.2036, Loss D: 1.9651\n",
      "epsilon is 3.608692623437951, alpha is 8.4\n",
      "Epoch 288, Loss G: 0.2055, Loss D: 1.9798\n",
      "epsilon is 3.615581809374088, alpha is 8.4\n",
      "Epoch 289, Loss G: 0.2034, Loss D: 1.9753\n",
      "epsilon is 3.622470995310225, alpha is 8.4\n",
      "Epoch 290, Loss G: 0.2008, Loss D: 1.9528\n",
      "epsilon is 3.629360181246362, alpha is 8.4\n",
      "Epoch 291, Loss G: 0.2046, Loss D: 1.9350\n",
      "epsilon is 3.636249367182499, alpha is 8.4\n",
      "Epoch 292, Loss G: 0.2101, Loss D: 1.9590\n",
      "epsilon is 3.6431385531186358, alpha is 8.4\n",
      "Epoch 293, Loss G: 0.1938, Loss D: 2.0108\n",
      "epsilon is 3.6500277390547726, alpha is 8.4\n",
      "Epoch 294, Loss G: 0.1910, Loss D: 2.0502\n",
      "epsilon is 3.656914920086205, alpha is 8.3\n",
      "Epoch 295, Loss G: 0.1829, Loss D: 2.0326\n",
      "epsilon is 3.663721535786885, alpha is 8.3\n",
      "Epoch 296, Loss G: 0.1866, Loss D: 2.0461\n",
      "epsilon is 3.6705281514875647, alpha is 8.3\n",
      "Epoch 297, Loss G: 0.1836, Loss D: 2.0217\n",
      "epsilon is 3.6773347671882446, alpha is 8.3\n",
      "Epoch 298, Loss G: 0.1717, Loss D: 2.1015\n",
      "epsilon is 3.684141382888925, alpha is 8.3\n",
      "Epoch 299, Loss G: 0.1741, Loss D: 2.0910\n",
      "epsilon is 3.6909479985896048, alpha is 8.3\n",
      "Epoch 300, Loss G: 0.1862, Loss D: 2.0360\n",
      "epsilon is 3.6977546142902846, alpha is 8.3\n",
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 1269.8011 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 25005 rows (same as raw) in 2.4802 sec.\n",
      "Now is Postprocessor with default-smartnoise...\n",
      "Now is Evaluator with anonymeter-singlingout_univariate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.0009585236406264672, baseline = 0.0009585236406264672. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is 20240322_exp7[Report]_anonymeter-singlingout_univariate_[global] save to csv...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with anonymeter-linkability...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.0009585236406264672, baseline = 0.0009585236406264672. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is 20240322_exp7[Report]_anonymeter-linkability_[global] save to csv...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with anonymeter-inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.7624958165650305, baseline = 0.7679852728049836. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is 20240322_exp7[Report]_anonymeter-inference_[global] save to csv...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with sdmetrics-diag...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|| 13/13 [00:00<00:00, 527.85it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|| 1/1 [00:00<00:00, 577.01it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is 20240321_exp7[Report]_sdmetrics-diag_[columnwise] save to csv...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with sdmetrics-qual...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|| 13/13 [00:00<00:00, 199.14it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|| 78/78 [00:03<00:00, 24.50it/s]\n",
      "\n",
      "Overall Score: 57.03%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 68.57%\n",
      "- Column Pair Trends: 45.49%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is 20240321_exp7[Report]_sdmetrics-qual_[columnwise] save to csv...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Regression: 100%|| 5/5 [02:05<00:00, 25.10s/it]\n",
      "Regression: 100%|| 5/5 [01:37<00:00, 19.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is 20240321_exp7[Report]_automl-regression_[global] save to csv...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classification: 100%|| 5/5 [05:05<00:00, 61.14s/it]\n",
      "Classification: 100%|| 5/5 [00:35<00:00,  7.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is 20240321_exp7[Report]_automl-classification_[global] save to csv...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering: 100%|| 5/5 [00:11<00:00,  2.32s/it]\n",
      "Clustering: 100%|| 5/5 [00:06<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan5]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is 20240321_exp7[Report]_automl-cluster_[global] save to csv...\n",
      "Now is Synthesizer with smartnoise-dpctgan1...\n",
      "Synthesizer (SmartNoise): Fitting dpctgan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opacus/privacy_engine.py:638: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opacus/privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1352: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.6661, Loss D: 1.4066\n",
      "epsilon is 0.16217888283723578, alpha is 63.0\n",
      "Epoch 2, Loss G: 0.6853, Loss D: 1.3994\n",
      "epsilon is 0.2163014051914117, alpha is 63.0\n",
      "Epoch 3, Loss G: 0.6903, Loss D: 1.3928\n",
      "epsilon is 0.27042392754558764, alpha is 63.0\n",
      "Epoch 4, Loss G: 0.6667, Loss D: 1.4017\n",
      "epsilon is 0.3245464498997635, alpha is 63.0\n",
      "Epoch 5, Loss G: 0.6627, Loss D: 1.3962\n",
      "epsilon is 0.376197456841065, alpha is 57.0\n",
      "Epoch 6, Loss G: 0.6597, Loss D: 1.3964\n",
      "epsilon is 0.4221411479824565, alpha is 51.0\n",
      "Epoch 7, Loss G: 0.6582, Loss D: 1.3946\n",
      "epsilon is 0.4639167774251823, alpha is 47.0\n",
      "Epoch 8, Loss G: 0.6578, Loss D: 1.3944\n",
      "epsilon is 0.5025193987805284, alpha is 44.0\n",
      "Epoch 9, Loss G: 0.6555, Loss D: 1.3932\n",
      "epsilon is 0.5386576819634908, alpha is 42.0\n",
      "Epoch 10, Loss G: 0.6574, Loss D: 1.3971\n",
      "epsilon is 0.5726766764984677, alpha is 39.0\n",
      "Epoch 11, Loss G: 0.6456, Loss D: 1.3975\n",
      "epsilon is 0.6050111960332332, alpha is 38.0\n",
      "Epoch 12, Loss G: 0.6497, Loss D: 1.3924\n",
      "epsilon is 0.6357796528187886, alpha is 36.0\n",
      "Epoch 13, Loss G: 0.6439, Loss D: 1.3953\n",
      "epsilon is 0.6653871970718096, alpha is 35.0\n",
      "Epoch 14, Loss G: 0.6419, Loss D: 1.3974\n",
      "epsilon is 0.6937671433528385, alpha is 33.0\n",
      "Epoch 15, Loss G: 0.6358, Loss D: 1.3953\n",
      "epsilon is 0.7211585434841012, alpha is 32.0\n",
      "Epoch 16, Loss G: 0.6371, Loss D: 1.3939\n",
      "epsilon is 0.7476730058511001, alpha is 31.0\n",
      "Epoch 17, Loss G: 0.6331, Loss D: 1.3920\n",
      "epsilon is 0.7734020455693197, alpha is 30.0\n",
      "Epoch 18, Loss G: 0.6349, Loss D: 1.3902\n",
      "epsilon is 0.7984498642333995, alpha is 29.0\n",
      "Epoch 19, Loss G: 0.6266, Loss D: 1.4014\n",
      "epsilon is 0.8226435666650334, alpha is 29.0\n",
      "Epoch 20, Loss G: 0.6227, Loss D: 1.3983\n",
      "epsilon is 0.8462755532142662, alpha is 28.0\n",
      "Epoch 21, Loss G: 0.6207, Loss D: 1.3953\n",
      "epsilon is 0.8694843445807604, alpha is 27.0\n",
      "Epoch 22, Loss G: 0.6242, Loss D: 1.4000\n",
      "epsilon is 0.8919717132862962, alpha is 27.0\n",
      "Epoch 23, Loss G: 0.6258, Loss D: 1.4016\n",
      "epsilon is 0.9140652932933118, alpha is 26.0\n",
      "Epoch 24, Loss G: 0.6205, Loss D: 1.3934\n",
      "epsilon is 0.9357016570631423, alpha is 26.0\n",
      "Epoch 25, Loss G: 0.6203, Loss D: 1.3994\n",
      "epsilon is 0.9568681678637022, alpha is 25.0\n",
      "Epoch 26, Loss G: 0.6083, Loss D: 1.3987\n",
      "epsilon is 0.9776549614336737, alpha is 25.0\n",
      "Epoch 27, Loss G: 0.5965, Loss D: 1.4147\n",
      "epsilon is 0.9981146214609729, alpha is 24.0\n",
      "Synthesizer (SmartNoise): Fitting  dpctgan spent 55.5609 sec.\n",
      "Synthesizer (SmartNoise): Sampling dpctgan # 25005 rows (same as raw) in 2.493 sec.\n",
      "Now is Postprocessor with default-smartnoise...\n",
      "Now is Evaluator with anonymeter-singlingout_univariate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.0009585236406264672, baseline = 0.0009585236406264672. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is 20240322_exp7[Report]_anonymeter-singlingout_univariate_[global] save to csv...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with anonymeter-linkability...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anonymeter/stats/confidence.py:218: UserWarning: Attack is as good or worse as baseline model. Estimated rates: attack = 0.0009585236406264672, baseline = 0.0009585236406264672. Analysis results cannot be trusted.\n",
      "  self._sanity_check()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is 20240322_exp7[Report]_anonymeter-linkability_[global] save to csv...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with anonymeter-inference...\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is 20240322_exp7[Report]_anonymeter-inference_[global] save to csv...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with sdmetrics-diag...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|| 13/13 [00:00<00:00, 526.87it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|| 1/1 [00:00<00:00, 679.90it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is 20240321_exp7[Report]_sdmetrics-diag_[columnwise] save to csv...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with sdmetrics-qual...\n",
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|| 13/13 [00:00<00:00, 198.01it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|| 78/78 [00:03<00:00, 24.58it/s]\n",
      "\n",
      "Overall Score: 53.66%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 63.54%\n",
      "- Column Pair Trends: 43.79%\n",
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is 20240321_exp7[Report]_sdmetrics-qual_[columnwise] save to csv...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Regression: 100%|| 5/5 [02:05<00:00, 25.15s/it]\n",
      "Regression: 100%|| 5/5 [01:30<00:00, 18.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is 20240321_exp7[Report]_automl-regression_[global] save to csv...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classification: 100%|| 5/5 [05:04<00:00, 60.85s/it]\n",
      "Classification: 100%|| 5/5 [00:36<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is 20240321_exp7[Report]_automl-classification_[global] save to csv...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is Evaluator with automl-cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering: 100%|| 5/5 [00:11<00:00,  2.40s/it]\n",
      "Clustering: 100%|| 5/5 [00:05<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is Reporter with save_data...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[train]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]_[validation]] save to csv...\n",
      "Now is 20240322_exp7_Loader[adult-income]_Splitter[p80_[2-2]]_Preprocessor[default-smartnoise]_Synthesizer[smartnoise-dpctgan1]_Postprocessor[default-smartnoise] save to csv...\n",
      "Now is Reporter with save_report_singlingout...\n",
      "Now is Reporter with save_report_linkability...\n",
      "Now is Reporter with save_report_inference...\n",
      "Now is Reporter with save_report_sdmetrics-diag...\n",
      "Now is Reporter with save_report_sdmetrics-qual...\n",
      "Now is Reporter with save_report_automl-regression...\n",
      "Now is Reporter with save_report_automl-classification...\n",
      "Now is Reporter with save_report_automl-cluster...\n",
      "Now is 20240321_exp7[Report]_automl-cluster_[global] save to csv...\n"
     ]
    }
   ],
   "source": [
    "exec = Executor(config='exp7.yaml')\n",
    "exec.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53788830-6c8b-4692-8d99-5c2316ba9e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
